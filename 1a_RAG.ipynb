{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YoshiyukiKono/langchain_for_beginners/blob/main/1a_RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://python.langchain.com/docs/modules/data_connection/document_loaders/pdf"
      ],
      "metadata": {
        "id": "YODRRq-0Y4Gj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pypdf"
      ],
      "metadata": {
        "id": "oX33RRkrY2WY",
        "outputId": "7e0feb6f-d7ec-41c3-b17c-789c62ac741b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pypdf\n",
            "  Downloading pypdf-3.17.0-py3-none-any.whl (277 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/277.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.6/277.4 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m277.4/277.4 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf\n",
            "Successfully installed pypdf-3.17.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain\n",
        "!pip install openai\n",
        "!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMMMfJaKo4Ww",
        "outputId": "9e180a2a-08c5-42ca-d4bc-cf06812bb300"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.0.330-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.22)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.8.6)\n",
            "Requirement already satisfied: anyio<4.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.7.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.1-py3-none-any.whl (27 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langsmith<0.1.0,>=0.0.52 (from langchain)\n",
            "  Downloading langsmith-0.0.57-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.5/44.5 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.13)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.3.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (1.1.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.5.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain) (23.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, jsonpointer, typing-inspect, langsmith, jsonpatch, dataclasses-json, langchain\n",
            "Successfully installed dataclasses-json-0.6.1 jsonpatch-1.33 jsonpointer-2.4 langchain-0.0.330 langsmith-0.0.57 marshmallow-3.20.1 mypy-extensions-1.0.0 typing-inspect-0.9.0\n",
            "Collecting openai\n",
            "  Downloading openai-0.28.1-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed openai-0.28.1\n",
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2023.7.22)\n",
            "Installing collected packages: tiktoken\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tiktoken-0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "\n",
        "loader = PyPDFLoader(\"./2302.00618.pdf\")\n",
        "pages = loader.load_and_split()"
      ],
      "metadata": {
        "id": "uqx1XkeMZCMd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pages[0]"
      ],
      "metadata": {
        "id": "QzK8Pk4RZY5I",
        "outputId": "cc10a765-9792-4276-a744-ad877c3b66cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content='Synthetic Prompting: Generating Chain-of-Thought Demonstrations for Large\\nLanguage Models\\nZhihong Shao1 2Yeyun Gong3Yelong Shen4Minlie Huang1Nan Duan3Weizhu Chen4\\nAbstract\\nLarge language models can perform various rea-\\nsoning tasks by using chain-of-thought prompting,\\nwhich guides them to ﬁnd answers through step-\\nby-step demonstrations. However, the quality of\\nthe prompts depends on the demonstrations given\\nto the models, and creating many of them by hand\\nis costly. We introduce S YNTHETIC PROMPTING ,\\na method that leverages a few handcrafted exam-\\nples to prompt the model to generate more exam-\\nples by itself, and selects effective demonstrations\\nto elicit better reasoning. Our method alternates\\nbetween a backward and forward process to gen-\\nerate new examples. The backward process gen-\\nerates a question that match a sampled reasoning\\nchain, so that the question is solvable and clear.\\nThe forward process produces a more detailed\\nreasoning chain for the question, improving the\\nquality of the example. We evaluate our method\\non numerical, symbolic, and algorithmic reason-\\ning tasks, and show that it outperforms existing\\nprompting techniques.\\n1. Introduction\\nFew-shot demonstrations, i.e., examples of inputs and out-\\nputs for a task, can enable Large Language Models (LLMs)\\nto perform various tasks without ﬁne-tuning (Brown et al.,\\n2020; Chung et al., 2022). LLMs can further improve their\\nperformance by using chain-of-thought prompting, which\\nprovides intermediate reasoning steps for the task (Wei et al.,\\n2022b; Kojima et al., 2022). However, the LLMs’ few-shot\\nperformance depends heavily on the quality of the demon-\\nstrations, especially for reasoning tasks that need complex\\nand diverse reasoning patterns. Manually creating a large\\nand diverse set of examples for demonstration selection is\\ncostly and tedious, while relying on a limited set of demon-\\nstrations may hamper the LLMs’ generalization and adapta-\\n1Tsinghua University2This work was done during an internship\\nin MSRA3Microsoft Research Asia4Microsoft. Correspondence\\nto: Minlie Huang <aihuang@tsinghua.edu.cn >.tion to different test inputs.\\nIn this paper, we propose a novel method, S YNTHETIC\\nPROMPTING , that leverages the LLMs’ own knowledge and\\ngenerative power to augment a limited set of demonstra-\\ntions with self-synthesized examples, and then uses the aug-\\nmented set to elicit better reasoning in the LLMs. Specif-\\nically, given a few seed examples, each consisting of a\\nquestion and a chain of reasoning steps, we prompt an\\nLLM to generate more examples by alternating between\\ntwo processes: (1) the backward process, where the LLM\\nsynthesizes a question based on a self-generated reasoning\\nchain, which ensures that the question is answerable and\\nwell-deﬁned; and (2) the forward process, where the LLM\\nproduces a reasoning chain for the synthesized question,\\nwhich reﬁnes the reasoning chain to be more precise and\\nconsistent with the question. We repeat this process until\\nwe obtain enough synthetic examples. To select the most\\neffective demonstrations from the augmented set, we pro-\\npose a new selection scheme based on in-cluster complexity,\\nwhich aims to maximize the diversity and informativeness\\nof the demonstrations by clustering them and choosing the\\nmost complex one (the one with the longest reasoning chain)\\nfrom each cluster. Finally, we prompt the LLM with the\\nselected demonstrations to generate a reasoning chain for a\\ntest question and then use it to obtain the answer.\\nWe evaluate our method on various reasoning tasks, in-\\ncluding numerical reasoning, algorithmic reasoning, and\\nsymbolic reasoning. Following previous few-shot settings\\n(Wang et al., 2022b; Suzgun et al., 2022), we demonstrate\\nthat our method can signiﬁcantly improve the LLMs’ per-\\nformance, achieving up to 15.6% absolute gains over the\\nstate-of-the-art methods.\\nOur main contributions are:\\n•We introduce S YNTHETIC PROMPTING , a novel\\nmethod that augments a limited set of demonstrations', metadata={'source': './2302.00618.pdf', 'page': 0})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Astra DB Template\n",
        "\n",
        "## Environment Setup\n",
        "It is expected to use GPU when using the embedding model. Change the setting from the menu as follows: Runtime > Change runtime type > Hardware accelerator: `GPU`"
      ],
      "metadata": {
        "id": "5GmUfFL0YCtB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O secure-connect-vector.zip \"https://datastax-cluster-config-prod.s3.us-east-2.amazonaws.com/216b7807-e6c4-471d-bb29-342090dcbade-1/secure-connect-vector.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIA2AIQRQ76S2JCB77W%2F20231110%2Fus-east-2%2Fs3%2Faws4_request&X-Amz-Date=20231110T061457Z&X-Amz-Expires=300&X-Amz-SignedHeaders=host&X-Amz-Signature=53e07e50340aa66b53bf613ca9175ec0605abaa8412810bab771115a107247eb\""
      ],
      "metadata": {
        "id": "IUm51RWBJiU9",
        "outputId": "537b557c-6bd0-40fb-9cd2-feabafaba02e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-11-10 06:15:15--  https://datastax-cluster-config-prod.s3.us-east-2.amazonaws.com/216b7807-e6c4-471d-bb29-342090dcbade-1/secure-connect-vector.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIA2AIQRQ76S2JCB77W%2F20231110%2Fus-east-2%2Fs3%2Faws4_request&X-Amz-Date=20231110T061457Z&X-Amz-Expires=300&X-Amz-SignedHeaders=host&X-Amz-Signature=53e07e50340aa66b53bf613ca9175ec0605abaa8412810bab771115a107247eb\n",
            "Resolving datastax-cluster-config-prod.s3.us-east-2.amazonaws.com (datastax-cluster-config-prod.s3.us-east-2.amazonaws.com)... 52.219.143.18, 3.5.128.17, 52.219.104.152, ...\n",
            "Connecting to datastax-cluster-config-prod.s3.us-east-2.amazonaws.com (datastax-cluster-config-prod.s3.us-east-2.amazonaws.com)|52.219.143.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 12252 (12K) [application/zip]\n",
            "Saving to: ‘secure-connect-vector.zip’\n",
            "\n",
            "secure-connect-vect 100%[===================>]  11.96K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-11-10 06:15:15 (152 MB/s) - ‘secure-connect-vector.zip’ saved [12252/12252]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cassandra-driver\n",
        "!pip install cassio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9k10ziT0zRYw",
        "outputId": "96459111-6dd4-4850-b34f-25a8879b95c0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting cassandra-driver\n",
            "  Downloading cassandra_driver-3.28.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.1/19.1 MB\u001b[0m \u001b[31m66.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.9 in /usr/local/lib/python3.10/dist-packages (from cassandra-driver) (1.16.0)\n",
            "Collecting geomet<0.3,>=0.1 (from cassandra-driver)\n",
            "  Downloading geomet-0.2.1.post1-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from geomet<0.3,>=0.1->cassandra-driver) (8.1.7)\n",
            "Installing collected packages: geomet, cassandra-driver\n",
            "Successfully installed cassandra-driver-3.28.0 geomet-0.2.1.post1\n",
            "Collecting cassio\n",
            "  Downloading cassio-0.1.3-py3-none-any.whl (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/40.1 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cassandra-driver>=3.28.0 in /usr/local/lib/python3.10/dist-packages (from cassio) (3.28.0)\n",
            "Requirement already satisfied: numpy>=1.0 in /usr/local/lib/python3.10/dist-packages (from cassio) (1.23.5)\n",
            "Requirement already satisfied: requests>=2 in /usr/local/lib/python3.10/dist-packages (from cassio) (2.31.0)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.10/dist-packages (from cassandra-driver>=3.28.0->cassio) (1.16.0)\n",
            "Requirement already satisfied: geomet<0.3,>=0.1 in /usr/local/lib/python3.10/dist-packages (from cassandra-driver>=3.28.0->cassio) (0.2.1.post1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2->cassio) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2->cassio) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2->cassio) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2->cassio) (2023.7.22)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from geomet<0.3,>=0.1->cassandra-driver>=3.28.0->cassio) (8.1.7)\n",
            "Installing collected packages: cassio\n",
            "Successfully installed cassio-0.1.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SECURE_CONNECT_BUNDLE_PATH = 'secure-connect-vector.zip'"
      ],
      "metadata": {
        "id": "qGzwcnhfIROt"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "\n",
        "ASTRA_CLIENT_ID = getpass.getpass()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVlMnfyJJVUb",
        "outputId": "69c06451-95b4-48ff-8659-711d1a0bd4f7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "ASTRA_CLIENT_SECRET = getpass.getpass()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvKJFm2vJgoU",
        "outputId": "5883cf83-f13c-4a83-cb51-20845f15e852"
      },
      "execution_count": 4,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from cassandra.cluster import Cluster\n",
        "from cassandra.auth import PlainTextAuthProvider\n",
        "\n",
        "cloud_config= {\n",
        "  'secure_connect_bundle': SECURE_CONNECT_BUNDLE_PATH\n",
        "}\n",
        "auth_provider = PlainTextAuthProvider(ASTRA_CLIENT_ID, ASTRA_CLIENT_SECRET)\n",
        "cluster = Cluster(cloud=cloud_config, auth_provider=auth_provider)\n",
        "session = cluster.connect()\n",
        "\n",
        "row = session.execute(\"select release_version from system.local\").one()\n",
        "if row:\n",
        "  print(row[0])\n",
        "else:\n",
        "  print(\"An error occurred.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qrGG5yAEJpnJ",
        "outputId": "caf705d8-2bba-4b94-b9bc-f3f2e00fcc9a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:cassandra.cluster:Downgrading core protocol version from 66 to 65 for 216b7807-e6c4-471d-bb29-342090dcbade-us-east1.db.astra.datastax.com:29042:ec50906d-357c-42c4-86c0-d2f110236649. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n",
            "WARNING:cassandra.cluster:Downgrading core protocol version from 65 to 5 for 216b7807-e6c4-471d-bb29-342090dcbade-us-east1.db.astra.datastax.com:29042:ec50906d-357c-42c4-86c0-d2f110236649. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n",
            "ERROR:cassandra.connection:Closing connection <AsyncoreConnection(138496730798432) 216b7807-e6c4-471d-bb29-342090dcbade-us-east1.db.astra.datastax.com:29042:ec50906d-357c-42c4-86c0-d2f110236649> due to protocol error: Error from server: code=000a [Protocol error] message=\"Beta version of the protocol used (5/v5-beta), but USE_BETA flag is unset\"\n",
            "WARNING:cassandra.cluster:Downgrading core protocol version from 5 to 4 for 216b7807-e6c4-471d-bb29-342090dcbade-us-east1.db.astra.datastax.com:29042:ec50906d-357c-42c4-86c0-d2f110236649. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.0.11-b86be92b8b5f\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "YOUR_KEYSPACE = 'pdf'\n",
        "session.set_keyspace(YOUR_KEYSPACE)\n",
        "session"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Im1ixFaIJ9Mw",
        "outputId": "5cab49ed-8e57-4772-a0cc-f0deb0b2fc8c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<cassandra.cluster.Session at 0x7df648712f20>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain\n",
        "!pip install openai\n",
        "!pip install tiktoken"
      ],
      "metadata": {
        "id": "tbVxBCC-4HPS",
        "outputId": "f0fe8478-14ca-4b5e-8f10-3cc5f348111a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.0.333)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.23)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.8.6)\n",
            "Requirement already satisfied: anyio<4.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.7.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.6.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.33)\n",
            "Requirement already satisfied: langsmith<0.1.0,>=0.0.62 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.63)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.13)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.3.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (1.1.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.5.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain) (23.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: anyio<4,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.25.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.13)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.10/dist-packages (from openai) (4.5.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (1.1.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.7.22)\n",
            "Requirement already satisfied: httpcore in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2023.7.22)\n",
            "Installing collected packages: tiktoken\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tiktoken-0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import Cassandra\n",
        "from langchain.document_loaders import TextLoader"
      ],
      "metadata": {
        "id": "FCsCyZLJcTgF"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import openai\n",
        "import getpass\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()\n",
        "#openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
      ],
      "metadata": {
        "id": "WLkDfg9_dB_l",
        "outputId": "3be45695-b598-42a5-d812-1b4147f4f31c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_function = OpenAIEmbeddings()"
      ],
      "metadata": {
        "id": "IeNgg0f1dLkn"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://python.langchain.com/docs/integrations/vectorstores/cassandra"
      ],
      "metadata": {
        "id": "iVdDamz_dQ2b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "docs = text_splitter.split_documents(pages)\n",
        "\n"
      ],
      "metadata": {
        "id": "Xv2mLw5ece87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Cassandra from documents"
      ],
      "metadata": {
        "id": "lWMh_qez4mGZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "table_name = \"pdf_arxiv\"\n",
        "\n",
        "docsearch = Cassandra.from_documents(\n",
        "    documents=docs,\n",
        "    embedding=embedding_function,\n",
        "    session=session,\n",
        "    keyspace=YOUR_KEYSPACE,\n",
        "    table_name=table_name,\n",
        ")"
      ],
      "metadata": {
        "id": "DatB7b8pdYzV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize Vectore Store from an exisiting table"
      ],
      "metadata": {
        "id": "UL_Fn_qR4q__"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import Cassandra\n",
        "docsearch = Cassandra(\n",
        "  embedding=embedding_function,\n",
        "  session=session,\n",
        "  keyspace=YOUR_KEYSPACE,\n",
        "  table_name=\"pdf_arxiv\",\n",
        ")"
      ],
      "metadata": {
        "id": "mraUEgHN419j"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is chain of thoughts\"\n",
        "docs = docsearch.similarity_search(query)\n",
        "print(len(docs))\n",
        "print(docs[0])\n",
        "for doc in docs:\n",
        "  print(doc)"
      ],
      "metadata": {
        "id": "yK39q3wldnBj",
        "outputId": "197dd1c2-4eea-4ded-e2af-a9818062473a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n",
            "page_content='Synthetic Prompting: Generating Chain-of-Thought Demonstrations for Large Language Models\\nAssociation for Computational Linguistics: Human Lan-\\nguage Technologies, NAACL 2022, Seattle, WA, United\\nStates, July 10-15, 2022 , pp. 5168–5186. Association\\nfor Computational Linguistics, 2022. doi: 10.18653/v1/\\n2022.naacl-main.380. URL https://doi.org/10.\\n18653/v1/2022.naacl-main.380 .\\nSuzgun, M., Scales, N., Sch ¨arli, N., Gehrmann, S., Tay, Y .,\\nChung, H. W., Chowdhery, A., Le, Q. V ., Chi, E. H., Zhou,\\nD., and Wei, J. Challenging big-bench tasks and whether\\nchain-of-thought can solve them. CoRR , abs/2210.09261,\\n2022. doi: 10.48550/arXiv.2210.09261. URL https:\\n//doi.org/10.48550/arXiv.2210.09261 .\\nThoppilan, R., Freitas, D. D., Hall, J., Shazeer, N., Kul-\\nshreshtha, A., Cheng, H., Jin, A., Bos, T., Baker, L., Du,\\nY ., Li, Y ., Lee, H., Zheng, H. S., Ghafouri, A., Mene-\\ngali, M., Huang, Y ., Krikun, M., Lepikhin, D., Qin, J.,\\nChen, D., Xu, Y ., Chen, Z., Roberts, A., Bosma, M.,\\nZhou, Y ., Chang, C., Krivokon, I., Rusch, W., Pickett,\\nM., Meier-Hellstern, K. S., Morris, M. R., Doshi, T.,\\nSantos, R. D., Duke, T., Soraker, J., Zevenbergen, B.,\\nPrabhakaran, V ., Diaz, M., Hutchinson, B., Olson, K.,\\nMolina, A., Hoffman-John, E., Lee, J., Aroyo, L., Ra-\\njakumar, R., Butryna, A., Lamm, M., Kuzmina, V ., Fen-\\nton, J., Cohen, A., Bernstein, R., Kurzweil, R., Aguera-\\nArcas, B., Cui, C., Croak, M., Chi, E. H., and Le, Q.\\nLamda: Language models for dialog applications. CoRR ,\\nabs/2201.08239, 2022. URL https://arxiv.org/\\nabs/2201.08239 .\\nWang, X., Wei, J., Schuurmans, D., Le, Q. V ., Chi, E. H.,\\nand Zhou, D. Self-consistency improves chain of thought\\nreasoning in language models. CoRR , abs/2203.11171,\\n2022a. doi: 10.48550/arXiv.2203.11171. URL https:\\n//doi.org/10.48550/arXiv.2203.11171 .\\nWang, Y ., Mishra, S., Alipoormolabashi, P., Kordi, Y .,\\nMirzaei, A., Arunkumar, A., Ashok, A., Dhanasekaran,\\nA. S., Naik, A., Stap, D., Pathak, E., Karamanolakis, G.,\\nLai, H. G., Purohit, I., Mondal, I., Anderson, J., Kuznia,\\nK., Doshi, K., Patel, M., Pal, K. K., Moradshahi, M., Par-\\nmar, M., Purohit, M., Varshney, N., Kaza, P. R., Verma,\\nP., Puri, R. S., Karia, R., Sampat, S. K., Doshi, S., Mishra,\\nS., Reddy, S., Patro, S., Dixit, T., Shen, X., Baral, C.,\\nChoi, Y ., Smith, N. A., Hajishirzi, H., and Khashabi, D.\\nSuper-naturalinstructions: Generalization via declarative\\ninstructions on 1600+ nlp tasks, 2022b.\\nWei, J., Bosma, M., Zhao, V . Y ., Guu, K., Yu, A. W., Lester,\\nB., Du, N., Dai, A. M., and Le, Q. V . Finetuned language\\nmodels are zero-shot learners. In The Tenth Interna-\\ntional Conference on Learning Representations, ICLR\\n2022, Virtual Event, April 25-29, 2022 . OpenReview.net,\\n2022a. URL https://openreview.net/forum?\\nid=gEZrGCozdqR .Wei, J., Wang, X., Schuurmans, D., Bosma, M., Chi,\\nE. H., Le, Q., and Zhou, D. Chain of thought prompt-\\ning elicits reasoning in large language models. CoRR ,\\nabs/2201.11903, 2022b. URL https://arxiv.org/\\nabs/2201.11903 .\\nWest, P., Bhagavatula, C., Hessel, J., Hwang, J. D., Jiang, L.,\\nBras, R. L., Lu, X., Welleck, S., and Choi, Y . Symbolic\\nknowledge distillation: from general language models\\nto commonsense models. In Carpuat, M., de Marneffe,\\nM., and Ru ´ız, I. V . M. (eds.), Proceedings of the 2022\\nConference of the North American Chapter of the As-\\nsociation for Computational Linguistics: Human Lan-\\nguage Technologies, NAACL 2022, Seattle, WA, United\\nStates, July 10-15, 2022 , pp. 4602–4625. Association\\nfor Computational Linguistics, 2022. doi: 10.18653/v1/\\n2022.naacl-main.341. URL https://doi.org/10.\\n18653/v1/2022.naacl-main.341 .\\nYang, K., Klein, D., Peng, N., and Tian, Y . DOC: im-\\nproving long story coherence with detailed outline con-\\ntrol. CoRR , abs/2212.10077, 2022. doi: 10.48550/arXiv.\\n2212.10077. URL https://doi.org/10.48550/\\narXiv.2212.10077 .\\nYe, J., Gao, J., Li, Q., Xu, H., Feng, J., Wu, Z., Yu, T.,\\nand Kong, L. Zerogen: Efﬁcient zero-shot learning via\\ndataset generation. CoRR , abs/2202.07922, 2022a. URL' metadata={'page': '10.0', 'source': './2302.00618.pdf'}\n",
            "page_content='Synthetic Prompting: Generating Chain-of-Thought Demonstrations for Large Language Models\\nAssociation for Computational Linguistics: Human Lan-\\nguage Technologies, NAACL 2022, Seattle, WA, United\\nStates, July 10-15, 2022 , pp. 5168–5186. Association\\nfor Computational Linguistics, 2022. doi: 10.18653/v1/\\n2022.naacl-main.380. URL https://doi.org/10.\\n18653/v1/2022.naacl-main.380 .\\nSuzgun, M., Scales, N., Sch ¨arli, N., Gehrmann, S., Tay, Y .,\\nChung, H. W., Chowdhery, A., Le, Q. V ., Chi, E. H., Zhou,\\nD., and Wei, J. Challenging big-bench tasks and whether\\nchain-of-thought can solve them. CoRR , abs/2210.09261,\\n2022. doi: 10.48550/arXiv.2210.09261. URL https:\\n//doi.org/10.48550/arXiv.2210.09261 .\\nThoppilan, R., Freitas, D. D., Hall, J., Shazeer, N., Kul-\\nshreshtha, A., Cheng, H., Jin, A., Bos, T., Baker, L., Du,\\nY ., Li, Y ., Lee, H., Zheng, H. S., Ghafouri, A., Mene-\\ngali, M., Huang, Y ., Krikun, M., Lepikhin, D., Qin, J.,\\nChen, D., Xu, Y ., Chen, Z., Roberts, A., Bosma, M.,\\nZhou, Y ., Chang, C., Krivokon, I., Rusch, W., Pickett,\\nM., Meier-Hellstern, K. S., Morris, M. R., Doshi, T.,\\nSantos, R. D., Duke, T., Soraker, J., Zevenbergen, B.,\\nPrabhakaran, V ., Diaz, M., Hutchinson, B., Olson, K.,\\nMolina, A., Hoffman-John, E., Lee, J., Aroyo, L., Ra-\\njakumar, R., Butryna, A., Lamm, M., Kuzmina, V ., Fen-\\nton, J., Cohen, A., Bernstein, R., Kurzweil, R., Aguera-\\nArcas, B., Cui, C., Croak, M., Chi, E. H., and Le, Q.\\nLamda: Language models for dialog applications. CoRR ,\\nabs/2201.08239, 2022. URL https://arxiv.org/\\nabs/2201.08239 .\\nWang, X., Wei, J., Schuurmans, D., Le, Q. V ., Chi, E. H.,\\nand Zhou, D. Self-consistency improves chain of thought\\nreasoning in language models. CoRR , abs/2203.11171,\\n2022a. doi: 10.48550/arXiv.2203.11171. URL https:\\n//doi.org/10.48550/arXiv.2203.11171 .\\nWang, Y ., Mishra, S., Alipoormolabashi, P., Kordi, Y .,\\nMirzaei, A., Arunkumar, A., Ashok, A., Dhanasekaran,\\nA. S., Naik, A., Stap, D., Pathak, E., Karamanolakis, G.,\\nLai, H. G., Purohit, I., Mondal, I., Anderson, J., Kuznia,\\nK., Doshi, K., Patel, M., Pal, K. K., Moradshahi, M., Par-\\nmar, M., Purohit, M., Varshney, N., Kaza, P. R., Verma,\\nP., Puri, R. S., Karia, R., Sampat, S. K., Doshi, S., Mishra,\\nS., Reddy, S., Patro, S., Dixit, T., Shen, X., Baral, C.,\\nChoi, Y ., Smith, N. A., Hajishirzi, H., and Khashabi, D.\\nSuper-naturalinstructions: Generalization via declarative\\ninstructions on 1600+ nlp tasks, 2022b.\\nWei, J., Bosma, M., Zhao, V . Y ., Guu, K., Yu, A. W., Lester,\\nB., Du, N., Dai, A. M., and Le, Q. V . Finetuned language\\nmodels are zero-shot learners. In The Tenth Interna-\\ntional Conference on Learning Representations, ICLR\\n2022, Virtual Event, April 25-29, 2022 . OpenReview.net,\\n2022a. URL https://openreview.net/forum?\\nid=gEZrGCozdqR .Wei, J., Wang, X., Schuurmans, D., Bosma, M., Chi,\\nE. H., Le, Q., and Zhou, D. Chain of thought prompt-\\ning elicits reasoning in large language models. CoRR ,\\nabs/2201.11903, 2022b. URL https://arxiv.org/\\nabs/2201.11903 .\\nWest, P., Bhagavatula, C., Hessel, J., Hwang, J. D., Jiang, L.,\\nBras, R. L., Lu, X., Welleck, S., and Choi, Y . Symbolic\\nknowledge distillation: from general language models\\nto commonsense models. In Carpuat, M., de Marneffe,\\nM., and Ru ´ız, I. V . M. (eds.), Proceedings of the 2022\\nConference of the North American Chapter of the As-\\nsociation for Computational Linguistics: Human Lan-\\nguage Technologies, NAACL 2022, Seattle, WA, United\\nStates, July 10-15, 2022 , pp. 4602–4625. Association\\nfor Computational Linguistics, 2022. doi: 10.18653/v1/\\n2022.naacl-main.341. URL https://doi.org/10.\\n18653/v1/2022.naacl-main.341 .\\nYang, K., Klein, D., Peng, N., and Tian, Y . DOC: im-\\nproving long story coherence with detailed outline con-\\ntrol. CoRR , abs/2212.10077, 2022. doi: 10.48550/arXiv.\\n2212.10077. URL https://doi.org/10.48550/\\narXiv.2212.10077 .\\nYe, J., Gao, J., Li, Q., Xu, H., Feng, J., Wu, Z., Yu, T.,\\nand Kong, L. Zerogen: Efﬁcient zero-shot learning via\\ndataset generation. CoRR , abs/2202.07922, 2022a. URL' metadata={'page': '10.0', 'source': './2302.00618.pdf'}\n",
            "page_content='Synthetic Prompting: Generating Chain-of-Thought Demonstrations for Large Language Models\\nprompting.\\nReferences\\nBrown, T. B., Mann, B., Ryder, N., Subbiah, M., Kaplan,\\nJ., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G.,\\nAskell, A., Agarwal, S., Herbert-V oss, A., Krueger, G.,\\nHenighan, T., Child, R., Ramesh, A., Ziegler, D. M., Wu,\\nJ., Winter, C., Hesse, C., Chen, M., Sigler, E., Litwin, M.,\\nGray, S., Chess, B., Clark, J., Berner, C., McCandlish, S.,\\nRadford, A., Sutskever, I., and Amodei, D. Language\\nmodels are few-shot learners. In Larochelle, H.,\\nRanzato, M., Hadsell, R., Balcan, M., and Lin, H. (eds.),\\nAdvances in Neural Information Processing Systems 33:\\nAnnual Conference on Neural Information Processing\\nSystems 2020, NeurIPS 2020, December 6-12, 2020,\\nvirtual , 2020. URL https://proceedings.\\nneurips.cc/paper/2020/hash/\\n1457c0d6bfcb4967418bfb8ac142f64a-Abstract.\\nhtml .\\nChen, W., Ma, X., Wang, X., and Cohen, W. W. Pro-\\ngram of thoughts prompting: Disentangling compu-\\ntation from reasoning for numerical reasoning tasks.\\nCoRR , abs/2211.12588, 2022. doi: 10.48550/arXiv.\\n2211.12588. URL https://doi.org/10.48550/\\narXiv.2211.12588 .\\nChowdhery, A., Narang, S., Devlin, J., Bosma, M., Mishra,\\nG., Roberts, A., Barham, P., Chung, H. W., Sutton,\\nC., Gehrmann, S., Schuh, P., Shi, K., Tsvyashchenko,\\nS., Maynez, J., Rao, A., Barnes, P., Tay, Y ., Shazeer,\\nN., Prabhakaran, V ., Reif, E., Du, N., Hutchinson, B.,\\nPope, R., Bradbury, J., Austin, J., Isard, M., Gur-Ari,\\nG., Yin, P., Duke, T., Levskaya, A., Ghemawat, S., Dev,\\nS., Michalewski, H., Garcia, X., Misra, V ., Robinson,\\nK., Fedus, L., Zhou, D., Ippolito, D., Luan, D., Lim,\\nH., Zoph, B., Spiridonov, A., Sepassi, R., Dohan, D.,\\nAgrawal, S., Omernick, M., Dai, A. M., Pillai, T. S., Pel-\\nlat, M., Lewkowycz, A., Moreira, E., Child, R., Polozov,\\nO., Lee, K., Zhou, Z., Wang, X., Saeta, B., Diaz, M.,\\nFirat, O., Catasta, M., Wei, J., Meier-Hellstern, K., Eck,\\nD., Dean, J., Petrov, S., and Fiedel, N. Palm: Scaling lan-\\nguage modeling with pathways. CoRR , abs/2204.02311,\\n2022. doi: 10.48550/arXiv.2204.02311. URL https:\\n//doi.org/10.48550/arXiv.2204.02311 .\\nChung, H. W., Hou, L., Longpre, S., Zoph, B., Tay, Y .,\\nFedus, W., Li, E., Wang, X., Dehghani, M., Brahma, S.,\\nWebson, A., Gu, S. S., Dai, Z., Suzgun, M., Chen, X.,\\nChowdhery, A., Narang, S., Mishra, G., Yu, A., Zhao,\\nV . Y ., Huang, Y ., Dai, A. M., Yu, H., Petrov, S., Chi, E. H.,\\nDean, J., Devlin, J., Roberts, A., Zhou, D., Le, Q. V .,\\nand Wei, J. Scaling instruction-ﬁnetuned language mod-\\nels.CoRR , abs/2210.11416, 2022. doi: 10.48550/arXiv.2210.11416. URL https://doi.org/10.48550/\\narXiv.2210.11416 .\\nCobbe, K., Kosaraju, V ., Bavarian, M., Hilton, J., Nakano,\\nR., Hesse, C., and Schulman, J. Training veriﬁers to solve\\nmath word problems. CoRR , abs/2110.14168, 2021. URL\\nhttps://arxiv.org/abs/2110.14168 .\\nDrozdov, A., Sch ¨arli, N., Aky ¨urek, E., Scales, N., Song,\\nX., Chen, X., Bousquet, O., and Zhou, D. Compo-\\nsitional semantic parsing with large language models.\\nCoRR , abs/2209.15003, 2022. doi: 10.48550/arXiv.\\n2209.15003. URL https://doi.org/10.48550/\\narXiv.2209.15003 .\\nFu, Y ., Peng, H., Sabharwal, A., Clark, P., and Khot,\\nT. Complexity-based prompting for multi-step reason-\\ning. CoRR , abs/2210.00720, 2022. doi: 10.48550/arXiv.\\n2210.00720. URL https://doi.org/10.48550/\\narXiv.2210.00720 .\\nGao, L., Dai, Z., Pasupat, P., Chen, A., Chaganty, A. T., Fan,\\nY ., Zhao, V . Y ., Lao, N., Lee, H., Juan, D.-C., and Guu,\\nK. Rarr: Researching and revising what language models\\nsay, using language models, 2022a.\\nGao, L., Madaan, A., Zhou, S., Alon, U., Liu, P., Yang,\\nY ., Callan, J., and Neubig, G. PAL: program-aided lan-\\nguage models. CoRR , abs/2211.10435, 2022b. doi: 10.\\n48550/arXiv.2211.10435. URL https://doi.org/\\n10.48550/arXiv.2211.10435 .\\nHoltzman, A., Buys, J., Du, L., Forbes, M., and Choi, Y .\\nThe curious case of neural text degeneration. In 8th\\nInternational Conference on Learning Representations,' metadata={'page': '8.0', 'source': './2302.00618.pdf'}\n",
            "page_content='Synthetic Prompting: Generating Chain-of-Thought Demonstrations for Large\\nLanguage Models\\nZhihong Shao1 2Yeyun Gong3Yelong Shen4Minlie Huang1Nan Duan3Weizhu Chen4\\nAbstract\\nLarge language models can perform various rea-\\nsoning tasks by using chain-of-thought prompting,\\nwhich guides them to ﬁnd answers through step-\\nby-step demonstrations. However, the quality of\\nthe prompts depends on the demonstrations given\\nto the models, and creating many of them by hand\\nis costly. We introduce S YNTHETIC PROMPTING ,\\na method that leverages a few handcrafted exam-\\nples to prompt the model to generate more exam-\\nples by itself, and selects effective demonstrations\\nto elicit better reasoning. Our method alternates\\nbetween a backward and forward process to gen-\\nerate new examples. The backward process gen-\\nerates a question that match a sampled reasoning\\nchain, so that the question is solvable and clear.\\nThe forward process produces a more detailed\\nreasoning chain for the question, improving the\\nquality of the example. We evaluate our method\\non numerical, symbolic, and algorithmic reason-\\ning tasks, and show that it outperforms existing\\nprompting techniques.\\n1. Introduction\\nFew-shot demonstrations, i.e., examples of inputs and out-\\nputs for a task, can enable Large Language Models (LLMs)\\nto perform various tasks without ﬁne-tuning (Brown et al.,\\n2020; Chung et al., 2022). LLMs can further improve their\\nperformance by using chain-of-thought prompting, which\\nprovides intermediate reasoning steps for the task (Wei et al.,\\n2022b; Kojima et al., 2022). However, the LLMs’ few-shot\\nperformance depends heavily on the quality of the demon-\\nstrations, especially for reasoning tasks that need complex\\nand diverse reasoning patterns. Manually creating a large\\nand diverse set of examples for demonstration selection is\\ncostly and tedious, while relying on a limited set of demon-\\nstrations may hamper the LLMs’ generalization and adapta-\\n1Tsinghua University2This work was done during an internship\\nin MSRA3Microsoft Research Asia4Microsoft. Correspondence\\nto: Minlie Huang <aihuang@tsinghua.edu.cn >.tion to different test inputs.\\nIn this paper, we propose a novel method, S YNTHETIC\\nPROMPTING , that leverages the LLMs’ own knowledge and\\ngenerative power to augment a limited set of demonstra-\\ntions with self-synthesized examples, and then uses the aug-\\nmented set to elicit better reasoning in the LLMs. Specif-\\nically, given a few seed examples, each consisting of a\\nquestion and a chain of reasoning steps, we prompt an\\nLLM to generate more examples by alternating between\\ntwo processes: (1) the backward process, where the LLM\\nsynthesizes a question based on a self-generated reasoning\\nchain, which ensures that the question is answerable and\\nwell-deﬁned; and (2) the forward process, where the LLM\\nproduces a reasoning chain for the synthesized question,\\nwhich reﬁnes the reasoning chain to be more precise and\\nconsistent with the question. We repeat this process until\\nwe obtain enough synthetic examples. To select the most\\neffective demonstrations from the augmented set, we pro-\\npose a new selection scheme based on in-cluster complexity,\\nwhich aims to maximize the diversity and informativeness\\nof the demonstrations by clustering them and choosing the\\nmost complex one (the one with the longest reasoning chain)\\nfrom each cluster. Finally, we prompt the LLM with the\\nselected demonstrations to generate a reasoning chain for a\\ntest question and then use it to obtain the answer.\\nWe evaluate our method on various reasoning tasks, in-\\ncluding numerical reasoning, algorithmic reasoning, and\\nsymbolic reasoning. Following previous few-shot settings\\n(Wang et al., 2022b; Suzgun et al., 2022), we demonstrate\\nthat our method can signiﬁcantly improve the LLMs’ per-\\nformance, achieving up to 15.6% absolute gains over the\\nstate-of-the-art methods.\\nOur main contributions are:\\n•We introduce S YNTHETIC PROMPTING , a novel\\nmethod that augments a limited set of demonstrations' metadata={'page': '0.0', 'source': './2302.00618.pdf'}\n",
            "page_content='Synthetic Prompting: Generating Chain-of-Thought Demonstrations for Large Language Models\\nDatasets Example\\nGSM8K Patrick has three glue sticks that are partially used. One has 1/6 left, the second has 2/3 left and\\nthe third one has 1/2 left. If a glue stick is 12 millimeters long originally, what is the total length\\nof the glue sticks that are not used?\\nColored Objects On the nightstand, you see several items arranged in a row: a blue crayon, a red notebook, a teal\\nbracelet, a magenta sheet of paper, a silver dog leash, and a black booklet. What is the color of the\\nitem furthest from the dog leash?\\nRepeat Copy Repeat election to the council three times, but after every other word say cool\\nTable 1: Examples from three datasets. Questions in the other numerical reasoning datasets resemble those in GSM8K.\\nFollowing these settings, we assumed access to 2 or 4 ran-\\ndom examples from each dataset by default. For numerical\\nreasoning tasks, we also experimented with the 8 examples\\nthat were manually crafted by Wei et al. (2022b) and were\\nadopted by several following papers (Fu et al., 2022; Wang\\net al., 2022a; Gao et al., 2022b). We also used the P AL-style\\nreasoning chains annotated by Gao et al. (2022b).\\nPrompting baselines without synthesis use all provided gold\\nexamples to construct prompts for inference. S YNTHETIC\\nPROMPTING and its variants synthesize examples using the\\nprovided examples, and select 8 synthetic demonstrations\\nbased on in-cluster complexity, unless stated otherwise.\\nSeed examples and synthetic prompts are provided in the\\nSupplementary Materials.\\n4.3. Baselines\\nDirect Prompting Direct prompting (Brown et al., 2020)\\nprompts LLMs to directly generate answers with demonstra-\\ntions of input-answer pairs.\\nCoT Prompting Chain-of-thought prompting (Wei et al.,\\n2022b) is effective in eliciting reasoning in LLMs, which\\nprompts LLMs to generate natural language reasoning steps\\nfollowed by an answer.\\nPAL Prompting PAL prompting (Gao et al., 2022b), a vari-\\nant of chain-of-thought prompting, improves reasoning with\\nstructured code. Figure 1 (right) provides two examples. It\\ndoes not prompt LLMs to include ﬁnal answers into com-\\npletions; answers are obtained by executing the code. This\\nprompting technique has achieved state-of-the-art results on\\nnumerous reasoning tasks.\\nVanilla S YNTHETIC PROMPTING This is a variant of\\nSYNTHETIC PROMPTING , which differs in that prompts\\nused for question synthesis only consist of questions from\\nseed examples. In other words, new questions are syn-\\nthesized by mimicking seed questions, without any other\\ncondition.4.4. Implementation Details\\nWe adopted P AL-style reasoning chains which are structured\\ncode with comments being natural language reasoning step.\\ntext-davinci-003 version of InstructGPT (Ouyang\\net al., 2022) was used as our backend LLM for both syn-\\nthesis and inference. We used top-p sampling (Holtzman\\net al., 2020) for synthesis with temperature set to 0.7, and\\nused greedy decoding for inference with temperature set to\\n0. All numerical reasoning datasets share one set of seed\\nexamples either randomly sampled from GSM8K (when\\nthe number of seeds is 2 or 4) or from Wei et al. (2022b)\\n(when the number of seeds is 8). For datasets of the other\\ntasks, seeds were randomly sampled from their own datasets.\\nWe annotated seed examples with both CoT-style reasoning\\nchains and P AL-style reasoning chains manually, following\\ntheir annotation protocols. Annotations are provided in the\\nSupplementary Materials. For each set of seed examples, we\\nsynthesized more examples by repeating backward-forward\\nsynthesis for 1,000 times. Target complexities range from\\nthe lowest complexity of seed examples to the highest one\\nplusc;cwas set to 4 for numerical reasoning and 2 on the\\nother datasets. In forward synthesis, the number of reason-\\ning chains sampled for each question was 3. The encoder\\nused for clustering was all-mpnet-base-v2 .\\n4.5. Main Results\\nAs shown by Table 2, S YNTHETIC PROMPTING consistently' metadata={'page': '4.0', 'source': './2302.00618.pdf'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(docs[0])"
      ],
      "metadata": {
        "id": "TCOdz30sdvAj",
        "outputId": "0ffd6e15-3648-45c9-f724-a6754371a810",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "page_content='Synthetic Prompting: Generating Chain-of-Thought Demonstrations for Large Language Models\\nAssociation for Computational Linguistics: Human Lan-\\nguage Technologies, NAACL 2022, Seattle, WA, United\\nStates, July 10-15, 2022 , pp. 5168–5186. Association\\nfor Computational Linguistics, 2022. doi: 10.18653/v1/\\n2022.naacl-main.380. URL https://doi.org/10.\\n18653/v1/2022.naacl-main.380 .\\nSuzgun, M., Scales, N., Sch ¨arli, N., Gehrmann, S., Tay, Y .,\\nChung, H. W., Chowdhery, A., Le, Q. V ., Chi, E. H., Zhou,\\nD., and Wei, J. Challenging big-bench tasks and whether\\nchain-of-thought can solve them. CoRR , abs/2210.09261,\\n2022. doi: 10.48550/arXiv.2210.09261. URL https:\\n//doi.org/10.48550/arXiv.2210.09261 .\\nThoppilan, R., Freitas, D. D., Hall, J., Shazeer, N., Kul-\\nshreshtha, A., Cheng, H., Jin, A., Bos, T., Baker, L., Du,\\nY ., Li, Y ., Lee, H., Zheng, H. S., Ghafouri, A., Mene-\\ngali, M., Huang, Y ., Krikun, M., Lepikhin, D., Qin, J.,\\nChen, D., Xu, Y ., Chen, Z., Roberts, A., Bosma, M.,\\nZhou, Y ., Chang, C., Krivokon, I., Rusch, W., Pickett,\\nM., Meier-Hellstern, K. S., Morris, M. R., Doshi, T.,\\nSantos, R. D., Duke, T., Soraker, J., Zevenbergen, B.,\\nPrabhakaran, V ., Diaz, M., Hutchinson, B., Olson, K.,\\nMolina, A., Hoffman-John, E., Lee, J., Aroyo, L., Ra-\\njakumar, R., Butryna, A., Lamm, M., Kuzmina, V ., Fen-\\nton, J., Cohen, A., Bernstein, R., Kurzweil, R., Aguera-\\nArcas, B., Cui, C., Croak, M., Chi, E. H., and Le, Q.\\nLamda: Language models for dialog applications. CoRR ,\\nabs/2201.08239, 2022. URL https://arxiv.org/\\nabs/2201.08239 .\\nWang, X., Wei, J., Schuurmans, D., Le, Q. V ., Chi, E. H.,\\nand Zhou, D. Self-consistency improves chain of thought\\nreasoning in language models. CoRR , abs/2203.11171,\\n2022a. doi: 10.48550/arXiv.2203.11171. URL https:\\n//doi.org/10.48550/arXiv.2203.11171 .\\nWang, Y ., Mishra, S., Alipoormolabashi, P., Kordi, Y .,\\nMirzaei, A., Arunkumar, A., Ashok, A., Dhanasekaran,\\nA. S., Naik, A., Stap, D., Pathak, E., Karamanolakis, G.,\\nLai, H. G., Purohit, I., Mondal, I., Anderson, J., Kuznia,\\nK., Doshi, K., Patel, M., Pal, K. K., Moradshahi, M., Par-\\nmar, M., Purohit, M., Varshney, N., Kaza, P. R., Verma,\\nP., Puri, R. S., Karia, R., Sampat, S. K., Doshi, S., Mishra,\\nS., Reddy, S., Patro, S., Dixit, T., Shen, X., Baral, C.,\\nChoi, Y ., Smith, N. A., Hajishirzi, H., and Khashabi, D.\\nSuper-naturalinstructions: Generalization via declarative\\ninstructions on 1600+ nlp tasks, 2022b.\\nWei, J., Bosma, M., Zhao, V . Y ., Guu, K., Yu, A. W., Lester,\\nB., Du, N., Dai, A. M., and Le, Q. V . Finetuned language\\nmodels are zero-shot learners. In The Tenth Interna-\\ntional Conference on Learning Representations, ICLR\\n2022, Virtual Event, April 25-29, 2022 . OpenReview.net,\\n2022a. URL https://openreview.net/forum?\\nid=gEZrGCozdqR .Wei, J., Wang, X., Schuurmans, D., Bosma, M., Chi,\\nE. H., Le, Q., and Zhou, D. Chain of thought prompt-\\ning elicits reasoning in large language models. CoRR ,\\nabs/2201.11903, 2022b. URL https://arxiv.org/\\nabs/2201.11903 .\\nWest, P., Bhagavatula, C., Hessel, J., Hwang, J. D., Jiang, L.,\\nBras, R. L., Lu, X., Welleck, S., and Choi, Y . Symbolic\\nknowledge distillation: from general language models\\nto commonsense models. In Carpuat, M., de Marneffe,\\nM., and Ru ´ız, I. V . M. (eds.), Proceedings of the 2022\\nConference of the North American Chapter of the As-\\nsociation for Computational Linguistics: Human Lan-\\nguage Technologies, NAACL 2022, Seattle, WA, United\\nStates, July 10-15, 2022 , pp. 4602–4625. Association\\nfor Computational Linguistics, 2022. doi: 10.18653/v1/\\n2022.naacl-main.341. URL https://doi.org/10.\\n18653/v1/2022.naacl-main.341 .\\nYang, K., Klein, D., Peng, N., and Tian, Y . DOC: im-\\nproving long story coherence with detailed outline con-\\ntrol. CoRR , abs/2212.10077, 2022. doi: 10.48550/arXiv.\\n2212.10077. URL https://doi.org/10.48550/\\narXiv.2212.10077 .\\nYe, J., Gao, J., Li, Q., Xu, H., Feng, J., Wu, Z., Yu, T.,\\nand Kong, L. Zerogen: Efﬁcient zero-shot learning via\\ndataset generation. CoRR , abs/2202.07922, 2022a. URL' metadata={'page': '10.0', 'source': './2302.00618.pdf'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Agent"
      ],
      "metadata": {
        "id": "Ba7nukJTeCnU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "retriever = docsearch.as_retriever(search_kwargs={\"k\":2})"
      ],
      "metadata": {
        "id": "3Cf1V6q3eE-G"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from langchain.agents.agent_toolkits import create_retriever_tool, create_conversational_retrieval_agent\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.callbacks import StreamlitCallbackHandler\n",
        "from langchain.schema import BaseRetriever, Document, SystemMessage"
      ],
      "metadata": {
        "id": "dgVtEjZEe1mI"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def create_chatbot_with_retriever(retriever):\n",
        "    llm = ChatOpenAI(temperature=0, streaming=True)\n",
        "    embedding = OpenAIEmbeddings()\n",
        "\n",
        "    retriever_tool = create_retriever_tool(\n",
        "        retriever, \"this_retrevier\", \"Useful when searching for the information about technologies\")\n",
        "    system_message = \"\"\"\n",
        "    You must use the this_retreiver.\n",
        "    \"\"\"\n",
        "    system_message = f\"{system_message} All the responses should be in Japanese language.\"\n",
        "    message = SystemMessage(content=system_message)\n",
        "    agent_executor = create_conversational_retrieval_agent(\n",
        "        llm=llm, tools=[retriever_tool], system_message=message, verbose=True, max_tokens_limit=500)\n",
        "    return agent_executor"
      ],
      "metadata": {
        "id": "M5flDOxIeOHT"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import langchain\n",
        "langchain.verbose = True"
      ],
      "metadata": {
        "id": "CYtpk9q-53D9"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chatbot = create_chatbot_with_retriever(retriever)"
      ],
      "metadata": {
        "id": "5Lq42CyifdOy"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "prompt = \"チェインオブソートはいつ誕生した\"\n",
        "result = chatbot.invoke({\n",
        "            \"input\": prompt})\n",
        "print(result[\"output\"])"
      ],
      "metadata": {
        "id": "eRvLgozxfrEg",
        "outputId": "a5e72f75-1617-4490-e1f1-385ab5b3578b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `this_retrevier` with `チェインオブソート`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m[Document(page_content='Synthetic Prompting: Generating Chain-of-Thought Demonstrations for Large Language Models\\nAssociation for Computational Linguistics: Human Lan-\\nguage Technologies, NAACL 2022, Seattle, WA, United\\nStates, July 10-15, 2022 , pp. 5168–5186. Association\\nfor Computational Linguistics, 2022. doi: 10.18653/v1/\\n2022.naacl-main.380. URL https://doi.org/10.\\n18653/v1/2022.naacl-main.380 .\\nSuzgun, M., Scales, N., Sch ¨arli, N., Gehrmann, S., Tay, Y .,\\nChung, H. W., Chowdhery, A., Le, Q. V ., Chi, E. H., Zhou,\\nD., and Wei, J. Challenging big-bench tasks and whether\\nchain-of-thought can solve them. CoRR , abs/2210.09261,\\n2022. doi: 10.48550/arXiv.2210.09261. URL https:\\n//doi.org/10.48550/arXiv.2210.09261 .\\nThoppilan, R., Freitas, D. D., Hall, J., Shazeer, N., Kul-\\nshreshtha, A., Cheng, H., Jin, A., Bos, T., Baker, L., Du,\\nY ., Li, Y ., Lee, H., Zheng, H. S., Ghafouri, A., Mene-\\ngali, M., Huang, Y ., Krikun, M., Lepikhin, D., Qin, J.,\\nChen, D., Xu, Y ., Chen, Z., Roberts, A., Bosma, M.,\\nZhou, Y ., Chang, C., Krivokon, I., Rusch, W., Pickett,\\nM., Meier-Hellstern, K. S., Morris, M. R., Doshi, T.,\\nSantos, R. D., Duke, T., Soraker, J., Zevenbergen, B.,\\nPrabhakaran, V ., Diaz, M., Hutchinson, B., Olson, K.,\\nMolina, A., Hoffman-John, E., Lee, J., Aroyo, L., Ra-\\njakumar, R., Butryna, A., Lamm, M., Kuzmina, V ., Fen-\\nton, J., Cohen, A., Bernstein, R., Kurzweil, R., Aguera-\\nArcas, B., Cui, C., Croak, M., Chi, E. H., and Le, Q.\\nLamda: Language models for dialog applications. CoRR ,\\nabs/2201.08239, 2022. URL https://arxiv.org/\\nabs/2201.08239 .\\nWang, X., Wei, J., Schuurmans, D., Le, Q. V ., Chi, E. H.,\\nand Zhou, D. Self-consistency improves chain of thought\\nreasoning in language models. CoRR , abs/2203.11171,\\n2022a. doi: 10.48550/arXiv.2203.11171. URL https:\\n//doi.org/10.48550/arXiv.2203.11171 .\\nWang, Y ., Mishra, S., Alipoormolabashi, P., Kordi, Y .,\\nMirzaei, A., Arunkumar, A., Ashok, A., Dhanasekaran,\\nA. S., Naik, A., Stap, D., Pathak, E., Karamanolakis, G.,\\nLai, H. G., Purohit, I., Mondal, I., Anderson, J., Kuznia,\\nK., Doshi, K., Patel, M., Pal, K. K., Moradshahi, M., Par-\\nmar, M., Purohit, M., Varshney, N., Kaza, P. R., Verma,\\nP., Puri, R. S., Karia, R., Sampat, S. K., Doshi, S., Mishra,\\nS., Reddy, S., Patro, S., Dixit, T., Shen, X., Baral, C.,\\nChoi, Y ., Smith, N. A., Hajishirzi, H., and Khashabi, D.\\nSuper-naturalinstructions: Generalization via declarative\\ninstructions on 1600+ nlp tasks, 2022b.\\nWei, J., Bosma, M., Zhao, V . Y ., Guu, K., Yu, A. W., Lester,\\nB., Du, N., Dai, A. M., and Le, Q. V . Finetuned language\\nmodels are zero-shot learners. In The Tenth Interna-\\ntional Conference on Learning Representations, ICLR\\n2022, Virtual Event, April 25-29, 2022 . OpenReview.net,\\n2022a. URL https://openreview.net/forum?\\nid=gEZrGCozdqR .Wei, J., Wang, X., Schuurmans, D., Bosma, M., Chi,\\nE. H., Le, Q., and Zhou, D. Chain of thought prompt-\\ning elicits reasoning in large language models. CoRR ,\\nabs/2201.11903, 2022b. URL https://arxiv.org/\\nabs/2201.11903 .\\nWest, P., Bhagavatula, C., Hessel, J., Hwang, J. D., Jiang, L.,\\nBras, R. L., Lu, X., Welleck, S., and Choi, Y . Symbolic\\nknowledge distillation: from general language models\\nto commonsense models. In Carpuat, M., de Marneffe,\\nM., and Ru ´ız, I. V . M. (eds.), Proceedings of the 2022\\nConference of the North American Chapter of the As-\\nsociation for Computational Linguistics: Human Lan-\\nguage Technologies, NAACL 2022, Seattle, WA, United\\nStates, July 10-15, 2022 , pp. 4602–4625. Association\\nfor Computational Linguistics, 2022. doi: 10.18653/v1/\\n2022.naacl-main.341. URL https://doi.org/10.\\n18653/v1/2022.naacl-main.341 .\\nYang, K., Klein, D., Peng, N., and Tian, Y . DOC: im-\\nproving long story coherence with detailed outline con-\\ntrol. CoRR , abs/2212.10077, 2022. doi: 10.48550/arXiv.\\n2212.10077. URL https://doi.org/10.48550/\\narXiv.2212.10077 .\\nYe, J., Gao, J., Li, Q., Xu, H., Feng, J., Wu, Z., Yu, T.,\\nand Kong, L. Zerogen: Efﬁcient zero-shot learning via\\ndataset generation. CoRR , abs/2202.07922, 2022a. URL', metadata={'page': '10.0', 'source': './2302.00618.pdf'}), Document(page_content='Synthetic Prompting: Generating Chain-of-Thought Demonstrations for Large Language Models\\nDatasets Example\\nGSM8K Patrick has three glue sticks that are partially used. One has 1/6 left, the second has 2/3 left and\\nthe third one has 1/2 left. If a glue stick is 12 millimeters long originally, what is the total length\\nof the glue sticks that are not used?\\nColored Objects On the nightstand, you see several items arranged in a row: a blue crayon, a red notebook, a teal\\nbracelet, a magenta sheet of paper, a silver dog leash, and a black booklet. What is the color of the\\nitem furthest from the dog leash?\\nRepeat Copy Repeat election to the council three times, but after every other word say cool\\nTable 1: Examples from three datasets. Questions in the other numerical reasoning datasets resemble those in GSM8K.\\nFollowing these settings, we assumed access to 2 or 4 ran-\\ndom examples from each dataset by default. For numerical\\nreasoning tasks, we also experimented with the 8 examples\\nthat were manually crafted by Wei et al. (2022b) and were\\nadopted by several following papers (Fu et al., 2022; Wang\\net al., 2022a; Gao et al., 2022b). We also used the P AL-style\\nreasoning chains annotated by Gao et al. (2022b).\\nPrompting baselines without synthesis use all provided gold\\nexamples to construct prompts for inference. S YNTHETIC\\nPROMPTING and its variants synthesize examples using the\\nprovided examples, and select 8 synthetic demonstrations\\nbased on in-cluster complexity, unless stated otherwise.\\nSeed examples and synthetic prompts are provided in the\\nSupplementary Materials.\\n4.3. Baselines\\nDirect Prompting Direct prompting (Brown et al., 2020)\\nprompts LLMs to directly generate answers with demonstra-\\ntions of input-answer pairs.\\nCoT Prompting Chain-of-thought prompting (Wei et al.,\\n2022b) is effective in eliciting reasoning in LLMs, which\\nprompts LLMs to generate natural language reasoning steps\\nfollowed by an answer.\\nPAL Prompting PAL prompting (Gao et al., 2022b), a vari-\\nant of chain-of-thought prompting, improves reasoning with\\nstructured code. Figure 1 (right) provides two examples. It\\ndoes not prompt LLMs to include ﬁnal answers into com-\\npletions; answers are obtained by executing the code. This\\nprompting technique has achieved state-of-the-art results on\\nnumerous reasoning tasks.\\nVanilla S YNTHETIC PROMPTING This is a variant of\\nSYNTHETIC PROMPTING , which differs in that prompts\\nused for question synthesis only consist of questions from\\nseed examples. In other words, new questions are syn-\\nthesized by mimicking seed questions, without any other\\ncondition.4.4. Implementation Details\\nWe adopted P AL-style reasoning chains which are structured\\ncode with comments being natural language reasoning step.\\ntext-davinci-003 version of InstructGPT (Ouyang\\net al., 2022) was used as our backend LLM for both syn-\\nthesis and inference. We used top-p sampling (Holtzman\\net al., 2020) for synthesis with temperature set to 0.7, and\\nused greedy decoding for inference with temperature set to\\n0. All numerical reasoning datasets share one set of seed\\nexamples either randomly sampled from GSM8K (when\\nthe number of seeds is 2 or 4) or from Wei et al. (2022b)\\n(when the number of seeds is 8). For datasets of the other\\ntasks, seeds were randomly sampled from their own datasets.\\nWe annotated seed examples with both CoT-style reasoning\\nchains and P AL-style reasoning chains manually, following\\ntheir annotation protocols. Annotations are provided in the\\nSupplementary Materials. For each set of seed examples, we\\nsynthesized more examples by repeating backward-forward\\nsynthesis for 1,000 times. Target complexities range from\\nthe lowest complexity of seed examples to the highest one\\nplusc;cwas set to 4 for numerical reasoning and 2 on the\\nother datasets. In forward synthesis, the number of reason-\\ning chains sampled for each question was 3. The encoder\\nused for clustering was all-mpnet-base-v2 .\\n4.5. Main Results\\nAs shown by Table 2, S YNTHETIC PROMPTING consistently', metadata={'page': '4.0', 'source': './2302.00618.pdf'})]\u001b[0m\u001b[32;1m\u001b[1;3mチェインオブソートの誕生に関する情報は見つかりませんでした。申し訳ありませんが、他のトピックについてお手伝いできることがあれば教えてください。\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "チェインオブソートの誕生に関する情報は見つかりませんでした。申し訳ありませんが、他のトピックについてお手伝いできることがあれば教えてください。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"'Chain-of-Thought'について説明して\"\n",
        "result = chatbot.invoke({\n",
        "            \"input\": prompt})\n",
        "print(result[\"output\"])"
      ],
      "metadata": {
        "id": "f1NyvFzqjoNv",
        "outputId": "ee8383fc-97ba-4407-8b16-747c00df970a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `this_retrevier` with `Chain-of-Thought`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m[Document(page_content='Synthetic Prompting: Generating Chain-of-Thought Demonstrations for Large Language Models\\nAssociation for Computational Linguistics: Human Lan-\\nguage Technologies, NAACL 2022, Seattle, WA, United\\nStates, July 10-15, 2022 , pp. 5168–5186. Association\\nfor Computational Linguistics, 2022. doi: 10.18653/v1/\\n2022.naacl-main.380. URL https://doi.org/10.\\n18653/v1/2022.naacl-main.380 .\\nSuzgun, M., Scales, N., Sch ¨arli, N., Gehrmann, S., Tay, Y .,\\nChung, H. W., Chowdhery, A., Le, Q. V ., Chi, E. H., Zhou,\\nD., and Wei, J. Challenging big-bench tasks and whether\\nchain-of-thought can solve them. CoRR , abs/2210.09261,\\n2022. doi: 10.48550/arXiv.2210.09261. URL https:\\n//doi.org/10.48550/arXiv.2210.09261 .\\nThoppilan, R., Freitas, D. D., Hall, J., Shazeer, N., Kul-\\nshreshtha, A., Cheng, H., Jin, A., Bos, T., Baker, L., Du,\\nY ., Li, Y ., Lee, H., Zheng, H. S., Ghafouri, A., Mene-\\ngali, M., Huang, Y ., Krikun, M., Lepikhin, D., Qin, J.,\\nChen, D., Xu, Y ., Chen, Z., Roberts, A., Bosma, M.,\\nZhou, Y ., Chang, C., Krivokon, I., Rusch, W., Pickett,\\nM., Meier-Hellstern, K. S., Morris, M. R., Doshi, T.,\\nSantos, R. D., Duke, T., Soraker, J., Zevenbergen, B.,\\nPrabhakaran, V ., Diaz, M., Hutchinson, B., Olson, K.,\\nMolina, A., Hoffman-John, E., Lee, J., Aroyo, L., Ra-\\njakumar, R., Butryna, A., Lamm, M., Kuzmina, V ., Fen-\\nton, J., Cohen, A., Bernstein, R., Kurzweil, R., Aguera-\\nArcas, B., Cui, C., Croak, M., Chi, E. H., and Le, Q.\\nLamda: Language models for dialog applications. CoRR ,\\nabs/2201.08239, 2022. URL https://arxiv.org/\\nabs/2201.08239 .\\nWang, X., Wei, J., Schuurmans, D., Le, Q. V ., Chi, E. H.,\\nand Zhou, D. Self-consistency improves chain of thought\\nreasoning in language models. CoRR , abs/2203.11171,\\n2022a. doi: 10.48550/arXiv.2203.11171. URL https:\\n//doi.org/10.48550/arXiv.2203.11171 .\\nWang, Y ., Mishra, S., Alipoormolabashi, P., Kordi, Y .,\\nMirzaei, A., Arunkumar, A., Ashok, A., Dhanasekaran,\\nA. S., Naik, A., Stap, D., Pathak, E., Karamanolakis, G.,\\nLai, H. G., Purohit, I., Mondal, I., Anderson, J., Kuznia,\\nK., Doshi, K., Patel, M., Pal, K. K., Moradshahi, M., Par-\\nmar, M., Purohit, M., Varshney, N., Kaza, P. R., Verma,\\nP., Puri, R. S., Karia, R., Sampat, S. K., Doshi, S., Mishra,\\nS., Reddy, S., Patro, S., Dixit, T., Shen, X., Baral, C.,\\nChoi, Y ., Smith, N. A., Hajishirzi, H., and Khashabi, D.\\nSuper-naturalinstructions: Generalization via declarative\\ninstructions on 1600+ nlp tasks, 2022b.\\nWei, J., Bosma, M., Zhao, V . Y ., Guu, K., Yu, A. W., Lester,\\nB., Du, N., Dai, A. M., and Le, Q. V . Finetuned language\\nmodels are zero-shot learners. In The Tenth Interna-\\ntional Conference on Learning Representations, ICLR\\n2022, Virtual Event, April 25-29, 2022 . OpenReview.net,\\n2022a. URL https://openreview.net/forum?\\nid=gEZrGCozdqR .Wei, J., Wang, X., Schuurmans, D., Bosma, M., Chi,\\nE. H., Le, Q., and Zhou, D. Chain of thought prompt-\\ning elicits reasoning in large language models. CoRR ,\\nabs/2201.11903, 2022b. URL https://arxiv.org/\\nabs/2201.11903 .\\nWest, P., Bhagavatula, C., Hessel, J., Hwang, J. D., Jiang, L.,\\nBras, R. L., Lu, X., Welleck, S., and Choi, Y . Symbolic\\nknowledge distillation: from general language models\\nto commonsense models. In Carpuat, M., de Marneffe,\\nM., and Ru ´ız, I. V . M. (eds.), Proceedings of the 2022\\nConference of the North American Chapter of the As-\\nsociation for Computational Linguistics: Human Lan-\\nguage Technologies, NAACL 2022, Seattle, WA, United\\nStates, July 10-15, 2022 , pp. 4602–4625. Association\\nfor Computational Linguistics, 2022. doi: 10.18653/v1/\\n2022.naacl-main.341. URL https://doi.org/10.\\n18653/v1/2022.naacl-main.341 .\\nYang, K., Klein, D., Peng, N., and Tian, Y . DOC: im-\\nproving long story coherence with detailed outline con-\\ntrol. CoRR , abs/2212.10077, 2022. doi: 10.48550/arXiv.\\n2212.10077. URL https://doi.org/10.48550/\\narXiv.2212.10077 .\\nYe, J., Gao, J., Li, Q., Xu, H., Feng, J., Wu, Z., Yu, T.,\\nand Kong, L. Zerogen: Efﬁcient zero-shot learning via\\ndataset generation. CoRR , abs/2202.07922, 2022a. URL', metadata={'page': '10.0', 'source': './2302.00618.pdf'}), Document(page_content='Synthetic Prompting: Generating Chain-of-Thought Demonstrations for Large Language Models\\nprompting.\\nReferences\\nBrown, T. B., Mann, B., Ryder, N., Subbiah, M., Kaplan,\\nJ., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G.,\\nAskell, A., Agarwal, S., Herbert-V oss, A., Krueger, G.,\\nHenighan, T., Child, R., Ramesh, A., Ziegler, D. M., Wu,\\nJ., Winter, C., Hesse, C., Chen, M., Sigler, E., Litwin, M.,\\nGray, S., Chess, B., Clark, J., Berner, C., McCandlish, S.,\\nRadford, A., Sutskever, I., and Amodei, D. Language\\nmodels are few-shot learners. In Larochelle, H.,\\nRanzato, M., Hadsell, R., Balcan, M., and Lin, H. (eds.),\\nAdvances in Neural Information Processing Systems 33:\\nAnnual Conference on Neural Information Processing\\nSystems 2020, NeurIPS 2020, December 6-12, 2020,\\nvirtual , 2020. URL https://proceedings.\\nneurips.cc/paper/2020/hash/\\n1457c0d6bfcb4967418bfb8ac142f64a-Abstract.\\nhtml .\\nChen, W., Ma, X., Wang, X., and Cohen, W. W. Pro-\\ngram of thoughts prompting: Disentangling compu-\\ntation from reasoning for numerical reasoning tasks.\\nCoRR , abs/2211.12588, 2022. doi: 10.48550/arXiv.\\n2211.12588. URL https://doi.org/10.48550/\\narXiv.2211.12588 .\\nChowdhery, A., Narang, S., Devlin, J., Bosma, M., Mishra,\\nG., Roberts, A., Barham, P., Chung, H. W., Sutton,\\nC., Gehrmann, S., Schuh, P., Shi, K., Tsvyashchenko,\\nS., Maynez, J., Rao, A., Barnes, P., Tay, Y ., Shazeer,\\nN., Prabhakaran, V ., Reif, E., Du, N., Hutchinson, B.,\\nPope, R., Bradbury, J., Austin, J., Isard, M., Gur-Ari,\\nG., Yin, P., Duke, T., Levskaya, A., Ghemawat, S., Dev,\\nS., Michalewski, H., Garcia, X., Misra, V ., Robinson,\\nK., Fedus, L., Zhou, D., Ippolito, D., Luan, D., Lim,\\nH., Zoph, B., Spiridonov, A., Sepassi, R., Dohan, D.,\\nAgrawal, S., Omernick, M., Dai, A. M., Pillai, T. S., Pel-\\nlat, M., Lewkowycz, A., Moreira, E., Child, R., Polozov,\\nO., Lee, K., Zhou, Z., Wang, X., Saeta, B., Diaz, M.,\\nFirat, O., Catasta, M., Wei, J., Meier-Hellstern, K., Eck,\\nD., Dean, J., Petrov, S., and Fiedel, N. Palm: Scaling lan-\\nguage modeling with pathways. CoRR , abs/2204.02311,\\n2022. doi: 10.48550/arXiv.2204.02311. URL https:\\n//doi.org/10.48550/arXiv.2204.02311 .\\nChung, H. W., Hou, L., Longpre, S., Zoph, B., Tay, Y .,\\nFedus, W., Li, E., Wang, X., Dehghani, M., Brahma, S.,\\nWebson, A., Gu, S. S., Dai, Z., Suzgun, M., Chen, X.,\\nChowdhery, A., Narang, S., Mishra, G., Yu, A., Zhao,\\nV . Y ., Huang, Y ., Dai, A. M., Yu, H., Petrov, S., Chi, E. H.,\\nDean, J., Devlin, J., Roberts, A., Zhou, D., Le, Q. V .,\\nand Wei, J. Scaling instruction-ﬁnetuned language mod-\\nels.CoRR , abs/2210.11416, 2022. doi: 10.48550/arXiv.2210.11416. URL https://doi.org/10.48550/\\narXiv.2210.11416 .\\nCobbe, K., Kosaraju, V ., Bavarian, M., Hilton, J., Nakano,\\nR., Hesse, C., and Schulman, J. Training veriﬁers to solve\\nmath word problems. CoRR , abs/2110.14168, 2021. URL\\nhttps://arxiv.org/abs/2110.14168 .\\nDrozdov, A., Sch ¨arli, N., Aky ¨urek, E., Scales, N., Song,\\nX., Chen, X., Bousquet, O., and Zhou, D. Compo-\\nsitional semantic parsing with large language models.\\nCoRR , abs/2209.15003, 2022. doi: 10.48550/arXiv.\\n2209.15003. URL https://doi.org/10.48550/\\narXiv.2209.15003 .\\nFu, Y ., Peng, H., Sabharwal, A., Clark, P., and Khot,\\nT. Complexity-based prompting for multi-step reason-\\ning. CoRR , abs/2210.00720, 2022. doi: 10.48550/arXiv.\\n2210.00720. URL https://doi.org/10.48550/\\narXiv.2210.00720 .\\nGao, L., Dai, Z., Pasupat, P., Chen, A., Chaganty, A. T., Fan,\\nY ., Zhao, V . Y ., Lao, N., Lee, H., Juan, D.-C., and Guu,\\nK. Rarr: Researching and revising what language models\\nsay, using language models, 2022a.\\nGao, L., Madaan, A., Zhou, S., Alon, U., Liu, P., Yang,\\nY ., Callan, J., and Neubig, G. PAL: program-aided lan-\\nguage models. CoRR , abs/2211.10435, 2022b. doi: 10.\\n48550/arXiv.2211.10435. URL https://doi.org/\\n10.48550/arXiv.2211.10435 .\\nHoltzman, A., Buys, J., Du, L., Forbes, M., and Choi, Y .\\nThe curious case of neural text degeneration. In 8th\\nInternational Conference on Learning Representations,', metadata={'page': '8.0', 'source': './2302.00618.pdf'})]\u001b[0m\u001b[32;1m\u001b[1;3m『Chain-of-Thought』に関する情報を見つけました。以下は関連する文献の一部です。\n",
            "\n",
            "1. \"Synthetic Prompting: Generating Chain-of-Thought Demonstrations for Large Language Models\" - この論文では、大規模な言語モデルに対してChain-of-Thoughtデモンストレーションを生成する方法について説明されています。\n",
            "\n",
            "2. \"Challenging big-bench tasks and whether chain-of-thought can solve them\" - この論文では、Chain-of-Thoughtが大規模なタスクを解決することができるかどうかについて検討されています。\n",
            "\n",
            "3. \"Lamda: Language models for dialog applications\" - この論文では、対話アプリケーションのための言語モデルについて説明されています。\n",
            "\n",
            "4. \"Self-consistency improves chain of thought reasoning in language models\" - この論文では、自己整合性が言語モデルのChain-of-Thought推論を改善する方法について説明されています。\n",
            "\n",
            "これらの文献は、『Chain-of-Thought』に関する詳細な情報を提供しています。\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "『Chain-of-Thought』に関する情報を見つけました。以下は関連する文献の一部です。\n",
            "\n",
            "1. \"Synthetic Prompting: Generating Chain-of-Thought Demonstrations for Large Language Models\" - この論文では、大規模な言語モデルに対してChain-of-Thoughtデモンストレーションを生成する方法について説明されています。\n",
            "\n",
            "2. \"Challenging big-bench tasks and whether chain-of-thought can solve them\" - この論文では、Chain-of-Thoughtが大規模なタスクを解決することができるかどうかについて検討されています。\n",
            "\n",
            "3. \"Lamda: Language models for dialog applications\" - この論文では、対話アプリケーションのための言語モデルについて説明されています。\n",
            "\n",
            "4. \"Self-consistency improves chain of thought reasoning in language models\" - この論文では、自己整合性が言語モデルのChain-of-Thought推論を改善する方法について説明されています。\n",
            "\n",
            "これらの文献は、『Chain-of-Thought』に関する詳細な情報を提供しています。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_chatbot_with_retriever(vector_store):\n",
        "    llm = ChatOpenAI(temperature=0, streaming=True)\n",
        "    embedding = OpenAIEmbeddings()\n",
        "\n",
        "    retriever = docsearch.as_retriever(search_kwargs={\"k\":10})\n",
        "\n",
        "    retriever_tool = create_retriever_tool(\n",
        "        retriever, \"this_retrevier\", \"Useful when searching for the information about technologies\")\n",
        "    system_message = \"\"\"\n",
        "    You must use the this_retreiver.\n",
        "    \"\"\"\n",
        "    system_message = f\"{system_message} All the responses should be in Japanese language.\"\n",
        "    message = SystemMessage(content=system_message)\n",
        "    agent_executor = create_conversational_retrieval_agent(\n",
        "        llm=llm, tools=[retriever_tool], system_message=message, verbose=True, max_tokens_limit=500)\n",
        "    return agent_executor"
      ],
      "metadata": {
        "id": "zUNyE3AP8hE7"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chatbot = create_chatbot_with_retriever(docsearch)"
      ],
      "metadata": {
        "id": "Fkfq2kVa8wVD"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"'Chain-of-Thought'について説明して\"\n",
        "result = chatbot.invoke({\n",
        "            \"input\": prompt})\n",
        "print(result[\"output\"])"
      ],
      "metadata": {
        "id": "jXO2FZ6P81zU",
        "outputId": "09f1d907-184c-47f5-9b5e-a4ea978a1005",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        }
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `this_retrevier` with `Chain-of-Thought`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m[Document(page_content='Synthetic Prompting: Generating Chain-of-Thought Demonstrations for Large Language Models\\nAssociation for Computational Linguistics: Human Lan-\\nguage Technologies, NAACL 2022, Seattle, WA, United\\nStates, July 10-15, 2022 , pp. 5168–5186. Association\\nfor Computational Linguistics, 2022. doi: 10.18653/v1/\\n2022.naacl-main.380. URL https://doi.org/10.\\n18653/v1/2022.naacl-main.380 .\\nSuzgun, M., Scales, N., Sch ¨arli, N., Gehrmann, S., Tay, Y .,\\nChung, H. W., Chowdhery, A., Le, Q. V ., Chi, E. H., Zhou,\\nD., and Wei, J. Challenging big-bench tasks and whether\\nchain-of-thought can solve them. CoRR , abs/2210.09261,\\n2022. doi: 10.48550/arXiv.2210.09261. URL https:\\n//doi.org/10.48550/arXiv.2210.09261 .\\nThoppilan, R., Freitas, D. D., Hall, J., Shazeer, N., Kul-\\nshreshtha, A., Cheng, H., Jin, A., Bos, T., Baker, L., Du,\\nY ., Li, Y ., Lee, H., Zheng, H. S., Ghafouri, A., Mene-\\ngali, M., Huang, Y ., Krikun, M., Lepikhin, D., Qin, J.,\\nChen, D., Xu, Y ., Chen, Z., Roberts, A., Bosma, M.,\\nZhou, Y ., Chang, C., Krivokon, I., Rusch, W., Pickett,\\nM., Meier-Hellstern, K. S., Morris, M. R., Doshi, T.,\\nSantos, R. D., Duke, T., Soraker, J., Zevenbergen, B.,\\nPrabhakaran, V ., Diaz, M., Hutchinson, B., Olson, K.,\\nMolina, A., Hoffman-John, E., Lee, J., Aroyo, L., Ra-\\njakumar, R., Butryna, A., Lamm, M., Kuzmina, V ., Fen-\\nton, J., Cohen, A., Bernstein, R., Kurzweil, R., Aguera-\\nArcas, B., Cui, C., Croak, M., Chi, E. H., and Le, Q.\\nLamda: Language models for dialog applications. CoRR ,\\nabs/2201.08239, 2022. URL https://arxiv.org/\\nabs/2201.08239 .\\nWang, X., Wei, J., Schuurmans, D., Le, Q. V ., Chi, E. H.,\\nand Zhou, D. Self-consistency improves chain of thought\\nreasoning in language models. CoRR , abs/2203.11171,\\n2022a. doi: 10.48550/arXiv.2203.11171. URL https:\\n//doi.org/10.48550/arXiv.2203.11171 .\\nWang, Y ., Mishra, S., Alipoormolabashi, P., Kordi, Y .,\\nMirzaei, A., Arunkumar, A., Ashok, A., Dhanasekaran,\\nA. S., Naik, A., Stap, D., Pathak, E., Karamanolakis, G.,\\nLai, H. G., Purohit, I., Mondal, I., Anderson, J., Kuznia,\\nK., Doshi, K., Patel, M., Pal, K. K., Moradshahi, M., Par-\\nmar, M., Purohit, M., Varshney, N., Kaza, P. R., Verma,\\nP., Puri, R. S., Karia, R., Sampat, S. K., Doshi, S., Mishra,\\nS., Reddy, S., Patro, S., Dixit, T., Shen, X., Baral, C.,\\nChoi, Y ., Smith, N. A., Hajishirzi, H., and Khashabi, D.\\nSuper-naturalinstructions: Generalization via declarative\\ninstructions on 1600+ nlp tasks, 2022b.\\nWei, J., Bosma, M., Zhao, V . Y ., Guu, K., Yu, A. W., Lester,\\nB., Du, N., Dai, A. M., and Le, Q. V . Finetuned language\\nmodels are zero-shot learners. In The Tenth Interna-\\ntional Conference on Learning Representations, ICLR\\n2022, Virtual Event, April 25-29, 2022 . OpenReview.net,\\n2022a. URL https://openreview.net/forum?\\nid=gEZrGCozdqR .Wei, J., Wang, X., Schuurmans, D., Bosma, M., Chi,\\nE. H., Le, Q., and Zhou, D. Chain of thought prompt-\\ning elicits reasoning in large language models. CoRR ,\\nabs/2201.11903, 2022b. URL https://arxiv.org/\\nabs/2201.11903 .\\nWest, P., Bhagavatula, C., Hessel, J., Hwang, J. D., Jiang, L.,\\nBras, R. L., Lu, X., Welleck, S., and Choi, Y . Symbolic\\nknowledge distillation: from general language models\\nto commonsense models. In Carpuat, M., de Marneffe,\\nM., and Ru ´ız, I. V . M. (eds.), Proceedings of the 2022\\nConference of the North American Chapter of the As-\\nsociation for Computational Linguistics: Human Lan-\\nguage Technologies, NAACL 2022, Seattle, WA, United\\nStates, July 10-15, 2022 , pp. 4602–4625. Association\\nfor Computational Linguistics, 2022. doi: 10.18653/v1/\\n2022.naacl-main.341. URL https://doi.org/10.\\n18653/v1/2022.naacl-main.341 .\\nYang, K., Klein, D., Peng, N., and Tian, Y . DOC: im-\\nproving long story coherence with detailed outline con-\\ntrol. CoRR , abs/2212.10077, 2022. doi: 10.48550/arXiv.\\n2212.10077. URL https://doi.org/10.48550/\\narXiv.2212.10077 .\\nYe, J., Gao, J., Li, Q., Xu, H., Feng, J., Wu, Z., Yu, T.,\\nand Kong, L. Zerogen: Efﬁcient zero-shot learning via\\ndataset generation. CoRR , abs/2202.07922, 2022a. URL', metadata={'page': '10.0', 'source': './2302.00618.pdf'}), Document(page_content='Synthetic Prompting: Generating Chain-of-Thought Demonstrations for Large Language Models\\nprompting.\\nReferences\\nBrown, T. B., Mann, B., Ryder, N., Subbiah, M., Kaplan,\\nJ., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G.,\\nAskell, A., Agarwal, S., Herbert-V oss, A., Krueger, G.,\\nHenighan, T., Child, R., Ramesh, A., Ziegler, D. M., Wu,\\nJ., Winter, C., Hesse, C., Chen, M., Sigler, E., Litwin, M.,\\nGray, S., Chess, B., Clark, J., Berner, C., McCandlish, S.,\\nRadford, A., Sutskever, I., and Amodei, D. Language\\nmodels are few-shot learners. In Larochelle, H.,\\nRanzato, M., Hadsell, R., Balcan, M., and Lin, H. (eds.),\\nAdvances in Neural Information Processing Systems 33:\\nAnnual Conference on Neural Information Processing\\nSystems 2020, NeurIPS 2020, December 6-12, 2020,\\nvirtual , 2020. URL https://proceedings.\\nneurips.cc/paper/2020/hash/\\n1457c0d6bfcb4967418bfb8ac142f64a-Abstract.\\nhtml .\\nChen, W., Ma, X., Wang, X., and Cohen, W. W. Pro-\\ngram of thoughts prompting: Disentangling compu-\\ntation from reasoning for numerical reasoning tasks.\\nCoRR , abs/2211.12588, 2022. doi: 10.48550/arXiv.\\n2211.12588. URL https://doi.org/10.48550/\\narXiv.2211.12588 .\\nChowdhery, A., Narang, S., Devlin, J., Bosma, M., Mishra,\\nG., Roberts, A., Barham, P., Chung, H. W., Sutton,\\nC., Gehrmann, S., Schuh, P., Shi, K., Tsvyashchenko,\\nS., Maynez, J., Rao, A., Barnes, P., Tay, Y ., Shazeer,\\nN., Prabhakaran, V ., Reif, E., Du, N., Hutchinson, B.,\\nPope, R., Bradbury, J., Austin, J., Isard, M., Gur-Ari,\\nG., Yin, P., Duke, T., Levskaya, A., Ghemawat, S., Dev,\\nS., Michalewski, H., Garcia, X., Misra, V ., Robinson,\\nK., Fedus, L., Zhou, D., Ippolito, D., Luan, D., Lim,\\nH., Zoph, B., Spiridonov, A., Sepassi, R., Dohan, D.,\\nAgrawal, S., Omernick, M., Dai, A. M., Pillai, T. S., Pel-\\nlat, M., Lewkowycz, A., Moreira, E., Child, R., Polozov,\\nO., Lee, K., Zhou, Z., Wang, X., Saeta, B., Diaz, M.,\\nFirat, O., Catasta, M., Wei, J., Meier-Hellstern, K., Eck,\\nD., Dean, J., Petrov, S., and Fiedel, N. Palm: Scaling lan-\\nguage modeling with pathways. CoRR , abs/2204.02311,\\n2022. doi: 10.48550/arXiv.2204.02311. URL https:\\n//doi.org/10.48550/arXiv.2204.02311 .\\nChung, H. W., Hou, L., Longpre, S., Zoph, B., Tay, Y .,\\nFedus, W., Li, E., Wang, X., Dehghani, M., Brahma, S.,\\nWebson, A., Gu, S. S., Dai, Z., Suzgun, M., Chen, X.,\\nChowdhery, A., Narang, S., Mishra, G., Yu, A., Zhao,\\nV . Y ., Huang, Y ., Dai, A. M., Yu, H., Petrov, S., Chi, E. H.,\\nDean, J., Devlin, J., Roberts, A., Zhou, D., Le, Q. V .,\\nand Wei, J. Scaling instruction-ﬁnetuned language mod-\\nels.CoRR , abs/2210.11416, 2022. doi: 10.48550/arXiv.2210.11416. URL https://doi.org/10.48550/\\narXiv.2210.11416 .\\nCobbe, K., Kosaraju, V ., Bavarian, M., Hilton, J., Nakano,\\nR., Hesse, C., and Schulman, J. Training veriﬁers to solve\\nmath word problems. CoRR , abs/2110.14168, 2021. URL\\nhttps://arxiv.org/abs/2110.14168 .\\nDrozdov, A., Sch ¨arli, N., Aky ¨urek, E., Scales, N., Song,\\nX., Chen, X., Bousquet, O., and Zhou, D. Compo-\\nsitional semantic parsing with large language models.\\nCoRR , abs/2209.15003, 2022. doi: 10.48550/arXiv.\\n2209.15003. URL https://doi.org/10.48550/\\narXiv.2209.15003 .\\nFu, Y ., Peng, H., Sabharwal, A., Clark, P., and Khot,\\nT. Complexity-based prompting for multi-step reason-\\ning. CoRR , abs/2210.00720, 2022. doi: 10.48550/arXiv.\\n2210.00720. URL https://doi.org/10.48550/\\narXiv.2210.00720 .\\nGao, L., Dai, Z., Pasupat, P., Chen, A., Chaganty, A. T., Fan,\\nY ., Zhao, V . Y ., Lao, N., Lee, H., Juan, D.-C., and Guu,\\nK. Rarr: Researching and revising what language models\\nsay, using language models, 2022a.\\nGao, L., Madaan, A., Zhou, S., Alon, U., Liu, P., Yang,\\nY ., Callan, J., and Neubig, G. PAL: program-aided lan-\\nguage models. CoRR , abs/2211.10435, 2022b. doi: 10.\\n48550/arXiv.2211.10435. URL https://doi.org/\\n10.48550/arXiv.2211.10435 .\\nHoltzman, A., Buys, J., Du, L., Forbes, M., and Choi, Y .\\nThe curious case of neural text degeneration. In 8th\\nInternational Conference on Learning Representations,', metadata={'page': '8.0', 'source': './2302.00618.pdf'}), Document(page_content='Synthetic Prompting: Generating Chain-of-Thought Demonstrations for Large Language Models\\nKoncel-Kedziorski, R., Roy, S., Amini, A., Kushman,\\nN., and Hajishirzi, H. MAWPS: A math word prob-\\nlem repository. In Knight, K., Nenkova, A., and Ram-\\nbow, O. (eds.), NAACL HLT 2016, The 2016 Confer-\\nence of the North American Chapter of the Associa-\\ntion for Computational Linguistics: Human Language\\nTechnologies, San Diego California, USA, June 12-17,\\n2016 , pp. 1152–1157. The Association for Computational\\nLinguistics, 2016. doi: 10.18653/v1/n16-1136. URL\\nhttps://doi.org/10.18653/v1/n16-1136 .\\nLi, Y ., Lin, Z., Zhang, S., Fu, Q., Chen, B., Lou, J.-G., and\\nChen, W. On the advance of making language models bet-\\nter reasoners. 2022. doi: 10.48550/ARXIV .2206.02336.\\nURL https://arxiv.org/abs/2206.02336 .\\nLiu, A., Swayamdipta, S., Smith, N. A., and Choi, Y .\\nWANLI: worker and AI collaboration for natural language\\ninference dataset creation. CoRR , abs/2201.05955, 2022a.\\nURL https://arxiv.org/abs/2201.05955 .\\nLiu, J., Shen, D., Zhang, Y ., Dolan, B., Carin, L., and\\nChen, W. What makes good in-context examples for\\ngpt-3? In Agirre, E., Apidianaki, M., and Vulic, I.\\n(eds.), Proceedings of Deep Learning Inside Out: The\\n3rd Workshop on Knowledge Extraction and Integration\\nfor Deep Learning Architectures, DeeLIO@ACL 2022,\\nDublin, Ireland and Online, May 27, 2022 , pp. 100–114.\\nAssociation for Computational Linguistics, 2022b. doi:\\n10.18653/v1/2022.deelio-1.10. URL https://doi.\\norg/10.18653/v1/2022.deelio-1.10 .\\nLyu, X., Min, S., Beltagy, I., Zettlemoyer, L., and Hajishirzi,\\nH. Z-ICL: zero-shot in-context learning with pseudo-\\ndemonstrations. CoRR , abs/2212.09865, 2022. doi: 10.\\n48550/arXiv.2212.09865. URL https://doi.org/\\n10.48550/arXiv.2212.09865 .\\nMiao, S., Liang, C., and Su, K. A diverse corpus for\\nevaluating and developing english math word problem\\nsolvers. In Jurafsky, D., Chai, J., Schluter, N., and\\nTetreault, J. R. (eds.), Proceedings of the 58th Annual\\nMeeting of the Association for Computational Linguis-\\ntics, ACL 2020, Online, July 5-10, 2020 , pp. 975–984.\\nAssociation for Computational Linguistics, 2020. doi:\\n10.18653/v1/2020.acl-main.92. URL https://doi.\\norg/10.18653/v1/2020.acl-main.92 .\\nOuyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright,\\nC. L., Mishkin, P., Zhang, C., Agarwal, S., Slama, K.,\\nRay, A., Schulman, J., Hilton, J., Kelton, F., Miller,\\nL., Simens, M., Askell, A., Welinder, P., Christiano,\\nP. F., Leike, J., and Lowe, R. Training language\\nmodels to follow instructions with human feedback.\\nCoRR , abs/2203.02155, 2022. doi: 10.48550/arXiv.\\n2203.02155. URL https://doi.org/10.48550/\\narXiv.2203.02155 .Patel, A., Bhattamishra, S., and Goyal, N. Are NLP\\nmodels really able to solve simple math word prob-\\nlems? In Toutanova, K., Rumshisky, A., Zettlemoyer,\\nL., Hakkani-T ¨ur, D., Beltagy, I., Bethard, S., Cotterell,\\nR., Chakraborty, T., and Zhou, Y . (eds.), Proceedings\\nof the 2021 Conference of the North American Chapter\\nof the Association for Computational Linguistics: Hu-\\nman Language Technologies, NAACL-HLT 2021, On-\\nline, June 6-11, 2021 , pp. 2080–2094. Association for\\nComputational Linguistics, 2021. doi: 10.18653/v1/\\n2021.naacl-main.168. URL https://doi.org/10.\\n18653/v1/2021.naacl-main.168 .\\nPi, X., Liu, Q., Chen, B., Ziyadi, M., Lin, Z., Gao, Y .,\\nFu, Q., Lou, J., and Chen, W. Reasoning like program\\nexecutors. CoRR , abs/2201.11473, 2022. URL https:\\n//arxiv.org/abs/2201.11473 .\\nPress, O., Zhang, M., Min, S., Schmidt, L., Smith, N. A.,\\nand Lewis, M. Measuring and narrowing the composi-\\ntionality gap in language models. CoRR , abs/2210.03350,\\n2022. doi: 10.48550/arXiv.2210.03350. URL https:\\n//doi.org/10.48550/arXiv.2210.03350 .\\nReimers, N. and Gurevych, I. Sentence-BERT: Sentence\\nembeddings using Siamese BERT-networks. In Pro-\\nceedings of the 2019 Conference on Empirical Meth-\\nods in Natural Language Processing and the 9th In-\\nternational Joint Conference on Natural Language Pro-', metadata={'page': '9.0', 'source': './2302.00618.pdf'}), Document(page_content='Synthetic Prompting: Generating Chain-of-Thought Demonstrations for Large Language Models\\nof reasoning steps required to answer it, where a step is a\\nline of code separated by a line break. For example, the\\ncomplexity of Example 1 in Figure 1 (left) is 5, as it has\\n5 lines of code. The target complexity for generating a\\nquestion is randomly sampled from a range that spans from\\nthe lowest complexity of the seed examples to the highest\\none plusc.\\nSelf-generated reasoning chain We prompt the model to\\ngenerate a reasoning chain of the target complexity for the\\ngiven topic, and then generate a question based on the rea-\\nsoning chain. We ﬁnd that this approach leads to more an-\\nswerable and well-deﬁned questions, compared to directly\\ngenerating questions without a reasoning chain. To guide\\nthe model to follow the target complexity, we number each\\nreasoning step in the demonstrations, e.g., #1and#2in Fig-\\nure 1 (left). We ﬁlter out the questions that are duplicated,\\nrepeat at least one 5-gram, or do not mention the given topic\\nword.\\n3.2.2. F ORWARD PROCESS\\nThe forward process aims to generate a reasoning chain\\nfor the question synthesized in the backward process. Fig-\\nure 1 (right) shows an example prompt for the forward\\nprocess, which consists of the seed examples. Unlike chain-\\nof-thought prompting, P AL prompting does not include the\\nﬁnal answers in the prompt, as the answers can be obtained\\nby executing the generated code, rather than extracted from\\nthe model output. We observe that the reasoning chain gen-\\nerated in the forward process is more relevant and precise\\nthan the one generated in the backward process, as it is\\ndirectly conditioned on the question.\\nWe also want to ensure that the model is conﬁdent about\\nthe answer produced by the reasoning chain. Following\\nHuang et al. (2022), we measure the conﬁdence of an an-\\nswer by the proportion of sampled reasoning chains that\\nlead to the same answer. For a question x, we sample m\\nreasoning chains and obtain their answers {a1,a2,...,am}.\\nWe then ﬁnd the most consistent answer by majority vot-\\ning:ˆa= argmaxai∑m\\nk=1 1(ai=ak). If more than m/2\\nreasoning chains lead to ˆa, we associate the shortest one\\nwith the synthesized question; otherwise, we discard the\\nquestion, as the model fails to produce conﬁdent reasoning\\nchains for it. Note that majority voting is only used for syn-\\nthesizing examples, not for inference (Section 3.3). This is\\ndifferent from Wang et al. (2022a), who use majority voting\\nfor inference.\\n3.3. Inference Phase\\nDuring inference, we select a subset of synthesized exam-\\nples as demonstrations for the model. According to Fu\\net al. (2022), selecting demonstrations based on complex-\\nity can improve the performance of the model on reason-ing tasks, compared to selecting them based on similarity.\\nMoreover, selecting demonstrations based on similarity may\\nintroduce biases (Zhang et al., 2022b; Lyu et al., 2022) from\\nthe demonstrations, especially if they are incorrect. Fur-\\nthermore, selecting demonstrations that are complementary\\nto each other may help the model fuse knowledge from\\ndifferent types of reasoning (Ye et al., 2022b; Zhang et al.,\\n2022b).\\nTherefore, we propose an in-cluster complexity based\\nscheme to select demonstrations that are both complex and\\ncomplementary. Speciﬁcally, we cluster the synthesized\\nexamples in a semantic embedding space, using Sentence-\\nBERT (Reimers & Gurevych, 2019) as the encoder. The\\nnumber of clusters is equal to the number of demonstrations\\nused for inference. We then choose the most complex exam-\\nple from each cluster as the demonstration. The inference\\nprocess is the same as previous work like P AL prompt-\\ning, where the model completes a given prompt. The only\\ndifference is that the demonstrations in our prompts are\\nsynthesized from the seed examples, rather than ﬁxed to\\nthem.\\n4. Experiments\\n4.1. Datasets\\nWe experimented on seven datasets of different reasoning\\ntasks. Examples are presented in Table 1.', metadata={'page': '3.0', 'source': './2302.00618.pdf'}), Document(page_content='Synthetic Prompting: Generating Chain-of-Thought Demonstrations for Large Language Models\\nDatasets Example\\nGSM8K Patrick has three glue sticks that are partially used. One has 1/6 left, the second has 2/3 left and\\nthe third one has 1/2 left. If a glue stick is 12 millimeters long originally, what is the total length\\nof the glue sticks that are not used?\\nColored Objects On the nightstand, you see several items arranged in a row: a blue crayon, a red notebook, a teal\\nbracelet, a magenta sheet of paper, a silver dog leash, and a black booklet. What is the color of the\\nitem furthest from the dog leash?\\nRepeat Copy Repeat election to the council three times, but after every other word say cool\\nTable 1: Examples from three datasets. Questions in the other numerical reasoning datasets resemble those in GSM8K.\\nFollowing these settings, we assumed access to 2 or 4 ran-\\ndom examples from each dataset by default. For numerical\\nreasoning tasks, we also experimented with the 8 examples\\nthat were manually crafted by Wei et al. (2022b) and were\\nadopted by several following papers (Fu et al., 2022; Wang\\net al., 2022a; Gao et al., 2022b). We also used the P AL-style\\nreasoning chains annotated by Gao et al. (2022b).\\nPrompting baselines without synthesis use all provided gold\\nexamples to construct prompts for inference. S YNTHETIC\\nPROMPTING and its variants synthesize examples using the\\nprovided examples, and select 8 synthetic demonstrations\\nbased on in-cluster complexity, unless stated otherwise.\\nSeed examples and synthetic prompts are provided in the\\nSupplementary Materials.\\n4.3. Baselines\\nDirect Prompting Direct prompting (Brown et al., 2020)\\nprompts LLMs to directly generate answers with demonstra-\\ntions of input-answer pairs.\\nCoT Prompting Chain-of-thought prompting (Wei et al.,\\n2022b) is effective in eliciting reasoning in LLMs, which\\nprompts LLMs to generate natural language reasoning steps\\nfollowed by an answer.\\nPAL Prompting PAL prompting (Gao et al., 2022b), a vari-\\nant of chain-of-thought prompting, improves reasoning with\\nstructured code. Figure 1 (right) provides two examples. It\\ndoes not prompt LLMs to include ﬁnal answers into com-\\npletions; answers are obtained by executing the code. This\\nprompting technique has achieved state-of-the-art results on\\nnumerous reasoning tasks.\\nVanilla S YNTHETIC PROMPTING This is a variant of\\nSYNTHETIC PROMPTING , which differs in that prompts\\nused for question synthesis only consist of questions from\\nseed examples. In other words, new questions are syn-\\nthesized by mimicking seed questions, without any other\\ncondition.4.4. Implementation Details\\nWe adopted P AL-style reasoning chains which are structured\\ncode with comments being natural language reasoning step.\\ntext-davinci-003 version of InstructGPT (Ouyang\\net al., 2022) was used as our backend LLM for both syn-\\nthesis and inference. We used top-p sampling (Holtzman\\net al., 2020) for synthesis with temperature set to 0.7, and\\nused greedy decoding for inference with temperature set to\\n0. All numerical reasoning datasets share one set of seed\\nexamples either randomly sampled from GSM8K (when\\nthe number of seeds is 2 or 4) or from Wei et al. (2022b)\\n(when the number of seeds is 8). For datasets of the other\\ntasks, seeds were randomly sampled from their own datasets.\\nWe annotated seed examples with both CoT-style reasoning\\nchains and P AL-style reasoning chains manually, following\\ntheir annotation protocols. Annotations are provided in the\\nSupplementary Materials. For each set of seed examples, we\\nsynthesized more examples by repeating backward-forward\\nsynthesis for 1,000 times. Target complexities range from\\nthe lowest complexity of seed examples to the highest one\\nplusc;cwas set to 4 for numerical reasoning and 2 on the\\nother datasets. In forward synthesis, the number of reason-\\ning chains sampled for each question was 3. The encoder\\nused for clustering was all-mpnet-base-v2 .\\n4.5. Main Results\\nAs shown by Table 2, S YNTHETIC PROMPTING consistently', metadata={'page': '4.0', 'source': './2302.00618.pdf'}), Document(page_content='Synthetic Prompting: Generating Chain-of-Thought Demonstrations for Large Language Models\\nTarget ComplexityTopic wordDemonstration\\nSynthesized QuestionSelf-Generated Reasoning ChainExample 1Question: Cynthia eats one serving of ice cream every night. She buys cartons of ice cream with 15 servings of ice cream per carton at a cost of $4.00 per carton. After 60 days, how much will she spend on ice cream?def solution():servings_per_night= 1servings_per_carton= 15cost_per_carton= 4.00num_days= 60num_servings= num_days* servings_per_nightnum_cartons= num_servings/ servings_per_cartonmoney_spent= cost_per_carton* num_cartonsresult = money_spentreturn resultExample 2Question: A chef bought 4 bags of onions. Each bag weighs 50 pounds. A pound of onions cost $1.50. How much did the chef spend?def solution():num_bags_bought= 4weight_per_bag= 50cost_per_pound= 1.50cost_per_bag= weight_per_bag* cost_per_poundmoney_spent= num_bags_bought* cost_per_bagresult = money_spentreturn money_spent\\nForward ProcessDemonstration\\nSynthesizedReasoning ChainExample 1# I implement a Python functioncalled solution()to solve the following question correctly.# The question is about work.def solution():””” 5-linefunction ”””# 1num_roses= 4# 2num_dahlias= num_roses+ 7# 3num_flowers= num_roses+ num_dahlias# 4result = num_flowers# 5return resultQuestion: There are 4 roses in the vase. There are 7 more dahlias than roses in the vase. How many flowers are there in the vase in total?Example 2# I implement a Python function called solution() to solve the following question correctly.# The question is about chef.def solution():””” 6-linefunction ”””# 1bags_of_onions= 4# 2weight_per_bag= 50# 3cost_per_bag= weight_per_bag* 1.50# 4money_spent= num_bags_bought* cost_per_bag# 5result = money_spent# 6return money_spentQuestion: A chef bought 4 bags of onions. Each bag weighs 50 pounds. A pound of onions cost $1.50. How much did the chef spend?Backward Process\\nFigure 1: Example prompts and model completions in the backward process (left) and the forward process (right) of example\\nsynthesis. We show only one demonstration in each prompt for brevity. Self-Generated Reasoning Chain\\n(in blue), Synthesized Question (in green), and Synthesized Reasoning Chain (in purple) are example\\ncompletions. In the backward process, an LLM synthesizes a question conditioned on a topic word, a target reasoning\\ncomplexity, and a generated reasoning chain. To better control the reasoning complexity, we number the reasoning steps,\\ne.g.,# 1 and# 2 on the left. In the forward process, the LLM synthesizes a more precise reasoning chain for the question\\nproduced in the backward process. The question produced in the backward process and the corresponding reasoning chain\\nproduced in the forward process constitute a synthetic example.\\nmay require different types of reasoning. For example,\\nquestions about taxmay involve arithmetic operations,\\nwhile questions about speed may involve unit conversions.\\nTo ensure diversity of the synthesized questions, we prompt\\nthe model to generate a question for a given topic word,\\nwhich is randomly sampled from a set of words. The word\\nset is created by prompting the model to list single-token\\nnoun words, following some random noun words from the\\nseed examples. The instruction for generating the word set\\nisList 50 noun words. Each word shouldcontain one token only. Do not repeat\\nwords already listed. , followed by no more than\\n10 words from the seed examples. We repeat this process\\nuntil we have 1,000 different words, or reach 100 repetitions\\nof prompting.\\nTarget complexity We also want to control the complexity\\nof the synthesized questions, as more complex examples\\nmay help the model learn better reasoning skills (Fu et al.,\\n2022). We deﬁne the complexity of a question as the number', metadata={'page': '2.0', 'source': './2302.00618.pdf'}), Document(page_content='Synthetic Prompting: Generating Chain-of-Thought Demonstrations for Large\\nLanguage Models\\nZhihong Shao1 2Yeyun Gong3Yelong Shen4Minlie Huang1Nan Duan3Weizhu Chen4\\nAbstract\\nLarge language models can perform various rea-\\nsoning tasks by using chain-of-thought prompting,\\nwhich guides them to ﬁnd answers through step-\\nby-step demonstrations. However, the quality of\\nthe prompts depends on the demonstrations given\\nto the models, and creating many of them by hand\\nis costly. We introduce S YNTHETIC PROMPTING ,\\na method that leverages a few handcrafted exam-\\nples to prompt the model to generate more exam-\\nples by itself, and selects effective demonstrations\\nto elicit better reasoning. Our method alternates\\nbetween a backward and forward process to gen-\\nerate new examples. The backward process gen-\\nerates a question that match a sampled reasoning\\nchain, so that the question is solvable and clear.\\nThe forward process produces a more detailed\\nreasoning chain for the question, improving the\\nquality of the example. We evaluate our method\\non numerical, symbolic, and algorithmic reason-\\ning tasks, and show that it outperforms existing\\nprompting techniques.\\n1. Introduction\\nFew-shot demonstrations, i.e., examples of inputs and out-\\nputs for a task, can enable Large Language Models (LLMs)\\nto perform various tasks without ﬁne-tuning (Brown et al.,\\n2020; Chung et al., 2022). LLMs can further improve their\\nperformance by using chain-of-thought prompting, which\\nprovides intermediate reasoning steps for the task (Wei et al.,\\n2022b; Kojima et al., 2022). However, the LLMs’ few-shot\\nperformance depends heavily on the quality of the demon-\\nstrations, especially for reasoning tasks that need complex\\nand diverse reasoning patterns. Manually creating a large\\nand diverse set of examples for demonstration selection is\\ncostly and tedious, while relying on a limited set of demon-\\nstrations may hamper the LLMs’ generalization and adapta-\\n1Tsinghua University2This work was done during an internship\\nin MSRA3Microsoft Research Asia4Microsoft. Correspondence\\nto: Minlie Huang <aihuang@tsinghua.edu.cn >.tion to different test inputs.\\nIn this paper, we propose a novel method, S YNTHETIC\\nPROMPTING , that leverages the LLMs’ own knowledge and\\ngenerative power to augment a limited set of demonstra-\\ntions with self-synthesized examples, and then uses the aug-\\nmented set to elicit better reasoning in the LLMs. Specif-\\nically, given a few seed examples, each consisting of a\\nquestion and a chain of reasoning steps, we prompt an\\nLLM to generate more examples by alternating between\\ntwo processes: (1) the backward process, where the LLM\\nsynthesizes a question based on a self-generated reasoning\\nchain, which ensures that the question is answerable and\\nwell-deﬁned; and (2) the forward process, where the LLM\\nproduces a reasoning chain for the synthesized question,\\nwhich reﬁnes the reasoning chain to be more precise and\\nconsistent with the question. We repeat this process until\\nwe obtain enough synthetic examples. To select the most\\neffective demonstrations from the augmented set, we pro-\\npose a new selection scheme based on in-cluster complexity,\\nwhich aims to maximize the diversity and informativeness\\nof the demonstrations by clustering them and choosing the\\nmost complex one (the one with the longest reasoning chain)\\nfrom each cluster. Finally, we prompt the LLM with the\\nselected demonstrations to generate a reasoning chain for a\\ntest question and then use it to obtain the answer.\\nWe evaluate our method on various reasoning tasks, in-\\ncluding numerical reasoning, algorithmic reasoning, and\\nsymbolic reasoning. Following previous few-shot settings\\n(Wang et al., 2022b; Suzgun et al., 2022), we demonstrate\\nthat our method can signiﬁcantly improve the LLMs’ per-\\nformance, achieving up to 15.6% absolute gains over the\\nstate-of-the-art methods.\\nOur main contributions are:\\n•We introduce S YNTHETIC PROMPTING , a novel\\nmethod that augments a limited set of demonstrations', metadata={'page': '0.0', 'source': './2302.00618.pdf'}), Document(page_content='Synthetic Prompting: Generating Chain-of-Thought Demonstrations for Large Language Models\\nconditioned on reasoning chains affects correctness nega-\\ntively; 62.5% are ﬂawed, 80% of which are unanswerable,\\ne.g.,\\nAn image is represented by a 4x4 matrix of integers. Each\\ncell of the matrix contains a single integer between 0 and\\n255. What is the average value of all the integers in the\\nmatrix? .\\nNotably, though we also include target complexities into the\\nprompts when synthesizing questions without conditioned\\non reasoning chains, the resulting questions tend to require\\nless reasoning steps than S YNTHETIC PROMPTING , indi-\\ncating that conditioning on numbered reasoning steps can\\ncontrol reasoning complexities better.\\n4.6.2. S CHEMES OF DEMONSTRATION SELECTION\\nDatasets GSM8K Colored Objects\\n# Seed Examples 2 4 2 4\\nRandom 73.4 73.1 83.0 90.0\\nCluster Centroid 73.1 73.0 91.2 93.6\\nSimilarity 72.9 74.0 87.0 94.2\\nIn-Cluster Similarity 72.9 73.2 89.3 95.4\\nComplexity 74.1 74.3 92.7 97.5\\nIn-Cluster Complexity 74.7 75.3 93.8 97.3\\nTable 5: Accuracies with different schemes of demonstra-\\ntion selection.\\nTo make good use of synthesized examples, having an ef-\\nfecitve selection scheme matters. We evaluated the follow-\\ning 6 selection schemes. (1) Random : randomly selects\\ndemonstrations; (2) Cluster Centroid : selects the example\\nclosest to each cluster centroid; (3) Similarity : retrieves\\nthe most similar examples according to cosine similarity;\\n(4)In-Cluster Similarity : select the most similar example\\nfrom each cluster; (5) Complexity : selects the examples\\nwith the most reasoning steps; (6) In-Cluster Complexity :\\nselects the most complex example from each cluster.\\nTable 5 presents the comparisons. Though most selection\\nschemes achieve better performance than P AL prompting,\\ncomplexity-based selection schemes are the most effective\\non the two reasoning tasks, with some other schemes like\\nRandom lagging far behind. Our proposed In-Cluster Com-\\nplexity outperforms Complexity, showing the beneﬁts of\\nusing diverse and complex demonstrations.\\n4.6.3. S ENSITIVITY TO SEED EXAMPLES\\nTo investigate how sensitive S YNTHETIC PROMPTING is\\nto seed examples, we repeated experiments on another two\\nrandom sets of seed examples. Figure 2 demonstrates our\\nsensitivity analysis. S YNTHETIC PROMPTING consistently\\noutperforms P AL prompting on different runs. However,\\n72.97374.373.572.472.774.172.47475.174.874.8\\n71.572.573.574.575.5\\n2 Seed Examples2 Seed Examples4 Seed Examples4 Seed ExamplesGSM8KPAL PromptingVanilla Synthetic PromptingSynthetic Prompting\\n88.685.995.393.294.791.787.491.894.194.495.997.7\\n8588919497100\\n2 Seed Examples2 Seed Examples4 Seed Examples4 Seed ExamplesColored ObjectsFigure 2: Sensitivity analysis on GSM8K and Colored Ob-\\njects. We experimented with another two random sets of\\nseed examples of size 2 and 4 for each dataset.\\nwe observed that seed examples with better P AL prompting\\nperformance does not necessarily lead to better S YNTHETIC\\nPROMPTING performance.\\n4.7. Comparison with Selecting from Training\\nExamples\\nTo measure the performance gap between using synthetic\\ndemonstrations and using gold demonstrations from a large\\nset of carefully-curated examples, we selected 8 demon-\\nstrations from the training set of GSM8K with the two\\ncomplexity-based selection schemes (i.e., Complexity and\\nIn-Cluster Complexity in Section 4.6.2), respectively. As\\nthe training examples were annotated with natural language\\nreasoning chains (CoT-style reasoning), we measured the\\nnumbers of natural language reasoning steps as reasoning\\ncomplexities for complexity-based selection, and manu-\\nally annotated selected examples with P AL-style reasoning\\nchains for P AL prompting. As the training examples of\\nGSM8K are diverse, both Complexity and In-Cluster Com-\\nplexity select diverse and informative demonstrations, and\\nyield an accuracy of 77.0% on the test set of GSM8K, sur-\\npassing our accuracy of 75.3% by absolute 1.7%. As shown', metadata={'page': '6.0', 'source': './2302.00618.pdf'}), Document(page_content='Synthetic Prompting: Generating Chain-of-Thought Demonstrations for Large Language Models\\nSeed Examples\\nQuestion: Carol has 20 signatures in her book, and Jennifer has 44. The sisters have three more weeks of summer vacation,\\nand they decide they want to reach 100 signatures between them by the end of the summer. How many signatures do the\\nsisters need to collect to reach their goal?\\nQuestion: A team of 4 painters worked on a mansion for 3/8ths of a day every day for 3 weeks. How many hours of work\\ndid each painter put in?\\nSynthetic Demonstrations from Vanilla S YNTHETIC PROMPTING\\nQuestion: 80 people attended a party. 40 of them were men and 40 were women. Of the men, 10 were married and of the\\nwomen, 20 were married. How many single people were at the party?\\nQuestion: The team of 4 painters worked on the mansion for 3/8ths of a day every day for 3 weeks. If each painter was\\npaid $25 per hour, how much money did the team of painters earn in total?\\nQuestion (Unanswerable): 80 students took a quiz in Mrs. Smith’s math class. The average score was 75%. How many\\nstudents scored a 95% or higher?\\nSynthetic Demonstrations from S YNTHETIC PROMPTING\\nGiven Topic Word: idea\\nQuestion: If 5 people each have 10 ideas, with 5 of those ideas being innovative and taking 2 minutes each to develop, and\\nthe other 5 ideas being non-innovative and taking 1 minute each to develop, how many minutes will it take all 5 people to\\ndevelop all 10 ideas?\\nGiven Topic Word: ofﬁce\\nQuestion: The ofﬁce is 20 feet wide, 30 feet long and 10 feet high. It has two windows that are each 5 feet wide and 6 feet\\nhigh, and one door that is 3 feet wide and 8 feet high. What is the total area of the ofﬁce walls?\\nGiven Topic Word: gallery\\nQuestion: A gallery has 10 paintings, 9 sculptures, 6 photos, and 4 mixed media pieces. The painting is $200, the sculpture\\nis $500, the photo is $100 and the mixed media piece is $150. You get a 15% discount and you have to pay 5% tax. How\\nmuch will you pay in total?\\nTable 6: A set of seed examples from GSM8K, as well as synthetic demonstrations selected by S YNTHETIC PROMPTING\\nand its vanilla version, respectively. We only show questions for brevity, as their reasoning chains are correct, except that the\\nthird question from vanilla S YNTHETIC PROMPTING is unanswerable.\\nwith access to only limited and possibly-simple examples,\\nautomatically synthesizing examples for selecting more ef-\\nfective demonstrations serves as a promising way to elicit\\nbetter reasoning in LLMs.\\n4.8. Quality Analysis of Synthetic Examples\\nTo investigate the quality of synthesized examples, we con-\\nducted manual evaluation on GSM8K. We evaluated 25\\nrandom examples synthesized by S YNTHETIC PROMPTING\\nand vanilla S YNTHETIC PROMPTING , respectively. Com-\\npared with vanilla S YNTHETIC PROMPTING , SYNTHETIC\\nPROMPTING synthesizes questions of higher complexities\\n(8.3 vs. 5.4) and also with lower error rate (8% vs. 24%).\\nWe further analyze the quality of selected synthetic demon-\\nstrations. For S YNTHETIC PROMPTING , all selected demon-\\nstrations are correct, while its vanilla version has one unan-\\nswerable question and another one with wrong reasoning.Table 6 shows two seed examples, as well as some synthetic\\ndemonstrations. For vanilla S YNTHETIC PROMPTING , the\\nﬁrst two questions are logically close to seed questions, and\\nthe third one is unanswerable. With S YNTHETIC PROMPT -\\nING, the LLM can synthesize on-topic questions requiring\\nnovel reasoning patterns, e.g., the second question about\\noffice requires geometric reasoning.\\n5. Conclusion\\nWe introduce S YNTHETIC PROMPTING , a novel technique\\nfor reasoning with large language models using few exam-\\nples, that differs from previous work by using the models\\nas generators of additional examples besides as consumers\\nof in-context demonstrations. We show that by prompting\\na large language model to synthesize more examples, we\\ncan improve its reasoning performance on numerical, sym-', metadata={'page': '7.0', 'source': './2302.00618.pdf'}), Document(page_content='Synthetic Prompting: Generating Chain-of-Thought Demonstrations for Large Language Models\\naugmented set for inference.\\n•We demonstrate the effectiveness of our method on\\nthree reasoning tasks, achieving signiﬁcant improve-\\nments over previous methods.\\n2. Related Work\\nIn-context few-shot learning With large-scale unsuper-\\nvised pre-training, LLMs (Brown et al., 2020; Chowdh-\\nery et al., 2022; Zhang et al., 2022a) can learn to perform\\ntasks by mimicking in-context demonstrations (Shin et al.,\\n2022). To improve robustness to prompts, instruction tuning\\n(Ouyang et al., 2022; Wei et al., 2022a; Sanh et al., 2022;\\nChung et al., 2022) has been proposed, which trains a lan-\\nguage model on diverse tasks to generate desirable outputs\\nthat follow given instructions. With improved controllability,\\nin-context learning-based applications ﬂourish, including\\ntext generation (Yang et al., 2022; Gao et al., 2022a), di-\\nalogue generation (Thoppilan et al., 2022), and resource\\nconstruction (West et al., 2022).\\nPrompting techniques for reasoning Instead of directly\\ngenerating an answer, chain-of-thought prompting (Wei\\net al., 2022b) prompts LLMs to arrive at an answer after\\na step-by-step reasoning process, which largely improves\\nperformance on numerous reasoning tasks. Following work\\nlike least-to-most prompting (Zhou et al., 2022), self-ask\\n(Press et al., 2022), and decomposed prompting (Khot et al.,\\n2022) also shares the spirit of question decomposition, i.e.,\\ndecomposing a complex question into a series of tractable\\nsub-questions. All these methods produce natural language\\nreasoning steps, which struggle with calculations and sym-\\nbolic manipulations. Techniques like P AL prompting (Gao\\net al., 2022b) and program-of-thought prompting (Chen\\net al., 2022) propose to improve natural language reasoning\\nwith structured code, showing signiﬁcant improvements on\\narithmetic, symbolic and algorithmic tasks.\\nOrthogonal to prompting workﬂows, there is also work that\\nexplores what make an effective demonstration. Metrics\\ninclude (1) diversity, which selects complementary demon-\\nstrations so that models can fuse different reasoning (Li\\net al., 2022; Ye et al., 2022b) or be less biased by one type\\nof reasoning (Zhang et al., 2022b); (2) reasoning complex-\\nity, which selects demonstrations with the highest reasoning\\ncomplexity, and has been found to work well on numerical\\nreasoning empirically (Fu et al., 2022); (3) similarity with a\\ntest input, which retrieves structurally (Drozdov et al., 2022)\\nor semantically (Liu et al., 2022b) similar demonstrations.\\nTo ensure both diversity and informativeness of demonstra-\\ntions, we propose a selection scheme based on in-cluster\\ncomplexity to choose the most complex examples from ex-\\nample clusters. All these selection schemes assume access\\nto a set of examples (whether annotated or not).Knowledge distillation from LLMs Some researches dis-\\ntilled knowledge from LLMs into symbolic knowledge, e.g.,\\nstructured commonsense knowledge (West et al., 2022) or\\ntask-speciﬁc examples (Liu et al., 2022a; Ye et al., 2022a;\\nHuang et al., 2022). These researches have at least one of\\nthe following characteristics: (1) assuming access to gold\\ninputs from training sets without needing to generate them;\\n(2) distilling knowledge based on collaboration between\\nworkers and AI; (3) using distilled knowledge for training.\\nBy contrast, we assume access to only a few gold examples,\\nautomatically synthesize more examples by prompting an\\nLLM, and study whether synthesized examples can be lever-\\naged to better elicit reasoning in the model itself, without\\nfurther training.\\n3. Synthetic Prompting\\n3.1. Overview\\nTo perform reasoning tasks with LLMs, given a few exam-\\nples each consisting of a question and a reasoning chain,\\nit is common to directly concatenate them into a prompt\\nfor inference. In this paper, we instead treat them as seed\\nexamples, and prompt an LLM to automatically synthesize\\nmore by repeating a backward-forward procedure; the back-', metadata={'page': '1.0', 'source': './2302.00618.pdf'})]\u001b[0m"
          ]
        },
        {
          "output_type": "error",
          "ename": "BadRequestError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-e88d119f74a2>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"'Chain-of-Thought'について説明して\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m result = chatbot.invoke({\n\u001b[0m\u001b[1;32m      3\u001b[0m             \"input\": prompt})\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"output\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m     ) -> Dict[str, Any]:\n\u001b[1;32m     86\u001b[0m         \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         return self(\n\u001b[0m\u001b[1;32m     88\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"callbacks\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m             \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m         \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m         final_outputs: Dict[str, Any] = self.prep_outputs(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    302\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m             outputs = (\n\u001b[0;32m--> 304\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m   1165\u001b[0m         \u001b[0;31m# We now enter the agent loop (until it returns something).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1166\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_continue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_elapsed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1167\u001b[0;31m             next_step_output = self._take_next_step(\n\u001b[0m\u001b[1;32m   1168\u001b[0m                 \u001b[0mname_to_tool_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1169\u001b[0m                 \u001b[0mcolor_mapping\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36m_take_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m             \u001b[0;31m# Call the LLM to see what to do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m             output = self.agent.plan(\n\u001b[0m\u001b[1;32m    955\u001b[0m                 \u001b[0mintermediate_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/agents/openai_functions_agent/base.py\u001b[0m in \u001b[0;36mplan\u001b[0;34m(self, intermediate_steps, callbacks, with_functions, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0mmessages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_messages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwith_functions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             predicted_message = self.llm.predict_messages(\n\u001b[0m\u001b[1;32m    105\u001b[0m                 \u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0mfunctions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chat_models/base.py\u001b[0m in \u001b[0;36mpredict_messages\u001b[0;34m(self, messages, stop, **kwargs)\u001b[0m\n\u001b[1;32m    651\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m             \u001b[0m_stop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 653\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m     async def apredict(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chat_models/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, messages, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m     ) -> BaseMessage:\n\u001b[0;32m--> 600\u001b[0;31m         generation = self.generate(\n\u001b[0m\u001b[1;32m    601\u001b[0m             \u001b[0;34m[\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m         ).generations[0][0]\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chat_models/base.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    347\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mrun_managers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m                     \u001b[0mrun_managers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_llm_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m         flattened_outputs = [\n\u001b[1;32m    351\u001b[0m             \u001b[0mLLMResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mllm_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chat_models/base.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m                 results.append(\n\u001b[0;32m--> 339\u001b[0;31m                     self._generate_with_cache(\n\u001b[0m\u001b[1;32m    340\u001b[0m                         \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                         \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chat_models/base.py\u001b[0m in \u001b[0;36m_generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    490\u001b[0m                 )\n\u001b[1;32m    491\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m                 return self._generate(\n\u001b[0m\u001b[1;32m    493\u001b[0m                     \u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chat_models/openai.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, messages, stop, run_manager, stream, **kwargs)\u001b[0m\n\u001b[1;32m    409\u001b[0m                 \u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m             )\n\u001b[0;32m--> 411\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_generate_from_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m         \u001b[0mmessage_dicts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_message_dicts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chat_models/base.py\u001b[0m in \u001b[0;36m_generate_from_stream\u001b[0;34m(stream)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_generate_from_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIterator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mChatGenerationChunk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mChatResult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mgeneration\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mChatGenerationChunk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgeneration\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mgeneration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chat_models/openai.py\u001b[0m in \u001b[0;36m_stream\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[0mdefault_chunk_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAIMessageChunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m         for chunk in self.completion_with_retry(\n\u001b[0m\u001b[1;32m    378\u001b[0m             \u001b[0mmessages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmessage_dicts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m         ):\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chat_models/openai.py\u001b[0m in \u001b[0;36mcompletion_with_retry\u001b[0;34m(self, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0;34m\"\"\"Use tenacity to retry the completion call.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_openai_v1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0mretry_decorator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_create_retry_decorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    297\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/resources/chat/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, max_tokens, n, presence_penalty, response_format, seed, stop, stream, temperature, tool_choice, tools, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mhttpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeout\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mNotGiven\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNOT_GIVEN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m     ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[0;32m--> 594\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    595\u001b[0m             \u001b[0;34m\"/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m             body=maybe_transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m         )\n\u001b[0;32m-> 1055\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1056\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1057\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    832\u001b[0m         \u001b[0mstream_cls\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_StreamT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m     ) -> ResponseT | _StreamT:\n\u001b[0;32m--> 834\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m    835\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    875\u001b[0m             \u001b[0;31m# to completion before attempting to access the response text.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 877\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    878\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mhttpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeoutException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mretries\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'message': \"This model's maximum context length is 4097 tokens. However, your messages resulted in 12015 tokens (11973 in the messages, 42 in the functions). Please reduce the length of the messages or functions.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "retriever = docsearch.as_retriever(search_kwargs={\"k\":10})\n",
        "llm = ChatOpenAI(temperature=0, streaming=True)\n",
        "qa = RetrievalQA.from_chain_type(\n",
        "        llm=llm,\n",
        "        #chain_type=\"stuff\",\n",
        "        chain_type=\"map_reduce\",\n",
        "        retriever=retriever,\n",
        "        return_source_documents=True,\n",
        "        verbose=True\n",
        "    )"
      ],
      "metadata": {
        "id": "XmROX2B16VKN"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"'Chain-of-Thought'について説明して\"\n",
        "response = qa(query)"
      ],
      "metadata": {
        "id": "5Xojob1b-v8x",
        "outputId": "84f6ec8e-9581-428c-b19f-5ad21ede6220",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new MapReduceDocumentsChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
            "Return any relevant text verbatim.\n",
            "______________________\n",
            "Synthetic Prompting: Generating Chain-of-Thought Demonstrations for Large Language Models\n",
            "Association for Computational Linguistics: Human Lan-\n",
            "guage Technologies, NAACL 2022, Seattle, WA, United\n",
            "States, July 10-15, 2022 , pp. 5168–5186. Association\n",
            "for Computational Linguistics, 2022. doi: 10.18653/v1/\n",
            "2022.naacl-main.380. URL https://doi.org/10.\n",
            "18653/v1/2022.naacl-main.380 .\n",
            "Suzgun, M., Scales, N., Sch ¨arli, N., Gehrmann, S., Tay, Y .,\n",
            "Chung, H. W., Chowdhery, A., Le, Q. V ., Chi, E. H., Zhou,\n",
            "D., and Wei, J. Challenging big-bench tasks and whether\n",
            "chain-of-thought can solve them. CoRR , abs/2210.09261,\n",
            "2022. doi: 10.48550/arXiv.2210.09261. URL https:\n",
            "//doi.org/10.48550/arXiv.2210.09261 .\n",
            "Thoppilan, R., Freitas, D. D., Hall, J., Shazeer, N., Kul-\n",
            "shreshtha, A., Cheng, H., Jin, A., Bos, T., Baker, L., Du,\n",
            "Y ., Li, Y ., Lee, H., Zheng, H. S., Ghafouri, A., Mene-\n",
            "gali, M., Huang, Y ., Krikun, M., Lepikhin, D., Qin, J.,\n",
            "Chen, D., Xu, Y ., Chen, Z., Roberts, A., Bosma, M.,\n",
            "Zhou, Y ., Chang, C., Krivokon, I., Rusch, W., Pickett,\n",
            "M., Meier-Hellstern, K. S., Morris, M. R., Doshi, T.,\n",
            "Santos, R. D., Duke, T., Soraker, J., Zevenbergen, B.,\n",
            "Prabhakaran, V ., Diaz, M., Hutchinson, B., Olson, K.,\n",
            "Molina, A., Hoffman-John, E., Lee, J., Aroyo, L., Ra-\n",
            "jakumar, R., Butryna, A., Lamm, M., Kuzmina, V ., Fen-\n",
            "ton, J., Cohen, A., Bernstein, R., Kurzweil, R., Aguera-\n",
            "Arcas, B., Cui, C., Croak, M., Chi, E. H., and Le, Q.\n",
            "Lamda: Language models for dialog applications. CoRR ,\n",
            "abs/2201.08239, 2022. URL https://arxiv.org/\n",
            "abs/2201.08239 .\n",
            "Wang, X., Wei, J., Schuurmans, D., Le, Q. V ., Chi, E. H.,\n",
            "and Zhou, D. Self-consistency improves chain of thought\n",
            "reasoning in language models. CoRR , abs/2203.11171,\n",
            "2022a. doi: 10.48550/arXiv.2203.11171. URL https:\n",
            "//doi.org/10.48550/arXiv.2203.11171 .\n",
            "Wang, Y ., Mishra, S., Alipoormolabashi, P., Kordi, Y .,\n",
            "Mirzaei, A., Arunkumar, A., Ashok, A., Dhanasekaran,\n",
            "A. S., Naik, A., Stap, D., Pathak, E., Karamanolakis, G.,\n",
            "Lai, H. G., Purohit, I., Mondal, I., Anderson, J., Kuznia,\n",
            "K., Doshi, K., Patel, M., Pal, K. K., Moradshahi, M., Par-\n",
            "mar, M., Purohit, M., Varshney, N., Kaza, P. R., Verma,\n",
            "P., Puri, R. S., Karia, R., Sampat, S. K., Doshi, S., Mishra,\n",
            "S., Reddy, S., Patro, S., Dixit, T., Shen, X., Baral, C.,\n",
            "Choi, Y ., Smith, N. A., Hajishirzi, H., and Khashabi, D.\n",
            "Super-naturalinstructions: Generalization via declarative\n",
            "instructions on 1600+ nlp tasks, 2022b.\n",
            "Wei, J., Bosma, M., Zhao, V . Y ., Guu, K., Yu, A. W., Lester,\n",
            "B., Du, N., Dai, A. M., and Le, Q. V . Finetuned language\n",
            "models are zero-shot learners. In The Tenth Interna-\n",
            "tional Conference on Learning Representations, ICLR\n",
            "2022, Virtual Event, April 25-29, 2022 . OpenReview.net,\n",
            "2022a. URL https://openreview.net/forum?\n",
            "id=gEZrGCozdqR .Wei, J., Wang, X., Schuurmans, D., Bosma, M., Chi,\n",
            "E. H., Le, Q., and Zhou, D. Chain of thought prompt-\n",
            "ing elicits reasoning in large language models. CoRR ,\n",
            "abs/2201.11903, 2022b. URL https://arxiv.org/\n",
            "abs/2201.11903 .\n",
            "West, P., Bhagavatula, C., Hessel, J., Hwang, J. D., Jiang, L.,\n",
            "Bras, R. L., Lu, X., Welleck, S., and Choi, Y . Symbolic\n",
            "knowledge distillation: from general language models\n",
            "to commonsense models. In Carpuat, M., de Marneffe,\n",
            "M., and Ru ´ız, I. V . M. (eds.), Proceedings of the 2022\n",
            "Conference of the North American Chapter of the As-\n",
            "sociation for Computational Linguistics: Human Lan-\n",
            "guage Technologies, NAACL 2022, Seattle, WA, United\n",
            "States, July 10-15, 2022 , pp. 4602–4625. Association\n",
            "for Computational Linguistics, 2022. doi: 10.18653/v1/\n",
            "2022.naacl-main.341. URL https://doi.org/10.\n",
            "18653/v1/2022.naacl-main.341 .\n",
            "Yang, K., Klein, D., Peng, N., and Tian, Y . DOC: im-\n",
            "proving long story coherence with detailed outline con-\n",
            "trol. CoRR , abs/2212.10077, 2022. doi: 10.48550/arXiv.\n",
            "2212.10077. URL https://doi.org/10.48550/\n",
            "arXiv.2212.10077 .\n",
            "Ye, J., Gao, J., Li, Q., Xu, H., Feng, J., Wu, Z., Yu, T.,\n",
            "and Kong, L. Zerogen: Efﬁcient zero-shot learning via\n",
            "dataset generation. CoRR , abs/2202.07922, 2022a. URL\n",
            "Human: 'Chain-of-Thought'について説明して\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
            "Return any relevant text verbatim.\n",
            "______________________\n",
            "Synthetic Prompting: Generating Chain-of-Thought Demonstrations for Large Language Models\n",
            "of reasoning steps required to answer it, where a step is a\n",
            "line of code separated by a line break. For example, the\n",
            "complexity of Example 1 in Figure 1 (left) is 5, as it has\n",
            "5 lines of code. The target complexity for generating a\n",
            "question is randomly sampled from a range that spans from\n",
            "the lowest complexity of the seed examples to the highest\n",
            "one plusc.\n",
            "Self-generated reasoning chain We prompt the model to\n",
            "generate a reasoning chain of the target complexity for the\n",
            "given topic, and then generate a question based on the rea-\n",
            "soning chain. We ﬁnd that this approach leads to more an-\n",
            "swerable and well-deﬁned questions, compared to directly\n",
            "generating questions without a reasoning chain. To guide\n",
            "the model to follow the target complexity, we number each\n",
            "reasoning step in the demonstrations, e.g., #1and#2in Fig-\n",
            "ure 1 (left). We ﬁlter out the questions that are duplicated,\n",
            "repeat at least one 5-gram, or do not mention the given topic\n",
            "word.\n",
            "3.2.2. F ORWARD PROCESS\n",
            "The forward process aims to generate a reasoning chain\n",
            "for the question synthesized in the backward process. Fig-\n",
            "ure 1 (right) shows an example prompt for the forward\n",
            "process, which consists of the seed examples. Unlike chain-\n",
            "of-thought prompting, P AL prompting does not include the\n",
            "ﬁnal answers in the prompt, as the answers can be obtained\n",
            "by executing the generated code, rather than extracted from\n",
            "the model output. We observe that the reasoning chain gen-\n",
            "erated in the forward process is more relevant and precise\n",
            "than the one generated in the backward process, as it is\n",
            "directly conditioned on the question.\n",
            "We also want to ensure that the model is conﬁdent about\n",
            "the answer produced by the reasoning chain. Following\n",
            "Huang et al. (2022), we measure the conﬁdence of an an-\n",
            "swer by the proportion of sampled reasoning chains that\n",
            "lead to the same answer. For a question x, we sample m\n",
            "reasoning chains and obtain their answers {a1,a2,...,am}.\n",
            "We then ﬁnd the most consistent answer by majority vot-\n",
            "ing:ˆa= argmaxai∑m\n",
            "k=1 1(ai=ak). If more than m/2\n",
            "reasoning chains lead to ˆa, we associate the shortest one\n",
            "with the synthesized question; otherwise, we discard the\n",
            "question, as the model fails to produce conﬁdent reasoning\n",
            "chains for it. Note that majority voting is only used for syn-\n",
            "thesizing examples, not for inference (Section 3.3). This is\n",
            "different from Wang et al. (2022a), who use majority voting\n",
            "for inference.\n",
            "3.3. Inference Phase\n",
            "During inference, we select a subset of synthesized exam-\n",
            "ples as demonstrations for the model. According to Fu\n",
            "et al. (2022), selecting demonstrations based on complex-\n",
            "ity can improve the performance of the model on reason-ing tasks, compared to selecting them based on similarity.\n",
            "Moreover, selecting demonstrations based on similarity may\n",
            "introduce biases (Zhang et al., 2022b; Lyu et al., 2022) from\n",
            "the demonstrations, especially if they are incorrect. Fur-\n",
            "thermore, selecting demonstrations that are complementary\n",
            "to each other may help the model fuse knowledge from\n",
            "different types of reasoning (Ye et al., 2022b; Zhang et al.,\n",
            "2022b).\n",
            "Therefore, we propose an in-cluster complexity based\n",
            "scheme to select demonstrations that are both complex and\n",
            "complementary. Speciﬁcally, we cluster the synthesized\n",
            "examples in a semantic embedding space, using Sentence-\n",
            "BERT (Reimers & Gurevych, 2019) as the encoder. The\n",
            "number of clusters is equal to the number of demonstrations\n",
            "used for inference. We then choose the most complex exam-\n",
            "ple from each cluster as the demonstration. The inference\n",
            "process is the same as previous work like P AL prompt-\n",
            "ing, where the model completes a given prompt. The only\n",
            "difference is that the demonstrations in our prompts are\n",
            "synthesized from the seed examples, rather than ﬁxed to\n",
            "them.\n",
            "4. Experiments\n",
            "4.1. Datasets\n",
            "We experimented on seven datasets of different reasoning\n",
            "tasks. Examples are presented in Table 1.\n",
            "Human: 'Chain-of-Thought'について説明して\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
            "Return any relevant text verbatim.\n",
            "______________________\n",
            "Synthetic Prompting: Generating Chain-of-Thought Demonstrations for Large Language Models\n",
            "Datasets Example\n",
            "GSM8K Patrick has three glue sticks that are partially used. One has 1/6 left, the second has 2/3 left and\n",
            "the third one has 1/2 left. If a glue stick is 12 millimeters long originally, what is the total length\n",
            "of the glue sticks that are not used?\n",
            "Colored Objects On the nightstand, you see several items arranged in a row: a blue crayon, a red notebook, a teal\n",
            "bracelet, a magenta sheet of paper, a silver dog leash, and a black booklet. What is the color of the\n",
            "item furthest from the dog leash?\n",
            "Repeat Copy Repeat election to the council three times, but after every other word say cool\n",
            "Table 1: Examples from three datasets. Questions in the other numerical reasoning datasets resemble those in GSM8K.\n",
            "Following these settings, we assumed access to 2 or 4 ran-\n",
            "dom examples from each dataset by default. For numerical\n",
            "reasoning tasks, we also experimented with the 8 examples\n",
            "that were manually crafted by Wei et al. (2022b) and were\n",
            "adopted by several following papers (Fu et al., 2022; Wang\n",
            "et al., 2022a; Gao et al., 2022b). We also used the P AL-style\n",
            "reasoning chains annotated by Gao et al. (2022b).\n",
            "Prompting baselines without synthesis use all provided gold\n",
            "examples to construct prompts for inference. S YNTHETIC\n",
            "PROMPTING and its variants synthesize examples using the\n",
            "provided examples, and select 8 synthetic demonstrations\n",
            "based on in-cluster complexity, unless stated otherwise.\n",
            "Seed examples and synthetic prompts are provided in the\n",
            "Supplementary Materials.\n",
            "4.3. Baselines\n",
            "Direct Prompting Direct prompting (Brown et al., 2020)\n",
            "prompts LLMs to directly generate answers with demonstra-\n",
            "tions of input-answer pairs.\n",
            "CoT Prompting Chain-of-thought prompting (Wei et al.,\n",
            "2022b) is effective in eliciting reasoning in LLMs, which\n",
            "prompts LLMs to generate natural language reasoning steps\n",
            "followed by an answer.\n",
            "PAL Prompting PAL prompting (Gao et al., 2022b), a vari-\n",
            "ant of chain-of-thought prompting, improves reasoning with\n",
            "structured code. Figure 1 (right) provides two examples. It\n",
            "does not prompt LLMs to include ﬁnal answers into com-\n",
            "pletions; answers are obtained by executing the code. This\n",
            "prompting technique has achieved state-of-the-art results on\n",
            "numerous reasoning tasks.\n",
            "Vanilla S YNTHETIC PROMPTING This is a variant of\n",
            "SYNTHETIC PROMPTING , which differs in that prompts\n",
            "used for question synthesis only consist of questions from\n",
            "seed examples. In other words, new questions are syn-\n",
            "thesized by mimicking seed questions, without any other\n",
            "condition.4.4. Implementation Details\n",
            "We adopted P AL-style reasoning chains which are structured\n",
            "code with comments being natural language reasoning step.\n",
            "text-davinci-003 version of InstructGPT (Ouyang\n",
            "et al., 2022) was used as our backend LLM for both syn-\n",
            "thesis and inference. We used top-p sampling (Holtzman\n",
            "et al., 2020) for synthesis with temperature set to 0.7, and\n",
            "used greedy decoding for inference with temperature set to\n",
            "0. All numerical reasoning datasets share one set of seed\n",
            "examples either randomly sampled from GSM8K (when\n",
            "the number of seeds is 2 or 4) or from Wei et al. (2022b)\n",
            "(when the number of seeds is 8). For datasets of the other\n",
            "tasks, seeds were randomly sampled from their own datasets.\n",
            "We annotated seed examples with both CoT-style reasoning\n",
            "chains and P AL-style reasoning chains manually, following\n",
            "their annotation protocols. Annotations are provided in the\n",
            "Supplementary Materials. For each set of seed examples, we\n",
            "synthesized more examples by repeating backward-forward\n",
            "synthesis for 1,000 times. Target complexities range from\n",
            "the lowest complexity of seed examples to the highest one\n",
            "plusc;cwas set to 4 for numerical reasoning and 2 on the\n",
            "other datasets. In forward synthesis, the number of reason-\n",
            "ing chains sampled for each question was 3. The encoder\n",
            "used for clustering was all-mpnet-base-v2 .\n",
            "4.5. Main Results\n",
            "As shown by Table 2, S YNTHETIC PROMPTING consistently\n",
            "Human: 'Chain-of-Thought'について説明して\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
            "Return any relevant text verbatim.\n",
            "______________________\n",
            "Synthetic Prompting: Generating Chain-of-Thought Demonstrations for Large Language Models\n",
            "prompting.\n",
            "References\n",
            "Brown, T. B., Mann, B., Ryder, N., Subbiah, M., Kaplan,\n",
            "J., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G.,\n",
            "Askell, A., Agarwal, S., Herbert-V oss, A., Krueger, G.,\n",
            "Henighan, T., Child, R., Ramesh, A., Ziegler, D. M., Wu,\n",
            "J., Winter, C., Hesse, C., Chen, M., Sigler, E., Litwin, M.,\n",
            "Gray, S., Chess, B., Clark, J., Berner, C., McCandlish, S.,\n",
            "Radford, A., Sutskever, I., and Amodei, D. Language\n",
            "models are few-shot learners. In Larochelle, H.,\n",
            "Ranzato, M., Hadsell, R., Balcan, M., and Lin, H. (eds.),\n",
            "Advances in Neural Information Processing Systems 33:\n",
            "Annual Conference on Neural Information Processing\n",
            "Systems 2020, NeurIPS 2020, December 6-12, 2020,\n",
            "virtual , 2020. URL https://proceedings.\n",
            "neurips.cc/paper/2020/hash/\n",
            "1457c0d6bfcb4967418bfb8ac142f64a-Abstract.\n",
            "html .\n",
            "Chen, W., Ma, X., Wang, X., and Cohen, W. W. Pro-\n",
            "gram of thoughts prompting: Disentangling compu-\n",
            "tation from reasoning for numerical reasoning tasks.\n",
            "CoRR , abs/2211.12588, 2022. doi: 10.48550/arXiv.\n",
            "2211.12588. URL https://doi.org/10.48550/\n",
            "arXiv.2211.12588 .\n",
            "Chowdhery, A., Narang, S., Devlin, J., Bosma, M., Mishra,\n",
            "G., Roberts, A., Barham, P., Chung, H. W., Sutton,\n",
            "C., Gehrmann, S., Schuh, P., Shi, K., Tsvyashchenko,\n",
            "S., Maynez, J., Rao, A., Barnes, P., Tay, Y ., Shazeer,\n",
            "N., Prabhakaran, V ., Reif, E., Du, N., Hutchinson, B.,\n",
            "Pope, R., Bradbury, J., Austin, J., Isard, M., Gur-Ari,\n",
            "G., Yin, P., Duke, T., Levskaya, A., Ghemawat, S., Dev,\n",
            "S., Michalewski, H., Garcia, X., Misra, V ., Robinson,\n",
            "K., Fedus, L., Zhou, D., Ippolito, D., Luan, D., Lim,\n",
            "H., Zoph, B., Spiridonov, A., Sepassi, R., Dohan, D.,\n",
            "Agrawal, S., Omernick, M., Dai, A. M., Pillai, T. S., Pel-\n",
            "lat, M., Lewkowycz, A., Moreira, E., Child, R., Polozov,\n",
            "O., Lee, K., Zhou, Z., Wang, X., Saeta, B., Diaz, M.,\n",
            "Firat, O., Catasta, M., Wei, J., Meier-Hellstern, K., Eck,\n",
            "D., Dean, J., Petrov, S., and Fiedel, N. Palm: Scaling lan-\n",
            "guage modeling with pathways. CoRR , abs/2204.02311,\n",
            "2022. doi: 10.48550/arXiv.2204.02311. URL https:\n",
            "//doi.org/10.48550/arXiv.2204.02311 .\n",
            "Chung, H. W., Hou, L., Longpre, S., Zoph, B., Tay, Y .,\n",
            "Fedus, W., Li, E., Wang, X., Dehghani, M., Brahma, S.,\n",
            "Webson, A., Gu, S. S., Dai, Z., Suzgun, M., Chen, X.,\n",
            "Chowdhery, A., Narang, S., Mishra, G., Yu, A., Zhao,\n",
            "V . Y ., Huang, Y ., Dai, A. M., Yu, H., Petrov, S., Chi, E. H.,\n",
            "Dean, J., Devlin, J., Roberts, A., Zhou, D., Le, Q. V .,\n",
            "and Wei, J. Scaling instruction-ﬁnetuned language mod-\n",
            "els.CoRR , abs/2210.11416, 2022. doi: 10.48550/arXiv.2210.11416. URL https://doi.org/10.48550/\n",
            "arXiv.2210.11416 .\n",
            "Cobbe, K., Kosaraju, V ., Bavarian, M., Hilton, J., Nakano,\n",
            "R., Hesse, C., and Schulman, J. Training veriﬁers to solve\n",
            "math word problems. CoRR , abs/2110.14168, 2021. URL\n",
            "https://arxiv.org/abs/2110.14168 .\n",
            "Drozdov, A., Sch ¨arli, N., Aky ¨urek, E., Scales, N., Song,\n",
            "X., Chen, X., Bousquet, O., and Zhou, D. Compo-\n",
            "sitional semantic parsing with large language models.\n",
            "CoRR , abs/2209.15003, 2022. doi: 10.48550/arXiv.\n",
            "2209.15003. URL https://doi.org/10.48550/\n",
            "arXiv.2209.15003 .\n",
            "Fu, Y ., Peng, H., Sabharwal, A., Clark, P., and Khot,\n",
            "T. Complexity-based prompting for multi-step reason-\n",
            "ing. CoRR , abs/2210.00720, 2022. doi: 10.48550/arXiv.\n",
            "2210.00720. URL https://doi.org/10.48550/\n",
            "arXiv.2210.00720 .\n",
            "Gao, L., Dai, Z., Pasupat, P., Chen, A., Chaganty, A. T., Fan,\n",
            "Y ., Zhao, V . Y ., Lao, N., Lee, H., Juan, D.-C., and Guu,\n",
            "K. Rarr: Researching and revising what language models\n",
            "say, using language models, 2022a.\n",
            "Gao, L., Madaan, A., Zhou, S., Alon, U., Liu, P., Yang,\n",
            "Y ., Callan, J., and Neubig, G. PAL: program-aided lan-\n",
            "guage models. CoRR , abs/2211.10435, 2022b. doi: 10.\n",
            "48550/arXiv.2211.10435. URL https://doi.org/\n",
            "10.48550/arXiv.2211.10435 .\n",
            "Holtzman, A., Buys, J., Du, L., Forbes, M., and Choi, Y .\n",
            "The curious case of neural text degeneration. In 8th\n",
            "International Conference on Learning Representations,\n",
            "Human: 'Chain-of-Thought'について説明して\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
            "Return any relevant text verbatim.\n",
            "______________________\n",
            "Synthetic Prompting: Generating Chain-of-Thought Demonstrations for Large Language Models\n",
            "Koncel-Kedziorski, R., Roy, S., Amini, A., Kushman,\n",
            "N., and Hajishirzi, H. MAWPS: A math word prob-\n",
            "lem repository. In Knight, K., Nenkova, A., and Ram-\n",
            "bow, O. (eds.), NAACL HLT 2016, The 2016 Confer-\n",
            "ence of the North American Chapter of the Associa-\n",
            "tion for Computational Linguistics: Human Language\n",
            "Technologies, San Diego California, USA, June 12-17,\n",
            "2016 , pp. 1152–1157. The Association for Computational\n",
            "Linguistics, 2016. doi: 10.18653/v1/n16-1136. URL\n",
            "https://doi.org/10.18653/v1/n16-1136 .\n",
            "Li, Y ., Lin, Z., Zhang, S., Fu, Q., Chen, B., Lou, J.-G., and\n",
            "Chen, W. On the advance of making language models bet-\n",
            "ter reasoners. 2022. doi: 10.48550/ARXIV .2206.02336.\n",
            "URL https://arxiv.org/abs/2206.02336 .\n",
            "Liu, A., Swayamdipta, S., Smith, N. A., and Choi, Y .\n",
            "WANLI: worker and AI collaboration for natural language\n",
            "inference dataset creation. CoRR , abs/2201.05955, 2022a.\n",
            "URL https://arxiv.org/abs/2201.05955 .\n",
            "Liu, J., Shen, D., Zhang, Y ., Dolan, B., Carin, L., and\n",
            "Chen, W. What makes good in-context examples for\n",
            "gpt-3? In Agirre, E., Apidianaki, M., and Vulic, I.\n",
            "(eds.), Proceedings of Deep Learning Inside Out: The\n",
            "3rd Workshop on Knowledge Extraction and Integration\n",
            "for Deep Learning Architectures, DeeLIO@ACL 2022,\n",
            "Dublin, Ireland and Online, May 27, 2022 , pp. 100–114.\n",
            "Association for Computational Linguistics, 2022b. doi:\n",
            "10.18653/v1/2022.deelio-1.10. URL https://doi.\n",
            "org/10.18653/v1/2022.deelio-1.10 .\n",
            "Lyu, X., Min, S., Beltagy, I., Zettlemoyer, L., and Hajishirzi,\n",
            "H. Z-ICL: zero-shot in-context learning with pseudo-\n",
            "demonstrations. CoRR , abs/2212.09865, 2022. doi: 10.\n",
            "48550/arXiv.2212.09865. URL https://doi.org/\n",
            "10.48550/arXiv.2212.09865 .\n",
            "Miao, S., Liang, C., and Su, K. A diverse corpus for\n",
            "evaluating and developing english math word problem\n",
            "solvers. In Jurafsky, D., Chai, J., Schluter, N., and\n",
            "Tetreault, J. R. (eds.), Proceedings of the 58th Annual\n",
            "Meeting of the Association for Computational Linguis-\n",
            "tics, ACL 2020, Online, July 5-10, 2020 , pp. 975–984.\n",
            "Association for Computational Linguistics, 2020. doi:\n",
            "10.18653/v1/2020.acl-main.92. URL https://doi.\n",
            "org/10.18653/v1/2020.acl-main.92 .\n",
            "Ouyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright,\n",
            "C. L., Mishkin, P., Zhang, C., Agarwal, S., Slama, K.,\n",
            "Ray, A., Schulman, J., Hilton, J., Kelton, F., Miller,\n",
            "L., Simens, M., Askell, A., Welinder, P., Christiano,\n",
            "P. F., Leike, J., and Lowe, R. Training language\n",
            "models to follow instructions with human feedback.\n",
            "CoRR , abs/2203.02155, 2022. doi: 10.48550/arXiv.\n",
            "2203.02155. URL https://doi.org/10.48550/\n",
            "arXiv.2203.02155 .Patel, A., Bhattamishra, S., and Goyal, N. Are NLP\n",
            "models really able to solve simple math word prob-\n",
            "lems? In Toutanova, K., Rumshisky, A., Zettlemoyer,\n",
            "L., Hakkani-T ¨ur, D., Beltagy, I., Bethard, S., Cotterell,\n",
            "R., Chakraborty, T., and Zhou, Y . (eds.), Proceedings\n",
            "of the 2021 Conference of the North American Chapter\n",
            "of the Association for Computational Linguistics: Hu-\n",
            "man Language Technologies, NAACL-HLT 2021, On-\n",
            "line, June 6-11, 2021 , pp. 2080–2094. Association for\n",
            "Computational Linguistics, 2021. doi: 10.18653/v1/\n",
            "2021.naacl-main.168. URL https://doi.org/10.\n",
            "18653/v1/2021.naacl-main.168 .\n",
            "Pi, X., Liu, Q., Chen, B., Ziyadi, M., Lin, Z., Gao, Y .,\n",
            "Fu, Q., Lou, J., and Chen, W. Reasoning like program\n",
            "executors. CoRR , abs/2201.11473, 2022. URL https:\n",
            "//arxiv.org/abs/2201.11473 .\n",
            "Press, O., Zhang, M., Min, S., Schmidt, L., Smith, N. A.,\n",
            "and Lewis, M. Measuring and narrowing the composi-\n",
            "tionality gap in language models. CoRR , abs/2210.03350,\n",
            "2022. doi: 10.48550/arXiv.2210.03350. URL https:\n",
            "//doi.org/10.48550/arXiv.2210.03350 .\n",
            "Reimers, N. and Gurevych, I. Sentence-BERT: Sentence\n",
            "embeddings using Siamese BERT-networks. In Pro-\n",
            "ceedings of the 2019 Conference on Empirical Meth-\n",
            "ods in Natural Language Processing and the 9th In-\n",
            "ternational Joint Conference on Natural Language Pro-\n",
            "Human: 'Chain-of-Thought'について説明して\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
            "Return any relevant text verbatim.\n",
            "______________________\n",
            "Synthetic Prompting: Generating Chain-of-Thought Demonstrations for Large\n",
            "Language Models\n",
            "Zhihong Shao1 2Yeyun Gong3Yelong Shen4Minlie Huang1Nan Duan3Weizhu Chen4\n",
            "Abstract\n",
            "Large language models can perform various rea-\n",
            "soning tasks by using chain-of-thought prompting,\n",
            "which guides them to ﬁnd answers through step-\n",
            "by-step demonstrations. However, the quality of\n",
            "the prompts depends on the demonstrations given\n",
            "to the models, and creating many of them by hand\n",
            "is costly. We introduce S YNTHETIC PROMPTING ,\n",
            "a method that leverages a few handcrafted exam-\n",
            "ples to prompt the model to generate more exam-\n",
            "ples by itself, and selects effective demonstrations\n",
            "to elicit better reasoning. Our method alternates\n",
            "between a backward and forward process to gen-\n",
            "erate new examples. The backward process gen-\n",
            "erates a question that match a sampled reasoning\n",
            "chain, so that the question is solvable and clear.\n",
            "The forward process produces a more detailed\n",
            "reasoning chain for the question, improving the\n",
            "quality of the example. We evaluate our method\n",
            "on numerical, symbolic, and algorithmic reason-\n",
            "ing tasks, and show that it outperforms existing\n",
            "prompting techniques.\n",
            "1. Introduction\n",
            "Few-shot demonstrations, i.e., examples of inputs and out-\n",
            "puts for a task, can enable Large Language Models (LLMs)\n",
            "to perform various tasks without ﬁne-tuning (Brown et al.,\n",
            "2020; Chung et al., 2022). LLMs can further improve their\n",
            "performance by using chain-of-thought prompting, which\n",
            "provides intermediate reasoning steps for the task (Wei et al.,\n",
            "2022b; Kojima et al., 2022). However, the LLMs’ few-shot\n",
            "performance depends heavily on the quality of the demon-\n",
            "strations, especially for reasoning tasks that need complex\n",
            "and diverse reasoning patterns. Manually creating a large\n",
            "and diverse set of examples for demonstration selection is\n",
            "costly and tedious, while relying on a limited set of demon-\n",
            "strations may hamper the LLMs’ generalization and adapta-\n",
            "1Tsinghua University2This work was done during an internship\n",
            "in MSRA3Microsoft Research Asia4Microsoft. Correspondence\n",
            "to: Minlie Huang <aihuang@tsinghua.edu.cn >.tion to different test inputs.\n",
            "In this paper, we propose a novel method, S YNTHETIC\n",
            "PROMPTING , that leverages the LLMs’ own knowledge and\n",
            "generative power to augment a limited set of demonstra-\n",
            "tions with self-synthesized examples, and then uses the aug-\n",
            "mented set to elicit better reasoning in the LLMs. Specif-\n",
            "ically, given a few seed examples, each consisting of a\n",
            "question and a chain of reasoning steps, we prompt an\n",
            "LLM to generate more examples by alternating between\n",
            "two processes: (1) the backward process, where the LLM\n",
            "synthesizes a question based on a self-generated reasoning\n",
            "chain, which ensures that the question is answerable and\n",
            "well-deﬁned; and (2) the forward process, where the LLM\n",
            "produces a reasoning chain for the synthesized question,\n",
            "which reﬁnes the reasoning chain to be more precise and\n",
            "consistent with the question. We repeat this process until\n",
            "we obtain enough synthetic examples. To select the most\n",
            "effective demonstrations from the augmented set, we pro-\n",
            "pose a new selection scheme based on in-cluster complexity,\n",
            "which aims to maximize the diversity and informativeness\n",
            "of the demonstrations by clustering them and choosing the\n",
            "most complex one (the one with the longest reasoning chain)\n",
            "from each cluster. Finally, we prompt the LLM with the\n",
            "selected demonstrations to generate a reasoning chain for a\n",
            "test question and then use it to obtain the answer.\n",
            "We evaluate our method on various reasoning tasks, in-\n",
            "cluding numerical reasoning, algorithmic reasoning, and\n",
            "symbolic reasoning. Following previous few-shot settings\n",
            "(Wang et al., 2022b; Suzgun et al., 2022), we demonstrate\n",
            "that our method can signiﬁcantly improve the LLMs’ per-\n",
            "formance, achieving up to 15.6% absolute gains over the\n",
            "state-of-the-art methods.\n",
            "Our main contributions are:\n",
            "•We introduce S YNTHETIC PROMPTING , a novel\n",
            "method that augments a limited set of demonstrations\n",
            "Human: 'Chain-of-Thought'について説明して\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
            "Return any relevant text verbatim.\n",
            "______________________\n",
            "Synthetic Prompting: Generating Chain-of-Thought Demonstrations for Large Language Models\n",
            "augmented set for inference.\n",
            "•We demonstrate the effectiveness of our method on\n",
            "three reasoning tasks, achieving signiﬁcant improve-\n",
            "ments over previous methods.\n",
            "2. Related Work\n",
            "In-context few-shot learning With large-scale unsuper-\n",
            "vised pre-training, LLMs (Brown et al., 2020; Chowdh-\n",
            "ery et al., 2022; Zhang et al., 2022a) can learn to perform\n",
            "tasks by mimicking in-context demonstrations (Shin et al.,\n",
            "2022). To improve robustness to prompts, instruction tuning\n",
            "(Ouyang et al., 2022; Wei et al., 2022a; Sanh et al., 2022;\n",
            "Chung et al., 2022) has been proposed, which trains a lan-\n",
            "guage model on diverse tasks to generate desirable outputs\n",
            "that follow given instructions. With improved controllability,\n",
            "in-context learning-based applications ﬂourish, including\n",
            "text generation (Yang et al., 2022; Gao et al., 2022a), di-\n",
            "alogue generation (Thoppilan et al., 2022), and resource\n",
            "construction (West et al., 2022).\n",
            "Prompting techniques for reasoning Instead of directly\n",
            "generating an answer, chain-of-thought prompting (Wei\n",
            "et al., 2022b) prompts LLMs to arrive at an answer after\n",
            "a step-by-step reasoning process, which largely improves\n",
            "performance on numerous reasoning tasks. Following work\n",
            "like least-to-most prompting (Zhou et al., 2022), self-ask\n",
            "(Press et al., 2022), and decomposed prompting (Khot et al.,\n",
            "2022) also shares the spirit of question decomposition, i.e.,\n",
            "decomposing a complex question into a series of tractable\n",
            "sub-questions. All these methods produce natural language\n",
            "reasoning steps, which struggle with calculations and sym-\n",
            "bolic manipulations. Techniques like P AL prompting (Gao\n",
            "et al., 2022b) and program-of-thought prompting (Chen\n",
            "et al., 2022) propose to improve natural language reasoning\n",
            "with structured code, showing signiﬁcant improvements on\n",
            "arithmetic, symbolic and algorithmic tasks.\n",
            "Orthogonal to prompting workﬂows, there is also work that\n",
            "explores what make an effective demonstration. Metrics\n",
            "include (1) diversity, which selects complementary demon-\n",
            "strations so that models can fuse different reasoning (Li\n",
            "et al., 2022; Ye et al., 2022b) or be less biased by one type\n",
            "of reasoning (Zhang et al., 2022b); (2) reasoning complex-\n",
            "ity, which selects demonstrations with the highest reasoning\n",
            "complexity, and has been found to work well on numerical\n",
            "reasoning empirically (Fu et al., 2022); (3) similarity with a\n",
            "test input, which retrieves structurally (Drozdov et al., 2022)\n",
            "or semantically (Liu et al., 2022b) similar demonstrations.\n",
            "To ensure both diversity and informativeness of demonstra-\n",
            "tions, we propose a selection scheme based on in-cluster\n",
            "complexity to choose the most complex examples from ex-\n",
            "ample clusters. All these selection schemes assume access\n",
            "to a set of examples (whether annotated or not).Knowledge distillation from LLMs Some researches dis-\n",
            "tilled knowledge from LLMs into symbolic knowledge, e.g.,\n",
            "structured commonsense knowledge (West et al., 2022) or\n",
            "task-speciﬁc examples (Liu et al., 2022a; Ye et al., 2022a;\n",
            "Huang et al., 2022). These researches have at least one of\n",
            "the following characteristics: (1) assuming access to gold\n",
            "inputs from training sets without needing to generate them;\n",
            "(2) distilling knowledge based on collaboration between\n",
            "workers and AI; (3) using distilled knowledge for training.\n",
            "By contrast, we assume access to only a few gold examples,\n",
            "automatically synthesize more examples by prompting an\n",
            "LLM, and study whether synthesized examples can be lever-\n",
            "aged to better elicit reasoning in the model itself, without\n",
            "further training.\n",
            "3. Synthetic Prompting\n",
            "3.1. Overview\n",
            "To perform reasoning tasks with LLMs, given a few exam-\n",
            "ples each consisting of a question and a reasoning chain,\n",
            "it is common to directly concatenate them into a prompt\n",
            "for inference. In this paper, we instead treat them as seed\n",
            "examples, and prompt an LLM to automatically synthesize\n",
            "more by repeating a backward-forward procedure; the back-\n",
            "Human: 'Chain-of-Thought'について説明して\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
            "Return any relevant text verbatim.\n",
            "______________________\n",
            "Synthetic Prompting: Generating Chain-of-Thought Demonstrations for Large Language Models\n",
            "conditioned on reasoning chains affects correctness nega-\n",
            "tively; 62.5% are ﬂawed, 80% of which are unanswerable,\n",
            "e.g.,\n",
            "An image is represented by a 4x4 matrix of integers. Each\n",
            "cell of the matrix contains a single integer between 0 and\n",
            "255. What is the average value of all the integers in the\n",
            "matrix? .\n",
            "Notably, though we also include target complexities into the\n",
            "prompts when synthesizing questions without conditioned\n",
            "on reasoning chains, the resulting questions tend to require\n",
            "less reasoning steps than S YNTHETIC PROMPTING , indi-\n",
            "cating that conditioning on numbered reasoning steps can\n",
            "control reasoning complexities better.\n",
            "4.6.2. S CHEMES OF DEMONSTRATION SELECTION\n",
            "Datasets GSM8K Colored Objects\n",
            "# Seed Examples 2 4 2 4\n",
            "Random 73.4 73.1 83.0 90.0\n",
            "Cluster Centroid 73.1 73.0 91.2 93.6\n",
            "Similarity 72.9 74.0 87.0 94.2\n",
            "In-Cluster Similarity 72.9 73.2 89.3 95.4\n",
            "Complexity 74.1 74.3 92.7 97.5\n",
            "In-Cluster Complexity 74.7 75.3 93.8 97.3\n",
            "Table 5: Accuracies with different schemes of demonstra-\n",
            "tion selection.\n",
            "To make good use of synthesized examples, having an ef-\n",
            "fecitve selection scheme matters. We evaluated the follow-\n",
            "ing 6 selection schemes. (1) Random : randomly selects\n",
            "demonstrations; (2) Cluster Centroid : selects the example\n",
            "closest to each cluster centroid; (3) Similarity : retrieves\n",
            "the most similar examples according to cosine similarity;\n",
            "(4)In-Cluster Similarity : select the most similar example\n",
            "from each cluster; (5) Complexity : selects the examples\n",
            "with the most reasoning steps; (6) In-Cluster Complexity :\n",
            "selects the most complex example from each cluster.\n",
            "Table 5 presents the comparisons. Though most selection\n",
            "schemes achieve better performance than P AL prompting,\n",
            "complexity-based selection schemes are the most effective\n",
            "on the two reasoning tasks, with some other schemes like\n",
            "Random lagging far behind. Our proposed In-Cluster Com-\n",
            "plexity outperforms Complexity, showing the beneﬁts of\n",
            "using diverse and complex demonstrations.\n",
            "4.6.3. S ENSITIVITY TO SEED EXAMPLES\n",
            "To investigate how sensitive S YNTHETIC PROMPTING is\n",
            "to seed examples, we repeated experiments on another two\n",
            "random sets of seed examples. Figure 2 demonstrates our\n",
            "sensitivity analysis. S YNTHETIC PROMPTING consistently\n",
            "outperforms P AL prompting on different runs. However,\n",
            "72.97374.373.572.472.774.172.47475.174.874.8\n",
            "71.572.573.574.575.5\n",
            "2 Seed Examples2 Seed Examples4 Seed Examples4 Seed ExamplesGSM8KPAL PromptingVanilla Synthetic PromptingSynthetic Prompting\n",
            "88.685.995.393.294.791.787.491.894.194.495.997.7\n",
            "8588919497100\n",
            "2 Seed Examples2 Seed Examples4 Seed Examples4 Seed ExamplesColored ObjectsFigure 2: Sensitivity analysis on GSM8K and Colored Ob-\n",
            "jects. We experimented with another two random sets of\n",
            "seed examples of size 2 and 4 for each dataset.\n",
            "we observed that seed examples with better P AL prompting\n",
            "performance does not necessarily lead to better S YNTHETIC\n",
            "PROMPTING performance.\n",
            "4.7. Comparison with Selecting from Training\n",
            "Examples\n",
            "To measure the performance gap between using synthetic\n",
            "demonstrations and using gold demonstrations from a large\n",
            "set of carefully-curated examples, we selected 8 demon-\n",
            "strations from the training set of GSM8K with the two\n",
            "complexity-based selection schemes (i.e., Complexity and\n",
            "In-Cluster Complexity in Section 4.6.2), respectively. As\n",
            "the training examples were annotated with natural language\n",
            "reasoning chains (CoT-style reasoning), we measured the\n",
            "numbers of natural language reasoning steps as reasoning\n",
            "complexities for complexity-based selection, and manu-\n",
            "ally annotated selected examples with P AL-style reasoning\n",
            "chains for P AL prompting. As the training examples of\n",
            "GSM8K are diverse, both Complexity and In-Cluster Com-\n",
            "plexity select diverse and informative demonstrations, and\n",
            "yield an accuracy of 77.0% on the test set of GSM8K, sur-\n",
            "passing our accuracy of 75.3% by absolute 1.7%. As shown\n",
            "Human: 'Chain-of-Thought'について説明して\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
            "Return any relevant text verbatim.\n",
            "______________________\n",
            "Synthetic Prompting: Generating Chain-of-Thought Demonstrations for Large Language Models\n",
            "Target ComplexityTopic wordDemonstration\n",
            "Synthesized QuestionSelf-Generated Reasoning ChainExample 1Question: Cynthia eats one serving of ice cream every night. She buys cartons of ice cream with 15 servings of ice cream per carton at a cost of $4.00 per carton. After 60 days, how much will she spend on ice cream?def solution():servings_per_night= 1servings_per_carton= 15cost_per_carton= 4.00num_days= 60num_servings= num_days* servings_per_nightnum_cartons= num_servings/ servings_per_cartonmoney_spent= cost_per_carton* num_cartonsresult = money_spentreturn resultExample 2Question: A chef bought 4 bags of onions. Each bag weighs 50 pounds. A pound of onions cost $1.50. How much did the chef spend?def solution():num_bags_bought= 4weight_per_bag= 50cost_per_pound= 1.50cost_per_bag= weight_per_bag* cost_per_poundmoney_spent= num_bags_bought* cost_per_bagresult = money_spentreturn money_spent\n",
            "Forward ProcessDemonstration\n",
            "SynthesizedReasoning ChainExample 1# I implement a Python functioncalled solution()to solve the following question correctly.# The question is about work.def solution():””” 5-linefunction ”””# 1num_roses= 4# 2num_dahlias= num_roses+ 7# 3num_flowers= num_roses+ num_dahlias# 4result = num_flowers# 5return resultQuestion: There are 4 roses in the vase. There are 7 more dahlias than roses in the vase. How many flowers are there in the vase in total?Example 2# I implement a Python function called solution() to solve the following question correctly.# The question is about chef.def solution():””” 6-linefunction ”””# 1bags_of_onions= 4# 2weight_per_bag= 50# 3cost_per_bag= weight_per_bag* 1.50# 4money_spent= num_bags_bought* cost_per_bag# 5result = money_spent# 6return money_spentQuestion: A chef bought 4 bags of onions. Each bag weighs 50 pounds. A pound of onions cost $1.50. How much did the chef spend?Backward Process\n",
            "Figure 1: Example prompts and model completions in the backward process (left) and the forward process (right) of example\n",
            "synthesis. We show only one demonstration in each prompt for brevity. Self-Generated Reasoning Chain\n",
            "(in blue), Synthesized Question (in green), and Synthesized Reasoning Chain (in purple) are example\n",
            "completions. In the backward process, an LLM synthesizes a question conditioned on a topic word, a target reasoning\n",
            "complexity, and a generated reasoning chain. To better control the reasoning complexity, we number the reasoning steps,\n",
            "e.g.,# 1 and# 2 on the left. In the forward process, the LLM synthesizes a more precise reasoning chain for the question\n",
            "produced in the backward process. The question produced in the backward process and the corresponding reasoning chain\n",
            "produced in the forward process constitute a synthetic example.\n",
            "may require different types of reasoning. For example,\n",
            "questions about taxmay involve arithmetic operations,\n",
            "while questions about speed may involve unit conversions.\n",
            "To ensure diversity of the synthesized questions, we prompt\n",
            "the model to generate a question for a given topic word,\n",
            "which is randomly sampled from a set of words. The word\n",
            "set is created by prompting the model to list single-token\n",
            "noun words, following some random noun words from the\n",
            "seed examples. The instruction for generating the word set\n",
            "isList 50 noun words. Each word shouldcontain one token only. Do not repeat\n",
            "words already listed. , followed by no more than\n",
            "10 words from the seed examples. We repeat this process\n",
            "until we have 1,000 different words, or reach 100 repetitions\n",
            "of prompting.\n",
            "Target complexity We also want to control the complexity\n",
            "of the synthesized questions, as more complex examples\n",
            "may help the model learn better reasoning skills (Fu et al.,\n",
            "2022). We deﬁne the complexity of a question as the number\n",
            "Human: 'Chain-of-Thought'について説明して\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
            "Return any relevant text verbatim.\n",
            "______________________\n",
            "of in-context demonstrations. We show that by prompting\n",
            "a large language model to synthesize more examples, we\n",
            "can improve its reasoning performance on numerical, sym-\n",
            "bolic, and algorithmic tasks, compared to existing prompt-\n",
            "ing methods such as chain-of-thought prompting and P AL\n",
            "Human: 'Chain-of-Thought'について説明して\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: Given the following extracted parts of a long document and a question, create a final answer. \n",
            "If you don't know the answer, just say that you don't know. Don't try to make up an answer.\n",
            "______________________\n",
            "\"Chain-of-Thought\"は、大規模な言語モデルにおいて、連鎖的な思考プロセスを生成する手法です。この手法では、与えられたテキストやプロンプトに基づいて、モデルが一貫性のある論理的な思考の流れを生成することを目指します。つまり、モデルが与えられた情報を適切に結びつけ、関連性のある情報を生成することで、より自然な文章や回答を生成することが期待されます。この手法は、自然言語処理のタスクにおいて、より高度な推論や論理的な思考が必要な場合に有用です。\n",
            "\n",
            "Chain-of-Thought（思考の連鎖）は、大規模な言語モデルに対して生成される推論のステップの連鎖です。このアプローチでは、与えられたトピックに関連する推論の連鎖を生成し、それに基づいて質問を生成します。モデルが目標の複雑さに従うようにするために、各推論ステップに番号を付け、与えられたトピックの言及がない、重複した質問、または少なくとも1つの5-gramを繰り返す質問をフィルタリングします。このアプローチは、より回答可能で明確な質問を生成することができます。\n",
            "\n",
            "Chain-of-Thought（思考の連鎖）は、大規模な言語モデルに対して推論を促すための手法です。この手法では、言語モデルに自然言語の推論ステップを生成させ、最終的な答えを導くように促します。具体的には、言語モデルに対して質問を提示し、それに対する推論ステップを生成させ、最終的な答えを導き出します。この手法は、言語モデルが論理的な推論を行うことを促すため、多くの推論タスクで効果的な結果を示しています。\n",
            "\n",
            "申し訳ありませんが、与えられたテキストでは「Chain-of-Thought」についての説明は見つかりませんでした。\n",
            "\n",
            "申し訳ありませんが、与えられたテキストには「Chain-of-Thought」という用語に関する情報は含まれていません。\n",
            "\n",
            "Chain-of-Thought（思考の連鎖）は、大規模言語モデルが論理的な推論タスクを実行するための手法です。この手法では、モデルがステップバイステップのデモンストレーションを通じて答えを見つけるように導かれます。しかし、プロンプトの品質はモデルに与えられるデモンストレーションに依存します。手作業で多くのデモンストレーションを作成することはコストがかかります。そこで、私たちは「SYNTHETIC PROMPTING」という手法を提案しています。この手法は、少数の手作業の例を活用してモデルに自己生成の例を生成させ、効果的なデモンストレーションを選択することで、推論をより良く引き出します。この手法は、逆方向と順方向のプロセスを交互に繰り返すことで新しい例を生成します。逆方向のプロセスでは、サンプリングされた推論チェーンに一致する質問を生成し、解決可能で明確な質問を生成します。順方向のプロセスでは、生成された質問に対するより詳細な推論チェーンを生成し、例の品質を向上させます。このプロセスを繰り返して十分な数の合成例を得ます。そして、拡張されたセットから最も効果的なデモンストレーションを選択するために、クラスタリングとクラスタ内の複雑さに基づいた新しい選択手法を提案します。最終的に、選択されたデモンストレーションを使用してモデルにテストの質問の推論チェーンを生成させ、それを使用して答えを得ます。\n",
            "\n",
            "Chain-of-Thought（思考の連鎖）は、大規模な言語モデルを使用して推論を行う際に使用される手法です。この手法では、いくつかの例文（質問と推論の連鎖からなる）を与え、言語モデルによって自動的に追加の例文を合成します。具体的には、逆方向から順方向への手順を繰り返し、言語モデルによって新たな例文を生成します。このようにして合成された例文は、モデル自体の推論を引き出すために活用されます。Chain-of-Thought手法は、推論タスクにおいて従来の方法よりも高い性能を実現することが示されています。\n",
            "\n",
            "この文書の一部では、\"Chain-of-Thought\"という言葉についての説明は見つかりません。\n",
            "\n",
            "この文書の一部では、大規模な言語モデルに対して「Chain-of-Thought」の生成について説明されています。具体的には、逆方向プロセスと順方向プロセスの2つの方法で、モデルが自己生成された推論チェーンに基づいて質問や解答を生成する方法が示されています。逆方向プロセスでは、トピックワード、目標の複雑さ、生成された推論チェーンに基づいて質問を生成し、順方向プロセスでは逆方向プロセスで生成された質問に対してより具体的な推論チェーンを生成します。これにより、モデルは推論の複雑さを制御しながら、多様な質問と推論の例を生成することができます。\n",
            "\n",
            "「Chain-of-Thought」とは、大規模な言語モデルに対して提示するプロンプトの一種です。この方法では、関連する文脈の中で論理的なつながりを持つ複数の文を提示することで、モデルの推論能力を向上させることができます。これにより、数値、記号、アルゴリズムに関連するタスクにおいて、既存のプロンプト方法よりも優れた結果を得ることができます。\n",
            "Human: 'Chain-of-Thought'について説明して\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## コスト計算"
      ],
      "metadata": {
        "id": "En-0MG5wA1eR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.callbacks import get_openai_callback\n",
        "def ask(qa, query):\n",
        "    with get_openai_callback() as cb:\n",
        "        answer = qa(query)\n",
        "\n",
        "    return answer, cb.total_cost"
      ],
      "metadata": {
        "id": "TVk-JG4z9VKW"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "retriever = docsearch.as_retriever(search_kwargs={\"k\":10})\n",
        "llm = ChatOpenAI(temperature=0, streaming=True)\n",
        "qa = RetrievalQA.from_chain_type(\n",
        "        llm=llm,\n",
        "        #chain_type=\"stuff\",\n",
        "        chain_type=\"map_rerank\",\n",
        "        retriever=retriever,\n",
        "        return_source_documents=True,\n",
        "        verbose=True\n",
        "    )"
      ],
      "metadata": {
        "id": "hAbwb_9QBhEy"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer, cost = ask(qa,\"'Chain-of-Thought'について説明して\")\n",
        "print(answer)\n",
        "print(cost)"
      ],
      "metadata": {
        "id": "TjkW5XwI93XA",
        "outputId": "7e78cbfd-5257-4746-c41c-9186ef6e63e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new MapRerankDocumentsChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
            "\n",
            "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
            "\n",
            "Question: [question here]\n",
            "Helpful Answer: [answer here]\n",
            "Score: [score between 0 and 100]\n",
            "\n",
            "How to determine the score:\n",
            "- Higher is a better answer\n",
            "- Better responds fully to the asked question, with sufficient level of detail\n",
            "- If you do not know the answer based on the context, that should be a score of 0\n",
            "- Don't be overconfident!\n",
            "\n",
            "Example #1\n",
            "\n",
            "Context:\n",
            "---------\n",
            "Apples are red\n",
            "---------\n",
            "Question: what color are apples?\n",
            "Helpful Answer: red\n",
            "Score: 100\n",
            "\n",
            "Example #2\n",
            "\n",
            "Context:\n",
            "---------\n",
            "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
            "---------\n",
            "Question: what type was the car?\n",
            "Helpful Answer: a sports car or an suv\n",
            "Score: 60\n",
            "\n",
            "Example #3\n",
            "\n",
            "Context:\n",
            "---------\n",
            "Pears are either red or orange\n",
            "---------\n",
            "Question: what color are apples?\n",
            "Helpful Answer: This document does not answer the question\n",
            "Score: 0\n",
            "\n",
            "Begin!\n",
            "\n",
            "Context:\n",
            "---------\n",
            "Synthetic Prompting: Generating Chain-of-Thought Demonstrations for Large Language Models\n",
            "Association for Computational Linguistics: Human Lan-\n",
            "guage Technologies, NAACL 2022, Seattle, WA, United\n",
            "States, July 10-15, 2022 , pp. 5168–5186. Association\n",
            "for Computational Linguistics, 2022. doi: 10.18653/v1/\n",
            "2022.naacl-main.380. URL https://doi.org/10.\n",
            "18653/v1/2022.naacl-main.380 .\n",
            "Suzgun, M., Scales, N., Sch ¨arli, N., Gehrmann, S., Tay, Y .,\n",
            "Chung, H. W., Chowdhery, A., Le, Q. V ., Chi, E. H., Zhou,\n",
            "D., and Wei, J. Challenging big-bench tasks and whether\n",
            "chain-of-thought can solve them. CoRR , abs/2210.09261,\n",
            "2022. doi: 10.48550/arXiv.2210.09261. URL https:\n",
            "//doi.org/10.48550/arXiv.2210.09261 .\n",
            "Thoppilan, R., Freitas, D. D., Hall, J., Shazeer, N., Kul-\n",
            "shreshtha, A., Cheng, H., Jin, A., Bos, T., Baker, L., Du,\n",
            "Y ., Li, Y ., Lee, H., Zheng, H. S., Ghafouri, A., Mene-\n",
            "gali, M., Huang, Y ., Krikun, M., Lepikhin, D., Qin, J.,\n",
            "Chen, D., Xu, Y ., Chen, Z., Roberts, A., Bosma, M.,\n",
            "Zhou, Y ., Chang, C., Krivokon, I., Rusch, W., Pickett,\n",
            "M., Meier-Hellstern, K. S., Morris, M. R., Doshi, T.,\n",
            "Santos, R. D., Duke, T., Soraker, J., Zevenbergen, B.,\n",
            "Prabhakaran, V ., Diaz, M., Hutchinson, B., Olson, K.,\n",
            "Molina, A., Hoffman-John, E., Lee, J., Aroyo, L., Ra-\n",
            "jakumar, R., Butryna, A., Lamm, M., Kuzmina, V ., Fen-\n",
            "ton, J., Cohen, A., Bernstein, R., Kurzweil, R., Aguera-\n",
            "Arcas, B., Cui, C., Croak, M., Chi, E. H., and Le, Q.\n",
            "Lamda: Language models for dialog applications. CoRR ,\n",
            "abs/2201.08239, 2022. URL https://arxiv.org/\n",
            "abs/2201.08239 .\n",
            "Wang, X., Wei, J., Schuurmans, D., Le, Q. V ., Chi, E. H.,\n",
            "and Zhou, D. Self-consistency improves chain of thought\n",
            "reasoning in language models. CoRR , abs/2203.11171,\n",
            "2022a. doi: 10.48550/arXiv.2203.11171. URL https:\n",
            "//doi.org/10.48550/arXiv.2203.11171 .\n",
            "Wang, Y ., Mishra, S., Alipoormolabashi, P., Kordi, Y .,\n",
            "Mirzaei, A., Arunkumar, A., Ashok, A., Dhanasekaran,\n",
            "A. S., Naik, A., Stap, D., Pathak, E., Karamanolakis, G.,\n",
            "Lai, H. G., Purohit, I., Mondal, I., Anderson, J., Kuznia,\n",
            "K., Doshi, K., Patel, M., Pal, K. K., Moradshahi, M., Par-\n",
            "mar, M., Purohit, M., Varshney, N., Kaza, P. R., Verma,\n",
            "P., Puri, R. S., Karia, R., Sampat, S. K., Doshi, S., Mishra,\n",
            "S., Reddy, S., Patro, S., Dixit, T., Shen, X., Baral, C.,\n",
            "Choi, Y ., Smith, N. A., Hajishirzi, H., and Khashabi, D.\n",
            "Super-naturalinstructions: Generalization via declarative\n",
            "instructions on 1600+ nlp tasks, 2022b.\n",
            "Wei, J., Bosma, M., Zhao, V . Y ., Guu, K., Yu, A. W., Lester,\n",
            "B., Du, N., Dai, A. M., and Le, Q. V . Finetuned language\n",
            "models are zero-shot learners. In The Tenth Interna-\n",
            "tional Conference on Learning Representations, ICLR\n",
            "2022, Virtual Event, April 25-29, 2022 . OpenReview.net,\n",
            "2022a. URL https://openreview.net/forum?\n",
            "id=gEZrGCozdqR .Wei, J., Wang, X., Schuurmans, D., Bosma, M., Chi,\n",
            "E. H., Le, Q., and Zhou, D. Chain of thought prompt-\n",
            "ing elicits reasoning in large language models. CoRR ,\n",
            "abs/2201.11903, 2022b. URL https://arxiv.org/\n",
            "abs/2201.11903 .\n",
            "West, P., Bhagavatula, C., Hessel, J., Hwang, J. D., Jiang, L.,\n",
            "Bras, R. L., Lu, X., Welleck, S., and Choi, Y . Symbolic\n",
            "knowledge distillation: from general language models\n",
            "to commonsense models. In Carpuat, M., de Marneffe,\n",
            "M., and Ru ´ız, I. V . M. (eds.), Proceedings of the 2022\n",
            "Conference of the North American Chapter of the As-\n",
            "sociation for Computational Linguistics: Human Lan-\n",
            "guage Technologies, NAACL 2022, Seattle, WA, United\n",
            "States, July 10-15, 2022 , pp. 4602–4625. Association\n",
            "for Computational Linguistics, 2022. doi: 10.18653/v1/\n",
            "2022.naacl-main.341. URL https://doi.org/10.\n",
            "18653/v1/2022.naacl-main.341 .\n",
            "Yang, K., Klein, D., Peng, N., and Tian, Y . DOC: im-\n",
            "proving long story coherence with detailed outline con-\n",
            "trol. CoRR , abs/2212.10077, 2022. doi: 10.48550/arXiv.\n",
            "2212.10077. URL https://doi.org/10.48550/\n",
            "arXiv.2212.10077 .\n",
            "Ye, J., Gao, J., Li, Q., Xu, H., Feng, J., Wu, Z., Yu, T.,\n",
            "and Kong, L. Zerogen: Efﬁcient zero-shot learning via\n",
            "dataset generation. CoRR , abs/2202.07922, 2022a. URL\n",
            "---------\n",
            "Question: 'Chain-of-Thought'について説明して\n",
            "Helpful Answer:\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
            "\n",
            "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
            "\n",
            "Question: [question here]\n",
            "Helpful Answer: [answer here]\n",
            "Score: [score between 0 and 100]\n",
            "\n",
            "How to determine the score:\n",
            "- Higher is a better answer\n",
            "- Better responds fully to the asked question, with sufficient level of detail\n",
            "- If you do not know the answer based on the context, that should be a score of 0\n",
            "- Don't be overconfident!\n",
            "\n",
            "Example #1\n",
            "\n",
            "Context:\n",
            "---------\n",
            "Apples are red\n",
            "---------\n",
            "Question: what color are apples?\n",
            "Helpful Answer: red\n",
            "Score: 100\n",
            "\n",
            "Example #2\n",
            "\n",
            "Context:\n",
            "---------\n",
            "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
            "---------\n",
            "Question: what type was the car?\n",
            "Helpful Answer: a sports car or an suv\n",
            "Score: 60\n",
            "\n",
            "Example #3\n",
            "\n",
            "Context:\n",
            "---------\n",
            "Pears are either red or orange\n",
            "---------\n",
            "Question: what color are apples?\n",
            "Helpful Answer: This document does not answer the question\n",
            "Score: 0\n",
            "\n",
            "Begin!\n",
            "\n",
            "Context:\n",
            "---------\n",
            "Synthetic Prompting: Generating Chain-of-Thought Demonstrations for Large Language Models\n",
            "of reasoning steps required to answer it, where a step is a\n",
            "line of code separated by a line break. For example, the\n",
            "complexity of Example 1 in Figure 1 (left) is 5, as it has\n",
            "5 lines of code. The target complexity for generating a\n",
            "question is randomly sampled from a range that spans from\n",
            "the lowest complexity of the seed examples to the highest\n",
            "one plusc.\n",
            "Self-generated reasoning chain We prompt the model to\n",
            "generate a reasoning chain of the target complexity for the\n",
            "given topic, and then generate a question based on the rea-\n",
            "soning chain. We ﬁnd that this approach leads to more an-\n",
            "swerable and well-deﬁned questions, compared to directly\n",
            "generating questions without a reasoning chain. To guide\n",
            "the model to follow the target complexity, we number each\n",
            "reasoning step in the demonstrations, e.g., #1and#2in Fig-\n",
            "ure 1 (left). We ﬁlter out the questions that are duplicated,\n",
            "repeat at least one 5-gram, or do not mention the given topic\n",
            "word.\n",
            "3.2.2. F ORWARD PROCESS\n",
            "The forward process aims to generate a reasoning chain\n",
            "for the question synthesized in the backward process. Fig-\n",
            "ure 1 (right) shows an example prompt for the forward\n",
            "process, which consists of the seed examples. Unlike chain-\n",
            "of-thought prompting, P AL prompting does not include the\n",
            "ﬁnal answers in the prompt, as the answers can be obtained\n",
            "by executing the generated code, rather than extracted from\n",
            "the model output. We observe that the reasoning chain gen-\n",
            "erated in the forward process is more relevant and precise\n",
            "than the one generated in the backward process, as it is\n",
            "directly conditioned on the question.\n",
            "We also want to ensure that the model is conﬁdent about\n",
            "the answer produced by the reasoning chain. Following\n",
            "Huang et al. (2022), we measure the conﬁdence of an an-\n",
            "swer by the proportion of sampled reasoning chains that\n",
            "lead to the same answer. For a question x, we sample m\n",
            "reasoning chains and obtain their answers {a1,a2,...,am}.\n",
            "We then ﬁnd the most consistent answer by majority vot-\n",
            "ing:ˆa= argmaxai∑m\n",
            "k=1 1(ai=ak). If more than m/2\n",
            "reasoning chains lead to ˆa, we associate the shortest one\n",
            "with the synthesized question; otherwise, we discard the\n",
            "question, as the model fails to produce conﬁdent reasoning\n",
            "chains for it. Note that majority voting is only used for syn-\n",
            "thesizing examples, not for inference (Section 3.3). This is\n",
            "different from Wang et al. (2022a), who use majority voting\n",
            "for inference.\n",
            "3.3. Inference Phase\n",
            "During inference, we select a subset of synthesized exam-\n",
            "ples as demonstrations for the model. According to Fu\n",
            "et al. (2022), selecting demonstrations based on complex-\n",
            "ity can improve the performance of the model on reason-ing tasks, compared to selecting them based on similarity.\n",
            "Moreover, selecting demonstrations based on similarity may\n",
            "introduce biases (Zhang et al., 2022b; Lyu et al., 2022) from\n",
            "the demonstrations, especially if they are incorrect. Fur-\n",
            "thermore, selecting demonstrations that are complementary\n",
            "to each other may help the model fuse knowledge from\n",
            "different types of reasoning (Ye et al., 2022b; Zhang et al.,\n",
            "2022b).\n",
            "Therefore, we propose an in-cluster complexity based\n",
            "scheme to select demonstrations that are both complex and\n",
            "complementary. Speciﬁcally, we cluster the synthesized\n",
            "examples in a semantic embedding space, using Sentence-\n",
            "BERT (Reimers & Gurevych, 2019) as the encoder. The\n",
            "number of clusters is equal to the number of demonstrations\n",
            "used for inference. We then choose the most complex exam-\n",
            "ple from each cluster as the demonstration. The inference\n",
            "process is the same as previous work like P AL prompt-\n",
            "ing, where the model completes a given prompt. The only\n",
            "difference is that the demonstrations in our prompts are\n",
            "synthesized from the seed examples, rather than ﬁxed to\n",
            "them.\n",
            "4. Experiments\n",
            "4.1. Datasets\n",
            "We experimented on seven datasets of different reasoning\n",
            "tasks. Examples are presented in Table 1.\n",
            "---------\n",
            "Question: 'Chain-of-Thought'について説明して\n",
            "Helpful Answer:\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
            "\n",
            "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
            "\n",
            "Question: [question here]\n",
            "Helpful Answer: [answer here]\n",
            "Score: [score between 0 and 100]\n",
            "\n",
            "How to determine the score:\n",
            "- Higher is a better answer\n",
            "- Better responds fully to the asked question, with sufficient level of detail\n",
            "- If you do not know the answer based on the context, that should be a score of 0\n",
            "- Don't be overconfident!\n",
            "\n",
            "Example #1\n",
            "\n",
            "Context:\n",
            "---------\n",
            "Apples are red\n",
            "---------\n",
            "Question: what color are apples?\n",
            "Helpful Answer: red\n",
            "Score: 100\n",
            "\n",
            "Example #2\n",
            "\n",
            "Context:\n",
            "---------\n",
            "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
            "---------\n",
            "Question: what type was the car?\n",
            "Helpful Answer: a sports car or an suv\n",
            "Score: 60\n",
            "\n",
            "Example #3\n",
            "\n",
            "Context:\n",
            "---------\n",
            "Pears are either red or orange\n",
            "---------\n",
            "Question: what color are apples?\n",
            "Helpful Answer: This document does not answer the question\n",
            "Score: 0\n",
            "\n",
            "Begin!\n",
            "\n",
            "Context:\n",
            "---------\n",
            "Synthetic Prompting: Generating Chain-of-Thought Demonstrations for Large Language Models\n",
            "Datasets Example\n",
            "GSM8K Patrick has three glue sticks that are partially used. One has 1/6 left, the second has 2/3 left and\n",
            "the third one has 1/2 left. If a glue stick is 12 millimeters long originally, what is the total length\n",
            "of the glue sticks that are not used?\n",
            "Colored Objects On the nightstand, you see several items arranged in a row: a blue crayon, a red notebook, a teal\n",
            "bracelet, a magenta sheet of paper, a silver dog leash, and a black booklet. What is the color of the\n",
            "item furthest from the dog leash?\n",
            "Repeat Copy Repeat election to the council three times, but after every other word say cool\n",
            "Table 1: Examples from three datasets. Questions in the other numerical reasoning datasets resemble those in GSM8K.\n",
            "Following these settings, we assumed access to 2 or 4 ran-\n",
            "dom examples from each dataset by default. For numerical\n",
            "reasoning tasks, we also experimented with the 8 examples\n",
            "that were manually crafted by Wei et al. (2022b) and were\n",
            "adopted by several following papers (Fu et al., 2022; Wang\n",
            "et al., 2022a; Gao et al., 2022b). We also used the P AL-style\n",
            "reasoning chains annotated by Gao et al. (2022b).\n",
            "Prompting baselines without synthesis use all provided gold\n",
            "examples to construct prompts for inference. S YNTHETIC\n",
            "PROMPTING and its variants synthesize examples using the\n",
            "provided examples, and select 8 synthetic demonstrations\n",
            "based on in-cluster complexity, unless stated otherwise.\n",
            "Seed examples and synthetic prompts are provided in the\n",
            "Supplementary Materials.\n",
            "4.3. Baselines\n",
            "Direct Prompting Direct prompting (Brown et al., 2020)\n",
            "prompts LLMs to directly generate answers with demonstra-\n",
            "tions of input-answer pairs.\n",
            "CoT Prompting Chain-of-thought prompting (Wei et al.,\n",
            "2022b) is effective in eliciting reasoning in LLMs, which\n",
            "prompts LLMs to generate natural language reasoning steps\n",
            "followed by an answer.\n",
            "PAL Prompting PAL prompting (Gao et al., 2022b), a vari-\n",
            "ant of chain-of-thought prompting, improves reasoning with\n",
            "structured code. Figure 1 (right) provides two examples. It\n",
            "does not prompt LLMs to include ﬁnal answers into com-\n",
            "pletions; answers are obtained by executing the code. This\n",
            "prompting technique has achieved state-of-the-art results on\n",
            "numerous reasoning tasks.\n",
            "Vanilla S YNTHETIC PROMPTING This is a variant of\n",
            "SYNTHETIC PROMPTING , which differs in that prompts\n",
            "used for question synthesis only consist of questions from\n",
            "seed examples. In other words, new questions are syn-\n",
            "thesized by mimicking seed questions, without any other\n",
            "condition.4.4. Implementation Details\n",
            "We adopted P AL-style reasoning chains which are structured\n",
            "code with comments being natural language reasoning step.\n",
            "text-davinci-003 version of InstructGPT (Ouyang\n",
            "et al., 2022) was used as our backend LLM for both syn-\n",
            "thesis and inference. We used top-p sampling (Holtzman\n",
            "et al., 2020) for synthesis with temperature set to 0.7, and\n",
            "used greedy decoding for inference with temperature set to\n",
            "0. All numerical reasoning datasets share one set of seed\n",
            "examples either randomly sampled from GSM8K (when\n",
            "the number of seeds is 2 or 4) or from Wei et al. (2022b)\n",
            "(when the number of seeds is 8). For datasets of the other\n",
            "tasks, seeds were randomly sampled from their own datasets.\n",
            "We annotated seed examples with both CoT-style reasoning\n",
            "chains and P AL-style reasoning chains manually, following\n",
            "their annotation protocols. Annotations are provided in the\n",
            "Supplementary Materials. For each set of seed examples, we\n",
            "synthesized more examples by repeating backward-forward\n",
            "synthesis for 1,000 times. Target complexities range from\n",
            "the lowest complexity of seed examples to the highest one\n",
            "plusc;cwas set to 4 for numerical reasoning and 2 on the\n",
            "other datasets. In forward synthesis, the number of reason-\n",
            "ing chains sampled for each question was 3. The encoder\n",
            "used for clustering was all-mpnet-base-v2 .\n",
            "4.5. Main Results\n",
            "As shown by Table 2, S YNTHETIC PROMPTING consistently\n",
            "---------\n",
            "Question: 'Chain-of-Thought'について説明して\n",
            "Helpful Answer:\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
            "\n",
            "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
            "\n",
            "Question: [question here]\n",
            "Helpful Answer: [answer here]\n",
            "Score: [score between 0 and 100]\n",
            "\n",
            "How to determine the score:\n",
            "- Higher is a better answer\n",
            "- Better responds fully to the asked question, with sufficient level of detail\n",
            "- If you do not know the answer based on the context, that should be a score of 0\n",
            "- Don't be overconfident!\n",
            "\n",
            "Example #1\n",
            "\n",
            "Context:\n",
            "---------\n",
            "Apples are red\n",
            "---------\n",
            "Question: what color are apples?\n",
            "Helpful Answer: red\n",
            "Score: 100\n",
            "\n",
            "Example #2\n",
            "\n",
            "Context:\n",
            "---------\n",
            "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
            "---------\n",
            "Question: what type was the car?\n",
            "Helpful Answer: a sports car or an suv\n",
            "Score: 60\n",
            "\n",
            "Example #3\n",
            "\n",
            "Context:\n",
            "---------\n",
            "Pears are either red or orange\n",
            "---------\n",
            "Question: what color are apples?\n",
            "Helpful Answer: This document does not answer the question\n",
            "Score: 0\n",
            "\n",
            "Begin!\n",
            "\n",
            "Context:\n",
            "---------\n",
            "Synthetic Prompting: Generating Chain-of-Thought Demonstrations for Large Language Models\n",
            "prompting.\n",
            "References\n",
            "Brown, T. B., Mann, B., Ryder, N., Subbiah, M., Kaplan,\n",
            "J., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G.,\n",
            "Askell, A., Agarwal, S., Herbert-V oss, A., Krueger, G.,\n",
            "Henighan, T., Child, R., Ramesh, A., Ziegler, D. M., Wu,\n",
            "J., Winter, C., Hesse, C., Chen, M., Sigler, E., Litwin, M.,\n",
            "Gray, S., Chess, B., Clark, J., Berner, C., McCandlish, S.,\n",
            "Radford, A., Sutskever, I., and Amodei, D. Language\n",
            "models are few-shot learners. In Larochelle, H.,\n",
            "Ranzato, M., Hadsell, R., Balcan, M., and Lin, H. (eds.),\n",
            "Advances in Neural Information Processing Systems 33:\n",
            "Annual Conference on Neural Information Processing\n",
            "Systems 2020, NeurIPS 2020, December 6-12, 2020,\n",
            "virtual , 2020. URL https://proceedings.\n",
            "neurips.cc/paper/2020/hash/\n",
            "1457c0d6bfcb4967418bfb8ac142f64a-Abstract.\n",
            "html .\n",
            "Chen, W., Ma, X., Wang, X., and Cohen, W. W. Pro-\n",
            "gram of thoughts prompting: Disentangling compu-\n",
            "tation from reasoning for numerical reasoning tasks.\n",
            "CoRR , abs/2211.12588, 2022. doi: 10.48550/arXiv.\n",
            "2211.12588. URL https://doi.org/10.48550/\n",
            "arXiv.2211.12588 .\n",
            "Chowdhery, A., Narang, S., Devlin, J., Bosma, M., Mishra,\n",
            "G., Roberts, A., Barham, P., Chung, H. W., Sutton,\n",
            "C., Gehrmann, S., Schuh, P., Shi, K., Tsvyashchenko,\n",
            "S., Maynez, J., Rao, A., Barnes, P., Tay, Y ., Shazeer,\n",
            "N., Prabhakaran, V ., Reif, E., Du, N., Hutchinson, B.,\n",
            "Pope, R., Bradbury, J., Austin, J., Isard, M., Gur-Ari,\n",
            "G., Yin, P., Duke, T., Levskaya, A., Ghemawat, S., Dev,\n",
            "S., Michalewski, H., Garcia, X., Misra, V ., Robinson,\n",
            "K., Fedus, L., Zhou, D., Ippolito, D., Luan, D., Lim,\n",
            "H., Zoph, B., Spiridonov, A., Sepassi, R., Dohan, D.,\n",
            "Agrawal, S., Omernick, M., Dai, A. M., Pillai, T. S., Pel-\n",
            "lat, M., Lewkowycz, A., Moreira, E., Child, R., Polozov,\n",
            "O., Lee, K., Zhou, Z., Wang, X., Saeta, B., Diaz, M.,\n",
            "Firat, O., Catasta, M., Wei, J., Meier-Hellstern, K., Eck,\n",
            "D., Dean, J., Petrov, S., and Fiedel, N. Palm: Scaling lan-\n",
            "guage modeling with pathways. CoRR , abs/2204.02311,\n",
            "2022. doi: 10.48550/arXiv.2204.02311. URL https:\n",
            "//doi.org/10.48550/arXiv.2204.02311 .\n",
            "Chung, H. W., Hou, L., Longpre, S., Zoph, B., Tay, Y .,\n",
            "Fedus, W., Li, E., Wang, X., Dehghani, M., Brahma, S.,\n",
            "Webson, A., Gu, S. S., Dai, Z., Suzgun, M., Chen, X.,\n",
            "Chowdhery, A., Narang, S., Mishra, G., Yu, A., Zhao,\n",
            "V . Y ., Huang, Y ., Dai, A. M., Yu, H., Petrov, S., Chi, E. H.,\n",
            "Dean, J., Devlin, J., Roberts, A., Zhou, D., Le, Q. V .,\n",
            "and Wei, J. Scaling instruction-ﬁnetuned language mod-\n",
            "els.CoRR , abs/2210.11416, 2022. doi: 10.48550/arXiv.2210.11416. URL https://doi.org/10.48550/\n",
            "arXiv.2210.11416 .\n",
            "Cobbe, K., Kosaraju, V ., Bavarian, M., Hilton, J., Nakano,\n",
            "R., Hesse, C., and Schulman, J. Training veriﬁers to solve\n",
            "math word problems. CoRR , abs/2110.14168, 2021. URL\n",
            "https://arxiv.org/abs/2110.14168 .\n",
            "Drozdov, A., Sch ¨arli, N., Aky ¨urek, E., Scales, N., Song,\n",
            "X., Chen, X., Bousquet, O., and Zhou, D. Compo-\n",
            "sitional semantic parsing with large language models.\n",
            "CoRR , abs/2209.15003, 2022. doi: 10.48550/arXiv.\n",
            "2209.15003. URL https://doi.org/10.48550/\n",
            "arXiv.2209.15003 .\n",
            "Fu, Y ., Peng, H., Sabharwal, A., Clark, P., and Khot,\n",
            "T. Complexity-based prompting for multi-step reason-\n",
            "ing. CoRR , abs/2210.00720, 2022. doi: 10.48550/arXiv.\n",
            "2210.00720. URL https://doi.org/10.48550/\n",
            "arXiv.2210.00720 .\n",
            "Gao, L., Dai, Z., Pasupat, P., Chen, A., Chaganty, A. T., Fan,\n",
            "Y ., Zhao, V . Y ., Lao, N., Lee, H., Juan, D.-C., and Guu,\n",
            "K. Rarr: Researching and revising what language models\n",
            "say, using language models, 2022a.\n",
            "Gao, L., Madaan, A., Zhou, S., Alon, U., Liu, P., Yang,\n",
            "Y ., Callan, J., and Neubig, G. PAL: program-aided lan-\n",
            "guage models. CoRR , abs/2211.10435, 2022b. doi: 10.\n",
            "48550/arXiv.2211.10435. URL https://doi.org/\n",
            "10.48550/arXiv.2211.10435 .\n",
            "Holtzman, A., Buys, J., Du, L., Forbes, M., and Choi, Y .\n",
            "The curious case of neural text degeneration. In 8th\n",
            "International Conference on Learning Representations,\n",
            "---------\n",
            "Question: 'Chain-of-Thought'について説明して\n",
            "Helpful Answer:\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
            "\n",
            "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
            "\n",
            "Question: [question here]\n",
            "Helpful Answer: [answer here]\n",
            "Score: [score between 0 and 100]\n",
            "\n",
            "How to determine the score:\n",
            "- Higher is a better answer\n",
            "- Better responds fully to the asked question, with sufficient level of detail\n",
            "- If you do not know the answer based on the context, that should be a score of 0\n",
            "- Don't be overconfident!\n",
            "\n",
            "Example #1\n",
            "\n",
            "Context:\n",
            "---------\n",
            "Apples are red\n",
            "---------\n",
            "Question: what color are apples?\n",
            "Helpful Answer: red\n",
            "Score: 100\n",
            "\n",
            "Example #2\n",
            "\n",
            "Context:\n",
            "---------\n",
            "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
            "---------\n",
            "Question: what type was the car?\n",
            "Helpful Answer: a sports car or an suv\n",
            "Score: 60\n",
            "\n",
            "Example #3\n",
            "\n",
            "Context:\n",
            "---------\n",
            "Pears are either red or orange\n",
            "---------\n",
            "Question: what color are apples?\n",
            "Helpful Answer: This document does not answer the question\n",
            "Score: 0\n",
            "\n",
            "Begin!\n",
            "\n",
            "Context:\n",
            "---------\n",
            "Synthetic Prompting: Generating Chain-of-Thought Demonstrations for Large Language Models\n",
            "Koncel-Kedziorski, R., Roy, S., Amini, A., Kushman,\n",
            "N., and Hajishirzi, H. MAWPS: A math word prob-\n",
            "lem repository. In Knight, K., Nenkova, A., and Ram-\n",
            "bow, O. (eds.), NAACL HLT 2016, The 2016 Confer-\n",
            "ence of the North American Chapter of the Associa-\n",
            "tion for Computational Linguistics: Human Language\n",
            "Technologies, San Diego California, USA, June 12-17,\n",
            "2016 , pp. 1152–1157. The Association for Computational\n",
            "Linguistics, 2016. doi: 10.18653/v1/n16-1136. URL\n",
            "https://doi.org/10.18653/v1/n16-1136 .\n",
            "Li, Y ., Lin, Z., Zhang, S., Fu, Q., Chen, B., Lou, J.-G., and\n",
            "Chen, W. On the advance of making language models bet-\n",
            "ter reasoners. 2022. doi: 10.48550/ARXIV .2206.02336.\n",
            "URL https://arxiv.org/abs/2206.02336 .\n",
            "Liu, A., Swayamdipta, S., Smith, N. A., and Choi, Y .\n",
            "WANLI: worker and AI collaboration for natural language\n",
            "inference dataset creation. CoRR , abs/2201.05955, 2022a.\n",
            "URL https://arxiv.org/abs/2201.05955 .\n",
            "Liu, J., Shen, D., Zhang, Y ., Dolan, B., Carin, L., and\n",
            "Chen, W. What makes good in-context examples for\n",
            "gpt-3? In Agirre, E., Apidianaki, M., and Vulic, I.\n",
            "(eds.), Proceedings of Deep Learning Inside Out: The\n",
            "3rd Workshop on Knowledge Extraction and Integration\n",
            "for Deep Learning Architectures, DeeLIO@ACL 2022,\n",
            "Dublin, Ireland and Online, May 27, 2022 , pp. 100–114.\n",
            "Association for Computational Linguistics, 2022b. doi:\n",
            "10.18653/v1/2022.deelio-1.10. URL https://doi.\n",
            "org/10.18653/v1/2022.deelio-1.10 .\n",
            "Lyu, X., Min, S., Beltagy, I., Zettlemoyer, L., and Hajishirzi,\n",
            "H. Z-ICL: zero-shot in-context learning with pseudo-\n",
            "demonstrations. CoRR , abs/2212.09865, 2022. doi: 10.\n",
            "48550/arXiv.2212.09865. URL https://doi.org/\n",
            "10.48550/arXiv.2212.09865 .\n",
            "Miao, S., Liang, C., and Su, K. A diverse corpus for\n",
            "evaluating and developing english math word problem\n",
            "solvers. In Jurafsky, D., Chai, J., Schluter, N., and\n",
            "Tetreault, J. R. (eds.), Proceedings of the 58th Annual\n",
            "Meeting of the Association for Computational Linguis-\n",
            "tics, ACL 2020, Online, July 5-10, 2020 , pp. 975–984.\n",
            "Association for Computational Linguistics, 2020. doi:\n",
            "10.18653/v1/2020.acl-main.92. URL https://doi.\n",
            "org/10.18653/v1/2020.acl-main.92 .\n",
            "Ouyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright,\n",
            "C. L., Mishkin, P., Zhang, C., Agarwal, S., Slama, K.,\n",
            "Ray, A., Schulman, J., Hilton, J., Kelton, F., Miller,\n",
            "L., Simens, M., Askell, A., Welinder, P., Christiano,\n",
            "P. F., Leike, J., and Lowe, R. Training language\n",
            "models to follow instructions with human feedback.\n",
            "CoRR , abs/2203.02155, 2022. doi: 10.48550/arXiv.\n",
            "2203.02155. URL https://doi.org/10.48550/\n",
            "arXiv.2203.02155 .Patel, A., Bhattamishra, S., and Goyal, N. Are NLP\n",
            "models really able to solve simple math word prob-\n",
            "lems? In Toutanova, K., Rumshisky, A., Zettlemoyer,\n",
            "L., Hakkani-T ¨ur, D., Beltagy, I., Bethard, S., Cotterell,\n",
            "R., Chakraborty, T., and Zhou, Y . (eds.), Proceedings\n",
            "of the 2021 Conference of the North American Chapter\n",
            "of the Association for Computational Linguistics: Hu-\n",
            "man Language Technologies, NAACL-HLT 2021, On-\n",
            "line, June 6-11, 2021 , pp. 2080–2094. Association for\n",
            "Computational Linguistics, 2021. doi: 10.18653/v1/\n",
            "2021.naacl-main.168. URL https://doi.org/10.\n",
            "18653/v1/2021.naacl-main.168 .\n",
            "Pi, X., Liu, Q., Chen, B., Ziyadi, M., Lin, Z., Gao, Y .,\n",
            "Fu, Q., Lou, J., and Chen, W. Reasoning like program\n",
            "executors. CoRR , abs/2201.11473, 2022. URL https:\n",
            "//arxiv.org/abs/2201.11473 .\n",
            "Press, O., Zhang, M., Min, S., Schmidt, L., Smith, N. A.,\n",
            "and Lewis, M. Measuring and narrowing the composi-\n",
            "tionality gap in language models. CoRR , abs/2210.03350,\n",
            "2022. doi: 10.48550/arXiv.2210.03350. URL https:\n",
            "//doi.org/10.48550/arXiv.2210.03350 .\n",
            "Reimers, N. and Gurevych, I. Sentence-BERT: Sentence\n",
            "embeddings using Siamese BERT-networks. In Pro-\n",
            "ceedings of the 2019 Conference on Empirical Meth-\n",
            "ods in Natural Language Processing and the 9th In-\n",
            "ternational Joint Conference on Natural Language Pro-\n",
            "---------\n",
            "Question: 'Chain-of-Thought'について説明して\n",
            "Helpful Answer:\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
            "\n",
            "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
            "\n",
            "Question: [question here]\n",
            "Helpful Answer: [answer here]\n",
            "Score: [score between 0 and 100]\n",
            "\n",
            "How to determine the score:\n",
            "- Higher is a better answer\n",
            "- Better responds fully to the asked question, with sufficient level of detail\n",
            "- If you do not know the answer based on the context, that should be a score of 0\n",
            "- Don't be overconfident!\n",
            "\n",
            "Example #1\n",
            "\n",
            "Context:\n",
            "---------\n",
            "Apples are red\n",
            "---------\n",
            "Question: what color are apples?\n",
            "Helpful Answer: red\n",
            "Score: 100\n",
            "\n",
            "Example #2\n",
            "\n",
            "Context:\n",
            "---------\n",
            "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
            "---------\n",
            "Question: what type was the car?\n",
            "Helpful Answer: a sports car or an suv\n",
            "Score: 60\n",
            "\n",
            "Example #3\n",
            "\n",
            "Context:\n",
            "---------\n",
            "Pears are either red or orange\n",
            "---------\n",
            "Question: what color are apples?\n",
            "Helpful Answer: This document does not answer the question\n",
            "Score: 0\n",
            "\n",
            "Begin!\n",
            "\n",
            "Context:\n",
            "---------\n",
            "Synthetic Prompting: Generating Chain-of-Thought Demonstrations for Large\n",
            "Language Models\n",
            "Zhihong Shao1 2Yeyun Gong3Yelong Shen4Minlie Huang1Nan Duan3Weizhu Chen4\n",
            "Abstract\n",
            "Large language models can perform various rea-\n",
            "soning tasks by using chain-of-thought prompting,\n",
            "which guides them to ﬁnd answers through step-\n",
            "by-step demonstrations. However, the quality of\n",
            "the prompts depends on the demonstrations given\n",
            "to the models, and creating many of them by hand\n",
            "is costly. We introduce S YNTHETIC PROMPTING ,\n",
            "a method that leverages a few handcrafted exam-\n",
            "ples to prompt the model to generate more exam-\n",
            "ples by itself, and selects effective demonstrations\n",
            "to elicit better reasoning. Our method alternates\n",
            "between a backward and forward process to gen-\n",
            "erate new examples. The backward process gen-\n",
            "erates a question that match a sampled reasoning\n",
            "chain, so that the question is solvable and clear.\n",
            "The forward process produces a more detailed\n",
            "reasoning chain for the question, improving the\n",
            "quality of the example. We evaluate our method\n",
            "on numerical, symbolic, and algorithmic reason-\n",
            "ing tasks, and show that it outperforms existing\n",
            "prompting techniques.\n",
            "1. Introduction\n",
            "Few-shot demonstrations, i.e., examples of inputs and out-\n",
            "puts for a task, can enable Large Language Models (LLMs)\n",
            "to perform various tasks without ﬁne-tuning (Brown et al.,\n",
            "2020; Chung et al., 2022). LLMs can further improve their\n",
            "performance by using chain-of-thought prompting, which\n",
            "provides intermediate reasoning steps for the task (Wei et al.,\n",
            "2022b; Kojima et al., 2022). However, the LLMs’ few-shot\n",
            "performance depends heavily on the quality of the demon-\n",
            "strations, especially for reasoning tasks that need complex\n",
            "and diverse reasoning patterns. Manually creating a large\n",
            "and diverse set of examples for demonstration selection is\n",
            "costly and tedious, while relying on a limited set of demon-\n",
            "strations may hamper the LLMs’ generalization and adapta-\n",
            "1Tsinghua University2This work was done during an internship\n",
            "in MSRA3Microsoft Research Asia4Microsoft. Correspondence\n",
            "to: Minlie Huang <aihuang@tsinghua.edu.cn >.tion to different test inputs.\n",
            "In this paper, we propose a novel method, S YNTHETIC\n",
            "PROMPTING , that leverages the LLMs’ own knowledge and\n",
            "generative power to augment a limited set of demonstra-\n",
            "tions with self-synthesized examples, and then uses the aug-\n",
            "mented set to elicit better reasoning in the LLMs. Specif-\n",
            "ically, given a few seed examples, each consisting of a\n",
            "question and a chain of reasoning steps, we prompt an\n",
            "LLM to generate more examples by alternating between\n",
            "two processes: (1) the backward process, where the LLM\n",
            "synthesizes a question based on a self-generated reasoning\n",
            "chain, which ensures that the question is answerable and\n",
            "well-deﬁned; and (2) the forward process, where the LLM\n",
            "produces a reasoning chain for the synthesized question,\n",
            "which reﬁnes the reasoning chain to be more precise and\n",
            "consistent with the question. We repeat this process until\n",
            "we obtain enough synthetic examples. To select the most\n",
            "effective demonstrations from the augmented set, we pro-\n",
            "pose a new selection scheme based on in-cluster complexity,\n",
            "which aims to maximize the diversity and informativeness\n",
            "of the demonstrations by clustering them and choosing the\n",
            "most complex one (the one with the longest reasoning chain)\n",
            "from each cluster. Finally, we prompt the LLM with the\n",
            "selected demonstrations to generate a reasoning chain for a\n",
            "test question and then use it to obtain the answer.\n",
            "We evaluate our method on various reasoning tasks, in-\n",
            "cluding numerical reasoning, algorithmic reasoning, and\n",
            "symbolic reasoning. Following previous few-shot settings\n",
            "(Wang et al., 2022b; Suzgun et al., 2022), we demonstrate\n",
            "that our method can signiﬁcantly improve the LLMs’ per-\n",
            "formance, achieving up to 15.6% absolute gains over the\n",
            "state-of-the-art methods.\n",
            "Our main contributions are:\n",
            "•We introduce S YNTHETIC PROMPTING , a novel\n",
            "method that augments a limited set of demonstrations\n",
            "---------\n",
            "Question: 'Chain-of-Thought'について説明して\n",
            "Helpful Answer:\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
            "\n",
            "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
            "\n",
            "Question: [question here]\n",
            "Helpful Answer: [answer here]\n",
            "Score: [score between 0 and 100]\n",
            "\n",
            "How to determine the score:\n",
            "- Higher is a better answer\n",
            "- Better responds fully to the asked question, with sufficient level of detail\n",
            "- If you do not know the answer based on the context, that should be a score of 0\n",
            "- Don't be overconfident!\n",
            "\n",
            "Example #1\n",
            "\n",
            "Context:\n",
            "---------\n",
            "Apples are red\n",
            "---------\n",
            "Question: what color are apples?\n",
            "Helpful Answer: red\n",
            "Score: 100\n",
            "\n",
            "Example #2\n",
            "\n",
            "Context:\n",
            "---------\n",
            "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
            "---------\n",
            "Question: what type was the car?\n",
            "Helpful Answer: a sports car or an suv\n",
            "Score: 60\n",
            "\n",
            "Example #3\n",
            "\n",
            "Context:\n",
            "---------\n",
            "Pears are either red or orange\n",
            "---------\n",
            "Question: what color are apples?\n",
            "Helpful Answer: This document does not answer the question\n",
            "Score: 0\n",
            "\n",
            "Begin!\n",
            "\n",
            "Context:\n",
            "---------\n",
            "Synthetic Prompting: Generating Chain-of-Thought Demonstrations for Large Language Models\n",
            "augmented set for inference.\n",
            "•We demonstrate the effectiveness of our method on\n",
            "three reasoning tasks, achieving signiﬁcant improve-\n",
            "ments over previous methods.\n",
            "2. Related Work\n",
            "In-context few-shot learning With large-scale unsuper-\n",
            "vised pre-training, LLMs (Brown et al., 2020; Chowdh-\n",
            "ery et al., 2022; Zhang et al., 2022a) can learn to perform\n",
            "tasks by mimicking in-context demonstrations (Shin et al.,\n",
            "2022). To improve robustness to prompts, instruction tuning\n",
            "(Ouyang et al., 2022; Wei et al., 2022a; Sanh et al., 2022;\n",
            "Chung et al., 2022) has been proposed, which trains a lan-\n",
            "guage model on diverse tasks to generate desirable outputs\n",
            "that follow given instructions. With improved controllability,\n",
            "in-context learning-based applications ﬂourish, including\n",
            "text generation (Yang et al., 2022; Gao et al., 2022a), di-\n",
            "alogue generation (Thoppilan et al., 2022), and resource\n",
            "construction (West et al., 2022).\n",
            "Prompting techniques for reasoning Instead of directly\n",
            "generating an answer, chain-of-thought prompting (Wei\n",
            "et al., 2022b) prompts LLMs to arrive at an answer after\n",
            "a step-by-step reasoning process, which largely improves\n",
            "performance on numerous reasoning tasks. Following work\n",
            "like least-to-most prompting (Zhou et al., 2022), self-ask\n",
            "(Press et al., 2022), and decomposed prompting (Khot et al.,\n",
            "2022) also shares the spirit of question decomposition, i.e.,\n",
            "decomposing a complex question into a series of tractable\n",
            "sub-questions. All these methods produce natural language\n",
            "reasoning steps, which struggle with calculations and sym-\n",
            "bolic manipulations. Techniques like P AL prompting (Gao\n",
            "et al., 2022b) and program-of-thought prompting (Chen\n",
            "et al., 2022) propose to improve natural language reasoning\n",
            "with structured code, showing signiﬁcant improvements on\n",
            "arithmetic, symbolic and algorithmic tasks.\n",
            "Orthogonal to prompting workﬂows, there is also work that\n",
            "explores what make an effective demonstration. Metrics\n",
            "include (1) diversity, which selects complementary demon-\n",
            "strations so that models can fuse different reasoning (Li\n",
            "et al., 2022; Ye et al., 2022b) or be less biased by one type\n",
            "of reasoning (Zhang et al., 2022b); (2) reasoning complex-\n",
            "ity, which selects demonstrations with the highest reasoning\n",
            "complexity, and has been found to work well on numerical\n",
            "reasoning empirically (Fu et al., 2022); (3) similarity with a\n",
            "test input, which retrieves structurally (Drozdov et al., 2022)\n",
            "or semantically (Liu et al., 2022b) similar demonstrations.\n",
            "To ensure both diversity and informativeness of demonstra-\n",
            "tions, we propose a selection scheme based on in-cluster\n",
            "complexity to choose the most complex examples from ex-\n",
            "ample clusters. All these selection schemes assume access\n",
            "to a set of examples (whether annotated or not).Knowledge distillation from LLMs Some researches dis-\n",
            "tilled knowledge from LLMs into symbolic knowledge, e.g.,\n",
            "structured commonsense knowledge (West et al., 2022) or\n",
            "task-speciﬁc examples (Liu et al., 2022a; Ye et al., 2022a;\n",
            "Huang et al., 2022). These researches have at least one of\n",
            "the following characteristics: (1) assuming access to gold\n",
            "inputs from training sets without needing to generate them;\n",
            "(2) distilling knowledge based on collaboration between\n",
            "workers and AI; (3) using distilled knowledge for training.\n",
            "By contrast, we assume access to only a few gold examples,\n",
            "automatically synthesize more examples by prompting an\n",
            "LLM, and study whether synthesized examples can be lever-\n",
            "aged to better elicit reasoning in the model itself, without\n",
            "further training.\n",
            "3. Synthetic Prompting\n",
            "3.1. Overview\n",
            "To perform reasoning tasks with LLMs, given a few exam-\n",
            "ples each consisting of a question and a reasoning chain,\n",
            "it is common to directly concatenate them into a prompt\n",
            "for inference. In this paper, we instead treat them as seed\n",
            "examples, and prompt an LLM to automatically synthesize\n",
            "more by repeating a backward-forward procedure; the back-\n",
            "---------\n",
            "Question: 'Chain-of-Thought'について説明して\n",
            "Helpful Answer:\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
            "\n",
            "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
            "\n",
            "Question: [question here]\n",
            "Helpful Answer: [answer here]\n",
            "Score: [score between 0 and 100]\n",
            "\n",
            "How to determine the score:\n",
            "- Higher is a better answer\n",
            "- Better responds fully to the asked question, with sufficient level of detail\n",
            "- If you do not know the answer based on the context, that should be a score of 0\n",
            "- Don't be overconfident!\n",
            "\n",
            "Example #1\n",
            "\n",
            "Context:\n",
            "---------\n",
            "Apples are red\n",
            "---------\n",
            "Question: what color are apples?\n",
            "Helpful Answer: red\n",
            "Score: 100\n",
            "\n",
            "Example #2\n",
            "\n",
            "Context:\n",
            "---------\n",
            "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
            "---------\n",
            "Question: what type was the car?\n",
            "Helpful Answer: a sports car or an suv\n",
            "Score: 60\n",
            "\n",
            "Example #3\n",
            "\n",
            "Context:\n",
            "---------\n",
            "Pears are either red or orange\n",
            "---------\n",
            "Question: what color are apples?\n",
            "Helpful Answer: This document does not answer the question\n",
            "Score: 0\n",
            "\n",
            "Begin!\n",
            "\n",
            "Context:\n",
            "---------\n",
            "Synthetic Prompting: Generating Chain-of-Thought Demonstrations for Large Language Models\n",
            "conditioned on reasoning chains affects correctness nega-\n",
            "tively; 62.5% are ﬂawed, 80% of which are unanswerable,\n",
            "e.g.,\n",
            "An image is represented by a 4x4 matrix of integers. Each\n",
            "cell of the matrix contains a single integer between 0 and\n",
            "255. What is the average value of all the integers in the\n",
            "matrix? .\n",
            "Notably, though we also include target complexities into the\n",
            "prompts when synthesizing questions without conditioned\n",
            "on reasoning chains, the resulting questions tend to require\n",
            "less reasoning steps than S YNTHETIC PROMPTING , indi-\n",
            "cating that conditioning on numbered reasoning steps can\n",
            "control reasoning complexities better.\n",
            "4.6.2. S CHEMES OF DEMONSTRATION SELECTION\n",
            "Datasets GSM8K Colored Objects\n",
            "# Seed Examples 2 4 2 4\n",
            "Random 73.4 73.1 83.0 90.0\n",
            "Cluster Centroid 73.1 73.0 91.2 93.6\n",
            "Similarity 72.9 74.0 87.0 94.2\n",
            "In-Cluster Similarity 72.9 73.2 89.3 95.4\n",
            "Complexity 74.1 74.3 92.7 97.5\n",
            "In-Cluster Complexity 74.7 75.3 93.8 97.3\n",
            "Table 5: Accuracies with different schemes of demonstra-\n",
            "tion selection.\n",
            "To make good use of synthesized examples, having an ef-\n",
            "fecitve selection scheme matters. We evaluated the follow-\n",
            "ing 6 selection schemes. (1) Random : randomly selects\n",
            "demonstrations; (2) Cluster Centroid : selects the example\n",
            "closest to each cluster centroid; (3) Similarity : retrieves\n",
            "the most similar examples according to cosine similarity;\n",
            "(4)In-Cluster Similarity : select the most similar example\n",
            "from each cluster; (5) Complexity : selects the examples\n",
            "with the most reasoning steps; (6) In-Cluster Complexity :\n",
            "selects the most complex example from each cluster.\n",
            "Table 5 presents the comparisons. Though most selection\n",
            "schemes achieve better performance than P AL prompting,\n",
            "complexity-based selection schemes are the most effective\n",
            "on the two reasoning tasks, with some other schemes like\n",
            "Random lagging far behind. Our proposed In-Cluster Com-\n",
            "plexity outperforms Complexity, showing the beneﬁts of\n",
            "using diverse and complex demonstrations.\n",
            "4.6.3. S ENSITIVITY TO SEED EXAMPLES\n",
            "To investigate how sensitive S YNTHETIC PROMPTING is\n",
            "to seed examples, we repeated experiments on another two\n",
            "random sets of seed examples. Figure 2 demonstrates our\n",
            "sensitivity analysis. S YNTHETIC PROMPTING consistently\n",
            "outperforms P AL prompting on different runs. However,\n",
            "72.97374.373.572.472.774.172.47475.174.874.8\n",
            "71.572.573.574.575.5\n",
            "2 Seed Examples2 Seed Examples4 Seed Examples4 Seed ExamplesGSM8KPAL PromptingVanilla Synthetic PromptingSynthetic Prompting\n",
            "88.685.995.393.294.791.787.491.894.194.495.997.7\n",
            "8588919497100\n",
            "2 Seed Examples2 Seed Examples4 Seed Examples4 Seed ExamplesColored ObjectsFigure 2: Sensitivity analysis on GSM8K and Colored Ob-\n",
            "jects. We experimented with another two random sets of\n",
            "seed examples of size 2 and 4 for each dataset.\n",
            "we observed that seed examples with better P AL prompting\n",
            "performance does not necessarily lead to better S YNTHETIC\n",
            "PROMPTING performance.\n",
            "4.7. Comparison with Selecting from Training\n",
            "Examples\n",
            "To measure the performance gap between using synthetic\n",
            "demonstrations and using gold demonstrations from a large\n",
            "set of carefully-curated examples, we selected 8 demon-\n",
            "strations from the training set of GSM8K with the two\n",
            "complexity-based selection schemes (i.e., Complexity and\n",
            "In-Cluster Complexity in Section 4.6.2), respectively. As\n",
            "the training examples were annotated with natural language\n",
            "reasoning chains (CoT-style reasoning), we measured the\n",
            "numbers of natural language reasoning steps as reasoning\n",
            "complexities for complexity-based selection, and manu-\n",
            "ally annotated selected examples with P AL-style reasoning\n",
            "chains for P AL prompting. As the training examples of\n",
            "GSM8K are diverse, both Complexity and In-Cluster Com-\n",
            "plexity select diverse and informative demonstrations, and\n",
            "yield an accuracy of 77.0% on the test set of GSM8K, sur-\n",
            "passing our accuracy of 75.3% by absolute 1.7%. As shown\n",
            "---------\n",
            "Question: 'Chain-of-Thought'について説明して\n",
            "Helpful Answer:\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
            "\n",
            "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
            "\n",
            "Question: [question here]\n",
            "Helpful Answer: [answer here]\n",
            "Score: [score between 0 and 100]\n",
            "\n",
            "How to determine the score:\n",
            "- Higher is a better answer\n",
            "- Better responds fully to the asked question, with sufficient level of detail\n",
            "- If you do not know the answer based on the context, that should be a score of 0\n",
            "- Don't be overconfident!\n",
            "\n",
            "Example #1\n",
            "\n",
            "Context:\n",
            "---------\n",
            "Apples are red\n",
            "---------\n",
            "Question: what color are apples?\n",
            "Helpful Answer: red\n",
            "Score: 100\n",
            "\n",
            "Example #2\n",
            "\n",
            "Context:\n",
            "---------\n",
            "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
            "---------\n",
            "Question: what type was the car?\n",
            "Helpful Answer: a sports car or an suv\n",
            "Score: 60\n",
            "\n",
            "Example #3\n",
            "\n",
            "Context:\n",
            "---------\n",
            "Pears are either red or orange\n",
            "---------\n",
            "Question: what color are apples?\n",
            "Helpful Answer: This document does not answer the question\n",
            "Score: 0\n",
            "\n",
            "Begin!\n",
            "\n",
            "Context:\n",
            "---------\n",
            "Synthetic Prompting: Generating Chain-of-Thought Demonstrations for Large Language Models\n",
            "Target ComplexityTopic wordDemonstration\n",
            "Synthesized QuestionSelf-Generated Reasoning ChainExample 1Question: Cynthia eats one serving of ice cream every night. She buys cartons of ice cream with 15 servings of ice cream per carton at a cost of $4.00 per carton. After 60 days, how much will she spend on ice cream?def solution():servings_per_night= 1servings_per_carton= 15cost_per_carton= 4.00num_days= 60num_servings= num_days* servings_per_nightnum_cartons= num_servings/ servings_per_cartonmoney_spent= cost_per_carton* num_cartonsresult = money_spentreturn resultExample 2Question: A chef bought 4 bags of onions. Each bag weighs 50 pounds. A pound of onions cost $1.50. How much did the chef spend?def solution():num_bags_bought= 4weight_per_bag= 50cost_per_pound= 1.50cost_per_bag= weight_per_bag* cost_per_poundmoney_spent= num_bags_bought* cost_per_bagresult = money_spentreturn money_spent\n",
            "Forward ProcessDemonstration\n",
            "SynthesizedReasoning ChainExample 1# I implement a Python functioncalled solution()to solve the following question correctly.# The question is about work.def solution():””” 5-linefunction ”””# 1num_roses= 4# 2num_dahlias= num_roses+ 7# 3num_flowers= num_roses+ num_dahlias# 4result = num_flowers# 5return resultQuestion: There are 4 roses in the vase. There are 7 more dahlias than roses in the vase. How many flowers are there in the vase in total?Example 2# I implement a Python function called solution() to solve the following question correctly.# The question is about chef.def solution():””” 6-linefunction ”””# 1bags_of_onions= 4# 2weight_per_bag= 50# 3cost_per_bag= weight_per_bag* 1.50# 4money_spent= num_bags_bought* cost_per_bag# 5result = money_spent# 6return money_spentQuestion: A chef bought 4 bags of onions. Each bag weighs 50 pounds. A pound of onions cost $1.50. How much did the chef spend?Backward Process\n",
            "Figure 1: Example prompts and model completions in the backward process (left) and the forward process (right) of example\n",
            "synthesis. We show only one demonstration in each prompt for brevity. Self-Generated Reasoning Chain\n",
            "(in blue), Synthesized Question (in green), and Synthesized Reasoning Chain (in purple) are example\n",
            "completions. In the backward process, an LLM synthesizes a question conditioned on a topic word, a target reasoning\n",
            "complexity, and a generated reasoning chain. To better control the reasoning complexity, we number the reasoning steps,\n",
            "e.g.,# 1 and# 2 on the left. In the forward process, the LLM synthesizes a more precise reasoning chain for the question\n",
            "produced in the backward process. The question produced in the backward process and the corresponding reasoning chain\n",
            "produced in the forward process constitute a synthetic example.\n",
            "may require different types of reasoning. For example,\n",
            "questions about taxmay involve arithmetic operations,\n",
            "while questions about speed may involve unit conversions.\n",
            "To ensure diversity of the synthesized questions, we prompt\n",
            "the model to generate a question for a given topic word,\n",
            "which is randomly sampled from a set of words. The word\n",
            "set is created by prompting the model to list single-token\n",
            "noun words, following some random noun words from the\n",
            "seed examples. The instruction for generating the word set\n",
            "isList 50 noun words. Each word shouldcontain one token only. Do not repeat\n",
            "words already listed. , followed by no more than\n",
            "10 words from the seed examples. We repeat this process\n",
            "until we have 1,000 different words, or reach 100 repetitions\n",
            "of prompting.\n",
            "Target complexity We also want to control the complexity\n",
            "of the synthesized questions, as more complex examples\n",
            "may help the model learn better reasoning skills (Fu et al.,\n",
            "2022). We deﬁne the complexity of a question as the number\n",
            "---------\n",
            "Question: 'Chain-of-Thought'について説明して\n",
            "Helpful Answer:\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
            "\n",
            "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
            "\n",
            "Question: [question here]\n",
            "Helpful Answer: [answer here]\n",
            "Score: [score between 0 and 100]\n",
            "\n",
            "How to determine the score:\n",
            "- Higher is a better answer\n",
            "- Better responds fully to the asked question, with sufficient level of detail\n",
            "- If you do not know the answer based on the context, that should be a score of 0\n",
            "- Don't be overconfident!\n",
            "\n",
            "Example #1\n",
            "\n",
            "Context:\n",
            "---------\n",
            "Apples are red\n",
            "---------\n",
            "Question: what color are apples?\n",
            "Helpful Answer: red\n",
            "Score: 100\n",
            "\n",
            "Example #2\n",
            "\n",
            "Context:\n",
            "---------\n",
            "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
            "---------\n",
            "Question: what type was the car?\n",
            "Helpful Answer: a sports car or an suv\n",
            "Score: 60\n",
            "\n",
            "Example #3\n",
            "\n",
            "Context:\n",
            "---------\n",
            "Pears are either red or orange\n",
            "---------\n",
            "Question: what color are apples?\n",
            "Helpful Answer: This document does not answer the question\n",
            "Score: 0\n",
            "\n",
            "Begin!\n",
            "\n",
            "Context:\n",
            "---------\n",
            "of in-context demonstrations. We show that by prompting\n",
            "a large language model to synthesize more examples, we\n",
            "can improve its reasoning performance on numerical, sym-\n",
            "bolic, and algorithmic tasks, compared to existing prompt-\n",
            "ing methods such as chain-of-thought prompting and P AL\n",
            "---------\n",
            "Question: 'Chain-of-Thought'について説明して\n",
            "Helpful Answer:\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:349: UserWarning: The apply_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qN2RLzPn-Wve"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}