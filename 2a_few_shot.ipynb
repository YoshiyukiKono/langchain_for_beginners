{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNLo9BSQ/gt51BDhwWjUHx5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YoshiyukiKono/langchain_for_beginners/blob/main/2a_few_shot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LangChain Chat History Memory with Astra DB\n",
        "\n",
        "## Package Install"
      ],
      "metadata": {
        "id": "5GmUfFL0YCtB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai==1.3.5 tiktoken==0.5.1 cohere==4.36\n",
        "!pip install langchain==0.0.340"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMMMfJaKo4Ww",
        "outputId": "38596020-3d02-40f7-b07a-2a112f4410d8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==1.3.5\n",
            "  Downloading openai-1.3.5-py3-none-any.whl (220 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.8/220.8 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tiktoken==0.5.1\n",
            "  Downloading tiktoken-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cohere==4.36\n",
            "  Downloading cohere-4.36-py3-none-any.whl (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<4,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.3.5) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai==1.3.5) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai==1.3.5)\n",
            "  Downloading httpx-0.25.2-py3-none-any.whl (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.3.5) (1.10.13)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai==1.3.5) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.10/dist-packages (from openai==1.3.5) (4.5.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.5.1) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.5.1) (2.31.0)\n",
            "Requirement already satisfied: aiohttp<4.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from cohere==4.36) (3.8.6)\n",
            "Collecting backoff<3.0,>=2.0 (from cohere==4.36)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Collecting fastavro==1.8.2 (from cohere==4.36)\n",
            "  Downloading fastavro-1.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib_metadata<7.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from cohere==4.36) (6.8.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from cohere==4.36) (2.0.7)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere==4.36) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere==4.36) (3.3.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere==4.36) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere==4.36) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere==4.36) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere==4.36) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere==4.36) (1.3.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai==1.3.5) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai==1.3.5) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai==1.3.5) (1.1.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai==1.3.5) (2023.7.22)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai==1.3.5)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.3.5)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib_metadata<7.0,>=6.0->cohere==4.36) (3.17.0)\n",
            "Installing collected packages: h11, fastavro, backoff, tiktoken, httpcore, httpx, cohere, openai\n",
            "Successfully installed backoff-2.2.1 cohere-4.36 fastavro-1.8.2 h11-0.14.0 httpcore-1.0.2 httpx-0.25.2 openai-1.3.5 tiktoken-0.5.1\n",
            "Collecting langchain==0.0.340\n",
            "  Downloading langchain-0.0.340-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.340) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.340) (2.0.23)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.340) (3.8.6)\n",
            "Requirement already satisfied: anyio<4.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.340) (3.7.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.340) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain==0.0.340)\n",
            "  Downloading dataclasses_json-0.6.3-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain==0.0.340)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langsmith<0.1.0,>=0.0.63 (from langchain==0.0.340)\n",
            "  Downloading langsmith-0.0.67-py3-none-any.whl (47 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.0/47.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.340) (1.23.5)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.340) (1.10.13)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.340) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.340) (8.2.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.340) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.340) (3.3.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.340) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.340) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.340) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.340) (1.3.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain==0.0.340) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain==0.0.340) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain==0.0.340) (1.1.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.340)\n",
            "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.340)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain==0.0.340)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.0.340) (4.5.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.340) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.340) (2023.7.22)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.0.340) (3.0.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain==0.0.340) (23.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.0.340)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, jsonpointer, typing-inspect, langsmith, jsonpatch, dataclasses-json, langchain\n",
            "Successfully installed dataclasses-json-0.6.3 jsonpatch-1.33 jsonpointer-2.4 langchain-0.0.340 langsmith-0.0.67 marshmallow-3.20.1 mypy-extensions-1.0.0 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cassandra-driver==3.28.0 cassio==0.1.3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9k10ziT0zRYw",
        "outputId": "1591f2c9-4c4a-4231-8a4d-f4ab210aa1e4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting cassandra-driver==3.28.0\n",
            "  Downloading cassandra_driver-3.28.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.1/19.1 MB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cassio==0.1.3\n",
            "  Downloading cassio-0.1.3-py3-none-any.whl (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/40.1 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.9 in /usr/local/lib/python3.10/dist-packages (from cassandra-driver==3.28.0) (1.16.0)\n",
            "Collecting geomet<0.3,>=0.1 (from cassandra-driver==3.28.0)\n",
            "  Downloading geomet-0.2.1.post1-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: numpy>=1.0 in /usr/local/lib/python3.10/dist-packages (from cassio==0.1.3) (1.23.5)\n",
            "Requirement already satisfied: requests>=2 in /usr/local/lib/python3.10/dist-packages (from cassio==0.1.3) (2.31.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from geomet<0.3,>=0.1->cassandra-driver==3.28.0) (8.1.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2->cassio==0.1.3) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2->cassio==0.1.3) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2->cassio==0.1.3) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2->cassio==0.1.3) (2023.7.22)\n",
            "Installing collected packages: geomet, cassandra-driver, cassio\n",
            "Successfully installed cassandra-driver-3.28.0 cassio-0.1.3 geomet-0.2.1.post1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Astra"
      ],
      "metadata": {
        "id": "gbIfQ5l_HaJV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O secure-connect-demo.zip \"https://...\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ig3ElhqbHd3G",
        "outputId": "cf33f74f-8741-4b43-e928-e0d581c64c4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-09-01 05:03:54--  https://datastax-cluster-config-prod.s3.us-east-2.amazonaws.com/d5556151-ea9a-4309-8be3-b8ea2b1cd03d-1/secure-connect-demo.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIA2AIQRQ76S2JCB77W%2F20230901%2Fus-east-2%2Fs3%2Faws4_request&X-Amz-Date=20230901T050340Z&X-Amz-Expires=300&X-Amz-SignedHeaders=host&X-Amz-Signature=7db1257a20828e206535d85e46ffdfe26c4fe1166781a157033bbaac549b23c3\n",
            "Resolving datastax-cluster-config-prod.s3.us-east-2.amazonaws.com (datastax-cluster-config-prod.s3.us-east-2.amazonaws.com)... 3.5.131.128, 52.219.95.34, 52.219.179.34, ...\n",
            "Connecting to datastax-cluster-config-prod.s3.us-east-2.amazonaws.com (datastax-cluster-config-prod.s3.us-east-2.amazonaws.com)|3.5.131.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 12247 (12K) [application/zip]\n",
            "Saving to: ‘secure-connect-demo.zip’\n",
            "\n",
            "secure-connect-demo 100%[===================>]  11.96K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-09-01 05:03:54 (119 MB/s) - ‘secure-connect-demo.zip’ saved [12247/12247]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SECURE_CONNECT_BUNDLE_PATH = 'secure-connect-demo.zip'"
      ],
      "metadata": {
        "id": "qGzwcnhfIROt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "\n",
        "ASTRA_CLIENT_ID = getpass.getpass()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVlMnfyJJVUb",
        "outputId": "f83cea73-a918-4262-b791-a597f474e282"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "ASTRA_CLIENT_SECRET = getpass.getpass()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvKJFm2vJgoU",
        "outputId": "7dcf6fd4-b9be-40ea-d45d-0d92c0565a32"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from cassandra.cluster import Cluster\n",
        "from cassandra.auth import PlainTextAuthProvider\n",
        "\n",
        "cloud_config= {\n",
        "  'secure_connect_bundle': SECURE_CONNECT_BUNDLE_PATH\n",
        "}\n",
        "auth_provider = PlainTextAuthProvider(ASTRA_CLIENT_ID, ASTRA_CLIENT_SECRET)\n",
        "cluster = Cluster(cloud=cloud_config, auth_provider=auth_provider)\n",
        "session = cluster.connect()\n",
        "\n",
        "row = session.execute(\"select release_version from system.local\").one()\n",
        "if row:\n",
        "  print(row[0])\n",
        "else:\n",
        "  print(\"An error occurred.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qrGG5yAEJpnJ",
        "outputId": "8429f947-48b4-4e8f-f11d-d0f7276c35f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:cassandra.cluster:Downgrading core protocol version from 66 to 65 for 216b7807-e6c4-471d-bb29-342090dcbade-us-east1.db.astra.datastax.com:29042:d0857863-2427-498c-a762-8483a4c1edb8. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n",
            "WARNING:cassandra.cluster:Downgrading core protocol version from 65 to 5 for 216b7807-e6c4-471d-bb29-342090dcbade-us-east1.db.astra.datastax.com:29042:d0857863-2427-498c-a762-8483a4c1edb8. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n",
            "ERROR:cassandra.connection:Closing connection <AsyncoreConnection(137969104745088) 216b7807-e6c4-471d-bb29-342090dcbade-us-east1.db.astra.datastax.com:29042:d0857863-2427-498c-a762-8483a4c1edb8> due to protocol error: Error from server: code=000a [Protocol error] message=\"Beta version of the protocol used (5/v5-beta), but USE_BETA flag is unset\"\n",
            "WARNING:cassandra.cluster:Downgrading core protocol version from 5 to 4 for 216b7807-e6c4-471d-bb29-342090dcbade-us-east1.db.astra.datastax.com:29042:d0857863-2427-498c-a762-8483a4c1edb8. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.0.11-13697dcfc157\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "YOUR_KEYSPACE = 'langchain'"
      ],
      "metadata": {
        "id": "7TxJnUlFJ4qo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "session.set_keyspace(YOUR_KEYSPACE)\n",
        "session"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Im1ixFaIJ9Mw",
        "outputId": "e576b477-78c8-46af-cb4d-218709c4d7f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<cassandra.cluster.Session at 0x7d7b6f7a7370>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Open AI\n",
        "\n",
        "### 動作確認"
      ],
      "metadata": {
        "id": "44jAlG1gYXMC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxpCJvN4xACO",
        "outputId": "e5a5db73-de41-4b75-a081-ffcda45dc9bd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI()\n",
        "client.models.list()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48L2DDIrsoQV",
        "outputId": "38875dd4-66d3-437c-dfa8-64efd2290785"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SyncPage[Model](data=[Model(id='text-search-babbage-doc-001', created=1651172509, object='model', owned_by='openai-dev'), Model(id='gpt-4', created=1687882411, object='model', owned_by='openai'), Model(id='curie-search-query', created=1651172509, object='model', owned_by='openai-dev'), Model(id='text-davinci-003', created=1669599635, object='model', owned_by='openai-internal'), Model(id='text-search-babbage-query-001', created=1651172509, object='model', owned_by='openai-dev'), Model(id='babbage', created=1649358449, object='model', owned_by='openai'), Model(id='babbage-search-query', created=1651172509, object='model', owned_by='openai-dev'), Model(id='text-babbage-001', created=1649364043, object='model', owned_by='openai'), Model(id='text-similarity-davinci-001', created=1651172505, object='model', owned_by='openai-dev'), Model(id='davinci-similarity', created=1651172509, object='model', owned_by='openai-dev'), Model(id='code-davinci-edit-001', created=1649880484, object='model', owned_by='openai'), Model(id='curie-similarity', created=1651172510, object='model', owned_by='openai-dev'), Model(id='babbage-search-document', created=1651172510, object='model', owned_by='openai-dev'), Model(id='curie-instruct-beta', created=1649364042, object='model', owned_by='openai'), Model(id='text-search-ada-doc-001', created=1651172507, object='model', owned_by='openai-dev'), Model(id='davinci-instruct-beta', created=1649364042, object='model', owned_by='openai'), Model(id='text-similarity-babbage-001', created=1651172505, object='model', owned_by='openai-dev'), Model(id='text-search-davinci-doc-001', created=1651172505, object='model', owned_by='openai-dev'), Model(id='gpt-3.5-turbo-0613', created=1686587434, object='model', owned_by='openai'), Model(id='babbage-similarity', created=1651172505, object='model', owned_by='openai-dev'), Model(id='text-embedding-ada-002', created=1671217299, object='model', owned_by='openai-internal'), Model(id='davinci-search-query', created=1651172505, object='model', owned_by='openai-dev'), Model(id='text-similarity-curie-001', created=1651172507, object='model', owned_by='openai-dev'), Model(id='text-davinci-001', created=1649364042, object='model', owned_by='openai'), Model(id='text-search-davinci-query-001', created=1651172505, object='model', owned_by='openai-dev'), Model(id='gpt-3.5-turbo-16k-0613', created=1685474247, object='model', owned_by='openai'), Model(id='ada-search-document', created=1651172507, object='model', owned_by='openai-dev'), Model(id='ada-code-search-code', created=1651172505, object='model', owned_by='openai-dev'), Model(id='babbage-002', created=1692634615, object='model', owned_by='system'), Model(id='gpt-4-vision-preview', created=1698894917, object='model', owned_by='system'), Model(id='davinci-002', created=1692634301, object='model', owned_by='system'), Model(id='gpt-4-0314', created=1687882410, object='model', owned_by='openai'), Model(id='gpt-3.5-turbo', created=1677610602, object='model', owned_by='openai'), Model(id='davinci-search-document', created=1651172509, object='model', owned_by='openai-dev'), Model(id='curie-search-document', created=1651172508, object='model', owned_by='openai-dev'), Model(id='babbage-code-search-code', created=1651172509, object='model', owned_by='openai-dev'), Model(id='gpt-4-0613', created=1686588896, object='model', owned_by='openai'), Model(id='text-search-ada-query-001', created=1651172505, object='model', owned_by='openai-dev'), Model(id='code-search-ada-text-001', created=1651172507, object='model', owned_by='openai-dev'), Model(id='babbage-code-search-text', created=1651172509, object='model', owned_by='openai-dev'), Model(id='code-search-babbage-code-001', created=1651172507, object='model', owned_by='openai-dev'), Model(id='ada-search-query', created=1651172505, object='model', owned_by='openai-dev'), Model(id='ada-code-search-text', created=1651172510, object='model', owned_by='openai-dev'), Model(id='dall-e-3', created=1698785189, object='model', owned_by='system'), Model(id='tts-1-hd', created=1699046015, object='model', owned_by='system'), Model(id='text-search-curie-query-001', created=1651172509, object='model', owned_by='openai-dev'), Model(id='text-davinci-002', created=1649880484, object='model', owned_by='openai'), Model(id='text-davinci-edit-001', created=1649809179, object='model', owned_by='openai'), Model(id='code-search-babbage-text-001', created=1651172507, object='model', owned_by='openai-dev'), Model(id='gpt-3.5-turbo-1106', created=1698959748, object='model', owned_by='system'), Model(id='ada', created=1649357491, object='model', owned_by='openai'), Model(id='text-ada-001', created=1649364042, object='model', owned_by='openai'), Model(id='ada-similarity', created=1651172507, object='model', owned_by='openai-dev'), Model(id='code-search-ada-code-001', created=1651172507, object='model', owned_by='openai-dev'), Model(id='gpt-3.5-turbo-instruct', created=1692901427, object='model', owned_by='system'), Model(id='text-similarity-ada-001', created=1651172505, object='model', owned_by='openai-dev'), Model(id='gpt-3.5-turbo-instruct-0914', created=1694122472, object='model', owned_by='system'), Model(id='canary-whisper', created=1699656801, object='model', owned_by='system'), Model(id='text-search-curie-doc-001', created=1651172509, object='model', owned_by='openai-dev'), Model(id='gpt-3.5-turbo-16k', created=1683758102, object='model', owned_by='openai-internal'), Model(id='text-curie-001', created=1649364043, object='model', owned_by='openai'), Model(id='curie', created=1649359874, object='model', owned_by='openai'), Model(id='canary-tts', created=1699492935, object='model', owned_by='system'), Model(id='tts-1', created=1681940951, object='model', owned_by='openai-internal'), Model(id='whisper-1', created=1677532384, object='model', owned_by='openai-internal'), Model(id='gpt-4-1106-preview', created=1698957206, object='model', owned_by='system'), Model(id='davinci', created=1649359874, object='model', owned_by='openai'), Model(id='dall-e-2', created=1698798177, object='model', owned_by='system'), Model(id='tts-1-1106', created=1699053241, object='model', owned_by='system'), Model(id='gpt-3.5-turbo-0301', created=1677649963, object='model', owned_by='openai'), Model(id='tts-1-hd-1106', created=1699053533, object='model', owned_by='system')], object='list')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### デバッグ"
      ],
      "metadata": {
        "id": "_r3q523qFiC-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "logging.getLogger('openai').setLevel(logging.DEBUG)"
      ],
      "metadata": {
        "id": "jAX6YYAeFlkR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#LangChain\n",
        "\n",
        "https://python.langchain.com/docs/integrations/vectorstores/cassandra"
      ],
      "metadata": {
        "id": "_okNsBij0Eok"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "\n",
        "completion = openai.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": \"3足す３掛ける３は何ですか？\"}#3足す３に3を掛けるといくつですか？ OR 3足す３掛ける３は何ですか？\n",
        "    ],\n",
        ")\n",
        "print(completion.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sLo5sD0ucno",
        "outputId": "b6beca15-2ea4-43d4-bebe-a90f8876dfce"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': '3足す３掛ける３は何ですか？'}], 'model': 'gpt-3.5-turbo'}}\n",
            "DEBUG:openai._base_client:HTTP Request: POST https://api.openai.com/v1/chat/completions \"200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3足す3は6です。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "\n",
        "completion = openai.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": \"3足す３に3を掛けるといくつですか？\"}#3足す３に3を掛けるといくつですか？ OR 3足す３掛ける３は何ですか？\n",
        "    ],\n",
        ")\n",
        "print(completion.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uT7ClDYmwiER",
        "outputId": "74573cec-1f2e-4156-976c-6c3ffe8561fb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': '3足す３に3を掛けるといくつですか？'}], 'model': 'gpt-3.5-turbo'}}\n",
            "DEBUG:openai._base_client:HTTP Request: POST https://api.openai.com/v1/chat/completions \"200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3足す3は6です。6に3を掛けると、18になります。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import SemanticSimilarityExampleSelector\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts import (\n",
        "    FewShotChatMessagePromptTemplate,\n",
        "    ChatPromptTemplate,\n",
        ")\n",
        "import openai\n",
        "\n",
        "examples = [\n",
        "    {\"input\": \"2+2\", \"output\": \"4\"},\n",
        "    {\"input\": \"2+3\", \"output\": \"5\"},\n",
        "    {\"input\": \"2+4\", \"output\": \"6\"},\n",
        "    {\"input\": \"1足す1に2を掛けるといくつですか？\", \"output\": \"4\"},\n",
        "    {\"input\": \"What did the cow say to the moon?\", \"output\": \"nothing at all\"},\n",
        "    {\"input\": \"Write me a poem about the moon\",\n",
        "     \"output\": \"One for the moon, and one for me, who are we to talk about the moon?\",},\n",
        "]\n",
        "\n",
        "to_vectorize = [\" \".join(example.values()) for example in examples]"
      ],
      "metadata": {
        "id": "Eceo9jwXK2Yx"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "embeddings = OpenAIEmbeddings()"
      ],
      "metadata": {
        "id": "xa6N5XLBbBgy"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import Cassandra"
      ],
      "metadata": {
        "id": "INJBeCy6zp8J"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "table_name = \"my_vector_db_table_for_few_shots_examples\"\n",
        "keyspace_name = YOUR_KEYSPACE\n",
        "vectorstore = Cassandra.from_texts(\n",
        "    to_vectorize,\n",
        "    embeddings,\n",
        "    metadatas=examples,\n",
        "    session=session,\n",
        "    keyspace=keyspace_name,\n",
        "    table_name=table_name,\n",
        ")"
      ],
      "metadata": {
        "id": "71Fey5SA1VnC",
        "outputId": "3d54a7c5-f49c-49dc-a6e3-c761454dae31",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x7d7b5b216830>, 'json_data': {'input': [[2028, 374, 264, 6205, 11914, 13]], 'model': 'text-embedding-ada-002', 'encoding_format': 'base64'}}\n",
            "DEBUG:openai._base_client:HTTP Request: POST https://api.openai.com/v1/embeddings \"200 OK\"\n",
            "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x7d7b5b216b90>, 'json_data': {'input': [[17, 10, 17, 220, 19], [17, 10, 18, 220, 20], [17, 10, 19, 220, 21], [16, 50266, 111, 17663, 16, 20230, 17, 30512, 19012, 249, 76622, 30369, 19732, 16995, 47884, 59739, 38641, 32149, 11571, 220, 19], [3923, 1550, 279, 19923, 2019, 311, 279, 18266, 30, 4400, 520, 682], [8144, 757, 264, 33894, 922, 279, 18266, 3861, 369, 279, 18266, 11, 323, 832, 369, 757, 11, 889, 527, 584, 311, 3137, 922, 279, 18266, 30]], 'model': 'text-embedding-ada-002', 'encoding_format': 'base64'}}\n",
            "DEBUG:openai._base_client:HTTP Request: POST https://api.openai.com/v1/embeddings \"200 OK\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gb7REW51otVk",
        "outputId": "c3d88396-9a71-4704-8e0a-e0211b10813a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x7d7b5a94b910>, 'json_data': {'input': [[18, 50266, 111, 17663, 34617, 19012, 249, 76622, 30369, 34617, 15682, 99849, 38641, 32149, 11571]], 'model': 'text-embedding-ada-002', 'encoding_format': 'base64'}}\n",
            "DEBUG:openai._base_client:HTTP Request: POST https://api.openai.com/v1/embeddings \"200 OK\"\n",
            "WARNING:cassandra.protocol:Server warning: Top-K queries can only be run with consistency level ONE / LOCAL_ONE / NODE_LOCAL. Consistency level LOCAL_QUORUM was requested. Downgrading the consistency level to LOCAL_ONE.\n",
            "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a wondrous wizard of math.'}, {'role': 'user', 'content': '1足す1に2を掛けるといくつですか？'}, {'role': 'assistant', 'content': '4'}, {'role': 'user', 'content': '2+3'}, {'role': 'assistant', 'content': '5'}, {'role': 'user', 'content': '3足す３掛ける３は何ですか？'}], 'model': 'gpt-3.5-turbo', 'n': 1, 'stream': False, 'temperature': 0.0}}\n",
            "DEBUG:openai._base_client:HTTP Request: POST https://api.openai.com/v1/chat/completions \"200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3足す3は6です。3を3倍すると9です。\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# セマンティック類似性に基づく選択器を初期化。kは類似する最上位kの例を選択する数を意味する\n",
        "example_selector = SemanticSimilarityExampleSelector(\n",
        "    vectorstore=vectorstore,\n",
        "    k=2,\n",
        ")\n",
        "\n",
        "# メッセージプロンプトテンプレートを定義\n",
        "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
        "    input_variables=[\"input\"],\n",
        "    example_selector=example_selector,\n",
        "    example_prompt=ChatPromptTemplate.from_messages(\n",
        "        [(\"human\", \"{input}\"), (\"ai\", \"{output}\")]\n",
        "    ),\n",
        ")\n",
        "\n",
        "# 最終的なチャットプロンプトテンプレートを定義\n",
        "final_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"You are a wondrous wizard of math.\"),\n",
        "        few_shot_prompt,\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# チャットモデルとプロンプトテンプレートをチェーン化\n",
        "#chain = final_prompt | ChatOpenAI(temperature=0.0, model=\"gpt-3.5-turbo\",openai_api_key=my_key)\n",
        "chain = final_prompt | ChatOpenAI(temperature=0.0, model=\"gpt-3.5-turbo\")\n",
        "\n",
        "# チェーンを使って質問を投げ、結果を表示\n",
        "#print(chain.invoke({\"input\": \"What's 3+3?\"}).content)\n",
        "print(chain.invoke({\"input\": \"3足す３掛ける３は何ですか？\"}).content)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "DEBUG:openai._base_client:Request options:\n",
        "{'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages':\n",
        "[{'role': 'system', 'content': 'You are a wondrous wizard of math.'},\n",
        "{'role': 'user', 'content': '1足す1に2を掛けるといくつですか？'},\n",
        "{'role': 'assistant', 'content': '4'},\n",
        "{'role': 'user', 'content': '2+3'},\n",
        "{'role': 'assistant', 'content': '5'},\n",
        "{'role': 'user', 'content': '3足す３掛ける３は何ですか？'}],\n",
        "'model': 'gpt-3.5-turbo', 'n': 1, 'stream': False, 'temperature': 0.0}}\n",
        "```\n"
      ],
      "metadata": {
        "id": "WEcazUKcHu_n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 参考 References\n",
        "\n",
        "https://zenn.dev/tsuzukia/articles/8fc74bdb8770a5"
      ],
      "metadata": {
        "id": "EwyLD9ORoyRM"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n4DcMJe9YmKB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}